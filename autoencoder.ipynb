{"cells":[{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":10713,"status":"ok","timestamp":1727205201330,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"JVxRWRFoXmzp"},"outputs":[],"source":["# Torch-related imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset, Subset\n","\n","# Scikit-learn-related imports\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","# Nibabel and Scipy imports (for handling fMRI and image processing)\n","import nibabel as nib\n","import scipy.ndimage as ndimage  # For smoothing\n","\n","# NumPy, Matplotlib, and Seaborn (for data manipulation and visualization)\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# OS for file system operations\n","import os"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1727205204171,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"gbM8hGXtXr20","outputId":"86fdd20c-ff4d-4855-dcfa-081c4a820ec0"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"Y6g2yk5jYDOY"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1350,"status":"ok","timestamp":1727205206943,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"nOOgfWGtXsiJ","outputId":"cc09d016-f527-47d8-df41-9d20ce946ae8"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# root_dir = os.path.join('/content/drive', 'My Drive', 'UCR', '2-2024', 'InvCC', 'ADHD200', 'Datasets', 'preprocessed')\n","\n","root_dir = os.path.join('preprocessed')\n","\n","# Carpetas para TDC y ADHD\n","tdc_dir = os.path.join(root_dir, 'TDC')\n","adhd_dir = os.path.join(root_dir, 'ADHD')\n","\n","# Para guardar el estado del autoencoder\n","save_path = os.path.join(root_dir, 'autoencoder.pt')\n","\n","# Listas para almacenar las rutas de archivos\n","tdc_file_paths = [os.path.join(tdc_dir, file) for file in os.listdir(tdc_dir) if file.endswith('.nii.gz')]\n","adhd_file_paths = [os.path.join(adhd_dir, file) for file in os.listdir(adhd_dir) if file.endswith('.nii.gz')]\n","\n","# Etiquetas correspondientes\n","tdc_labels = [0] * len(tdc_file_paths)\n","adhd_labels = [1] * len(adhd_file_paths)\n","\n","# Combinar rutas de archivos y etiquetas\n","file_paths = tdc_file_paths + adhd_file_paths\n","labels = tdc_labels + adhd_labels"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1727205212587,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"l6rQM69NXyLm"},"outputs":[],"source":["class FMRI_Dataset(Dataset):\n","    def __init__(self, file_paths, labels, max_shape, smoothing_sigma=1):\n","        self.file_paths = file_paths  # List of paths to the fMRI data files\n","        self.labels = labels  # Corresponding labels\n","        self.max_shape = max_shape  # Shape to pad all inputs to\n","        self.smoothing_sigma = smoothing_sigma  # Standard deviation for Gaussian smoothing\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, idx):\n","        # Load fMRI data using NiBabel\n","        fmri_img = nib.load(self.file_paths[idx])\n","        data = fmri_img.get_fdata()  # Extract the fMRI data as a NumPy array\n","\n","        # Apply smoothing\n","        # data = self.smooth_data(data)\n","\n","        # Normalize the data\n","        data = self.normalize_data(data)\n","\n","        # Convert NumPy array to a PyTorch tensor\n","        data = torch.tensor(data, dtype=torch.float32)\n","\n","        # Get the label\n","        label = torch.tensor(self.labels[idx])\n","\n","        # Pad the tensor to the max_shape\n","        data_padded = F.pad(data, pad=self.calculate_padding(data.shape), mode='constant', value=0)\n","\n","        return data_padded, label\n","\n","    def calculate_padding(self, current_shape):\n","        padding = []\n","        for current_dim, max_dim in zip(reversed(current_shape), reversed(self.max_shape)):\n","            pad_total = max_dim - current_dim\n","            padding.append(pad_total // 2)  # pad_left or pad_top, etc.\n","            padding.append(pad_total - (pad_total // 2))  # pad_right or pad_bottom, etc.\n","\n","        return padding\n","\n","    def normalize_data(self, data):\n","        \"\"\"Normalize the data to zero mean and unit variance.\"\"\"\n","        mean = data.mean()\n","        std = data.std()\n","        if std > 0:  # Avoid division by zero\n","            data = (data - mean) / std\n","        return data\n","\n","    def smooth_data(self, data):\n","        \"\"\"Apply Gaussian smoothing to the data.\"\"\"\n","        return ndimage.gaussian_filter(data, sigma=self.smoothing_sigma)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1690,"status":"ok","timestamp":1727205217105,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"oNSAi-5rX3Pt","outputId":"6aa5e157-c2da-4190-a96d-15b000d70ec4"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([53, 64, 46, 512]) tensor(0)\n"]}],"source":["# Determine the maximum shape across all tensors\n","max_shape = [1, 53, 64, 46, 512]\n","\n","# Create the dataset with padded tensors\n","dataset = FMRI_Dataset(file_paths, labels, max_shape)\n","\n","sample_data, sample_label = dataset[0]\n","print(sample_data.shape, sample_label)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":10228,"status":"ok","timestamp":1727205249449,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"VuxrLbWOX5uj"},"outputs":[],"source":["# Crear el objeto StratifiedShuffleSplit para dividir en conjuntos de entrenamiento y prueba\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n","\n","# Dividir en entrenamiento y prueba\n","for train_val_idx, test_idx in sss.split(range(len(dataset)), dataset.labels):\n","    train_val_set = torch.utils.data.Subset(dataset, train_val_idx)\n","    testset = torch.utils.data.Subset(dataset, test_idx)\n","\n","# Ahora crear un segundo StratifiedShuffleSplit para los conjuntos de entrenamiento y validación\n","sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)  # 0.25 de 0.8 es 0.2 total para validación\n","\n","# Acceder a las etiquetas del conjunto de entrenamiento y validación\n","train_val_labels = [dataset.labels[i] for i in train_val_idx]  # Obtener las etiquetas usando una lista de comprensión\n","\n","for train_idx, val_idx in sss_val.split(range(len(train_val_set)), train_val_labels):\n","    trainset = torch.utils.data.Subset(train_val_set, train_idx)\n","    valset = torch.utils.data.Subset(train_val_set, val_idx)\n","\n","# Crear los dataloaders\n","batch_size = 1\n","trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n","valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=0)\n","testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n","\n","class_names = [\"TDC\", \"ADHD\"]\n","\n","# Iterate over the dataloaders to verify they are being processed correctly\n","for batch in trainloader:\n","    if batch[0] is not None:\n","        images, _ = batch\n","        break\n","        # print(f\"Shape of inputs: {images.shape}, Shape of labels: {_}\")\n","\n","\n","for batch in testloader:\n","    if batch[0] is not None:\n","        images, _ = batch\n","        break\n","        # print(f\"Shape of inputs: {images.shape}, Shape of labels: {_}\")\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1727205253990,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"ElUPKRG4X7m9","outputId":"1e7cfc3d-4985-4eec-b14d-f66a5025d64e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of samples in valloader: 34\n","Number of samples in trainloader: 102\n","Number of samples in testloader: 34\n"]}],"source":["print(f\"Number of samples in valloader: {len(valloader.dataset)}\")\n","print(f\"Number of samples in trainloader: {len(trainloader.dataset)}\")\n","print(f\"Number of samples in testloader: {len(testloader.dataset)}\")"]},{"cell_type":"markdown","metadata":{"id":"O8foNAGnYHdv"},"source":["# CNN-AE"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2468,"status":"ok","timestamp":1727205276496,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"3mG-7GH_YKAO","outputId":"19a7bdcb-b596-48f5-ebe2-14332a68922d"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 53, 64, 46])\n"]}],"source":["class CNN_Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(CNN_Autoencoder, self).__init__()\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv3d(1, 16, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Dropout3d(0.2),\n","            nn.Conv3d(16, 64, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Dropout3d(0.2),\n","            nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Dropout3d(0.2),\n","            nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose3d(256, 128, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(0, 1, 0)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(1, 0, 1)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(64, 16, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 0, 1)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 1, 1)),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","\n","# Example usage\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","autoencoder = CNN_Autoencoder().to(device)\n","\n","# Generate random input matching new shape [1, 1, 53, 64] (Batch size 1)\n","inputs = torch.rand((1, 53, 64, 46)).to(device)  # Example input\n","output = autoencoder(inputs)\n","print(output.shape)  # should match the input shape [1, 53, 64, 46]\n","\n","# Loss and optimizer\n","criterion = nn.MSELoss()  # Since it's an autoencoder, Mean Squared Error is commonly used\n","optimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)\n"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHZ6Bjm4YMCa","outputId":"f0d69c64-f5a9-44fa-88bc-75d50fdf19cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Training Loss: 0.21615308322304605\n","Epoch [1/100], Validation Loss: 0.1898005849079174\n","Model saved at epoch 1 with validation loss: 0.1898005849079174\n","Epoch [2/100], Training Loss: 0.18170130117705055\n","Epoch [2/100], Validation Loss: 0.18593355728422895\n","Model saved at epoch 2 with validation loss: 0.18593355728422895\n","Epoch [3/100], Training Loss: 0.17623058249991314\n","Epoch [3/100], Validation Loss: 0.17841029353439808\n","Model saved at epoch 3 with validation loss: 0.17841029353439808\n","Epoch [4/100], Training Loss: 0.15812896418513037\n","Epoch [4/100], Validation Loss: 0.12286891503369107\n","Model saved at epoch 4 with validation loss: 0.12286891503369107\n","Epoch [5/100], Training Loss: 0.10846456467155732\n","Epoch [5/100], Validation Loss: 0.09919735504423871\n","Model saved at epoch 5 with validation loss: 0.09919735504423871\n","Epoch [6/100], Training Loss: 0.0941785421112881\n","Epoch [6/100], Validation Loss: 0.09095219747327707\n","Model saved at epoch 6 with validation loss: 0.09095219747327707\n","Epoch [7/100], Training Loss: 0.08852992360206212\n","Epoch [7/100], Validation Loss: 0.08756188303232193\n","Model saved at epoch 7 with validation loss: 0.08756188303232193\n","Epoch [8/100], Training Loss: 0.08508086885672574\n","Epoch [8/100], Validation Loss: 0.08454690024475842\n","Model saved at epoch 8 with validation loss: 0.08454690024475842\n","Epoch [9/100], Training Loss: 0.08302762505470537\n","Epoch [9/100], Validation Loss: 0.08326142757911892\n","Model saved at epoch 9 with validation loss: 0.08326142757911892\n","Epoch [10/100], Training Loss: 0.08157008115713503\n","Epoch [10/100], Validation Loss: 0.08150238593054168\n","Model saved at epoch 10 with validation loss: 0.08150238593054168\n","Epoch [11/100], Training Loss: 0.08028253412568102\n","Epoch [11/100], Validation Loss: 0.0818836904843064\n","Epoch [12/100], Training Loss: 0.07900452014862322\n","Epoch [12/100], Validation Loss: 0.07961069808944184\n","Model saved at epoch 12 with validation loss: 0.07961069808944184\n","Epoch [13/100], Training Loss: 0.07798137161515507\n","Epoch [13/100], Validation Loss: 0.07949810195714235\n","Model saved at epoch 13 with validation loss: 0.07949810195714235\n","Epoch [14/100], Training Loss: 0.07728021796427521\n","Epoch [14/100], Validation Loss: 0.0776833308970227\n","Model saved at epoch 14 with validation loss: 0.0776833308970227\n","Epoch [15/100], Training Loss: 0.07630899007998261\n","Epoch [15/100], Validation Loss: 0.07699458027148948\n","Model saved at epoch 15 with validation loss: 0.07699458027148948\n","Epoch [16/100], Training Loss: 0.0752290473228284\n","Epoch [16/100], Validation Loss: 0.07625156772487304\n","Model saved at epoch 16 with validation loss: 0.07625156772487304\n","Epoch [17/100], Training Loss: 0.07501748008836134\n","Epoch [17/100], Validation Loss: 0.07537305092110354\n","Model saved at epoch 17 with validation loss: 0.07537305092110354\n","Epoch [18/100], Training Loss: 0.07443827105795636\n","Epoch [18/100], Validation Loss: 0.07552110995439922\n","Epoch [19/100], Training Loss: 0.0734699795606966\n","Epoch [19/100], Validation Loss: 0.07452747253153254\n","Model saved at epoch 19 with validation loss: 0.07452747253153254\n","Epoch [20/100], Training Loss: 0.07309548638980179\n","Epoch [20/100], Validation Loss: 0.07407172730959513\n","Model saved at epoch 20 with validation loss: 0.07407172730959513\n","Epoch [21/100], Training Loss: 0.07274055461782743\n","Epoch [21/100], Validation Loss: 0.07352370955049992\n","Model saved at epoch 21 with validation loss: 0.07352370955049992\n","Epoch [22/100], Training Loss: 0.07182049208010237\n","Epoch [22/100], Validation Loss: 0.07350338557187248\n","Model saved at epoch 22 with validation loss: 0.07350338557187248\n","Epoch [23/100], Training Loss: 0.07143798675935935\n","Epoch [23/100], Validation Loss: 0.07502801217796172\n","Epoch [24/100], Training Loss: 0.07145071306320674\n","Epoch [24/100], Validation Loss: 0.07241307650966679\n","Model saved at epoch 24 with validation loss: 0.07241307650966679\n","Epoch [25/100], Training Loss: 0.0711742371192896\n","Epoch [25/100], Validation Loss: 0.07207716401556835\n","Model saved at epoch 25 with validation loss: 0.07207716401556835\n","Epoch [26/100], Training Loss: 0.07037998710338976\n","Epoch [26/100], Validation Loss: 0.07171685081523131\n","Model saved at epoch 26 with validation loss: 0.07171685081523131\n","Epoch [27/100], Training Loss: 0.07025796399616144\n","Epoch [27/100], Validation Loss: 0.07103591278085813\n","Model saved at epoch 27 with validation loss: 0.07103591278085813\n","Epoch [28/100], Training Loss: 0.06962465411782556\n","Epoch [28/100], Validation Loss: 0.07072983032968991\n","Model saved at epoch 28 with validation loss: 0.07072983032968991\n","Epoch [29/100], Training Loss: 0.06905974780994595\n","Epoch [29/100], Validation Loss: 0.07083883624085609\n","Epoch [30/100], Training Loss: 0.06870819918592186\n","Epoch [30/100], Validation Loss: 0.07171486728989027\n","Epoch [31/100], Training Loss: 0.06894421969156932\n","Epoch [31/100], Validation Loss: 0.06989577582434696\n","Model saved at epoch 31 with validation loss: 0.06989577582434696\n","Epoch [32/100], Training Loss: 0.0685282873409782\n","Epoch [32/100], Validation Loss: 0.07059578526326839\n","Epoch [33/100], Training Loss: 0.06843636418674506\n","Epoch [33/100], Validation Loss: 0.06848629865357105\n","Model saved at epoch 33 with validation loss: 0.06848629865357105\n","Epoch [34/100], Training Loss: 0.06835655811443633\n","Epoch [34/100], Validation Loss: 0.06864291347344131\n","Epoch [35/100], Training Loss: 0.06797511779757984\n","Epoch [35/100], Validation Loss: 0.06865616846720085\n","Epoch [36/100], Training Loss: 0.06805448005815931\n","Epoch [36/100], Validation Loss: 0.06780036536100156\n","Model saved at epoch 36 with validation loss: 0.06780036536100156\n","Epoch [37/100], Training Loss: 0.06747726060669212\n","Epoch [37/100], Validation Loss: 0.07262568619540509\n","Epoch [38/100], Training Loss: 0.06789892142200295\n","Epoch [38/100], Validation Loss: 0.06790886841276113\n","Epoch [39/100], Training Loss: 0.06759253706710011\n","Epoch [39/100], Validation Loss: 0.0680377601974589\n","Epoch [40/100], Training Loss: 0.06762610846107789\n","Epoch [40/100], Validation Loss: 0.06777333468198776\n","Model saved at epoch 40 with validation loss: 0.06777333468198776\n","Epoch [41/100], Training Loss: 0.06735526550305533\n","Epoch [41/100], Validation Loss: 0.06805507866117884\n","Epoch [42/100], Training Loss: 0.06685203517440196\n","Epoch [42/100], Validation Loss: 0.06700306495322901\n","Model saved at epoch 42 with validation loss: 0.06700306495322901\n","Epoch [43/100], Training Loss: 0.06715097606145576\n","Epoch [43/100], Validation Loss: 0.07142548857475906\n","Epoch [44/100], Training Loss: 0.06668515541755102\n","Epoch [44/100], Validation Loss: 0.0667825204813305\n","Model saved at epoch 44 with validation loss: 0.0667825204813305\n","Epoch [45/100], Training Loss: 0.06680257867693025\n","Epoch [45/100], Validation Loss: 0.06647020000416566\n","Model saved at epoch 45 with validation loss: 0.06647020000416566\n","Epoch [46/100], Training Loss: 0.06628707447545786\n","Epoch [46/100], Validation Loss: 0.06641989803927786\n","Model saved at epoch 46 with validation loss: 0.06641989803927786\n","Epoch [47/100], Training Loss: 0.06566426889313494\n","Epoch [47/100], Validation Loss: 0.0661879361826269\n","Model saved at epoch 47 with validation loss: 0.0661879361826269\n","Epoch [48/100], Training Loss: 0.06614341499174342\n","Epoch [48/100], Validation Loss: 0.06605825619772077\n","Model saved at epoch 48 with validation loss: 0.06605825619772077\n","Epoch [49/100], Training Loss: 0.06565146211206037\n","Epoch [49/100], Validation Loss: 0.06639513863688883\n","Epoch [50/100], Training Loss: 0.06700342174108122\n","Epoch [50/100], Validation Loss: 0.07689847734154147\n","Epoch [51/100], Training Loss: 0.06704811101742819\n","Epoch [51/100], Validation Loss: 0.06606550399652299\n","Epoch [52/100], Training Loss: 0.06669903625095007\n","Epoch [52/100], Validation Loss: 0.06780604730524561\n","Epoch [53/100], Training Loss: 0.06591203978613895\n","Epoch [53/100], Validation Loss: 0.06779195392942604\n","Epoch [54/100], Training Loss: 0.06527998428061313\n","Epoch [54/100], Validation Loss: 0.06671837900820024\n","Epoch [55/100], Training Loss: 0.06597671425883092\n","Epoch [55/100], Validation Loss: 0.06639045323519145\n","Epoch [56/100], Training Loss: 0.06617984233204932\n","Epoch [56/100], Validation Loss: 0.0678201281629941\n","Epoch [57/100], Training Loss: 0.06632489490998435\n","Epoch [57/100], Validation Loss: 0.06595193548128009\n","Model saved at epoch 57 with validation loss: 0.06595193548128009\n","Epoch [58/100], Training Loss: 0.06576735932635618\n","Epoch [58/100], Validation Loss: 0.06644031312316656\n","Epoch [59/100], Training Loss: 0.06506348647834624\n","Epoch [59/100], Validation Loss: 0.0651357819819275\n","Model saved at epoch 59 with validation loss: 0.0651357819819275\n","Epoch [60/100], Training Loss: 0.06581368724651196\n","Epoch [60/100], Validation Loss: 0.06666751761975534\n","Epoch [61/100], Training Loss: 0.06528125020364921\n","Epoch [61/100], Validation Loss: 0.06720523314331384\n","Epoch [62/100], Training Loss: 0.06545552941879221\n","Epoch [62/100], Validation Loss: 0.06636972355601542\n","Epoch [63/100], Training Loss: 0.06588762980319705\n","Epoch [63/100], Validation Loss: 0.0652241301996743\n","Epoch [64/100], Training Loss: 0.06483291533282574\n","Epoch [64/100], Validation Loss: 0.06518908505163648\n","Epoch [65/100], Training Loss: 0.0648357261739233\n","Epoch [65/100], Validation Loss: 0.06501716884839184\n","Model saved at epoch 65 with validation loss: 0.06501716884839184\n","Epoch [66/100], Training Loss: 0.06521203948696162\n","Epoch [66/100], Validation Loss: 0.0648322740350576\n","Model saved at epoch 66 with validation loss: 0.0648322740350576\n","Epoch [67/100], Training Loss: 0.06479933545650805\n","Epoch [67/100], Validation Loss: 0.0659396771396346\n","Epoch [68/100], Training Loss: 0.06467678253630213\n","Epoch [68/100], Validation Loss: 0.06499661239521469\n","Epoch [69/100], Training Loss: 0.06492986109144255\n","Epoch [69/100], Validation Loss: 0.0652751175358015\n","Epoch [70/100], Training Loss: 0.06477750886195138\n","Epoch [70/100], Validation Loss: 0.06509585125262246\n","Epoch [71/100], Training Loss: 0.06507569919431619\n","Epoch [71/100], Validation Loss: 0.06521616752862054\n","Epoch [72/100], Training Loss: 0.06451909118058051\n","Epoch [72/100], Validation Loss: 0.06447219130966593\n","Model saved at epoch 72 with validation loss: 0.06447219130966593\n","Epoch [73/100], Training Loss: 0.06513600808330904\n","Epoch [73/100], Validation Loss: 0.06752858006888453\n","Epoch [74/100], Training Loss: 0.06482513511882108\n","Epoch [74/100], Validation Loss: 0.06725067543961546\n","Epoch [75/100], Training Loss: 0.06445552592220552\n","Epoch [75/100], Validation Loss: 0.06655688496196971\n","Epoch [76/100], Training Loss: 0.06383109908076186\n","Epoch [76/100], Validation Loss: 0.06474085710942745\n","Epoch [77/100], Training Loss: 0.06415211865861042\n","Epoch [77/100], Validation Loss: 0.0673696754828972\n","Epoch [78/100], Training Loss: 0.06438605944790385\n","Epoch [78/100], Validation Loss: 0.0650884683298714\n","Epoch [79/100], Training Loss: 0.06388549065655645\n","Epoch [79/100], Validation Loss: 0.06416512801147559\n","Model saved at epoch 79 with validation loss: 0.06416512801147559\n","Epoch [80/100], Training Loss: 0.06374821021203317\n","Epoch [80/100], Validation Loss: 0.06433190868290908\n","Epoch [81/100], Training Loss: 0.06433547273570416\n","Epoch [81/100], Validation Loss: 0.06499673152232871\n","Epoch [82/100], Training Loss: 0.06444021486038086\n","Epoch [82/100], Validation Loss: 0.06642374692156035\n","Epoch [83/100], Training Loss: 0.06412939067163012\n","Epoch [83/100], Validation Loss: 0.06692469722646124\n","Epoch [84/100], Training Loss: 0.06396396740284913\n","Epoch [84/100], Validation Loss: 0.06488306146553334\n","Epoch [85/100], Training Loss: 0.06440305227742475\n","Epoch [85/100], Validation Loss: 0.06422034914002699\n","Epoch [86/100], Training Loss: 0.06345196019894644\n","Epoch [86/100], Validation Loss: 0.06505008055554594\n","Epoch [87/100], Training Loss: 0.06387633453214578\n","Epoch [87/100], Validation Loss: 0.06514910890666001\n","Epoch [88/100], Training Loss: 0.06367411420625799\n","Epoch [88/100], Validation Loss: 0.06385120053720825\n","Model saved at epoch 88 with validation loss: 0.06385120053720825\n","Epoch [89/100], Training Loss: 0.06370771874436269\n","Epoch [89/100], Validation Loss: 0.0640867739532362\n","Epoch [90/100], Training Loss: 0.06363981258233681\n","Epoch [90/100], Validation Loss: 0.06570307792657439\n","Epoch [91/100], Training Loss: 0.06383979816318434\n","Epoch [91/100], Validation Loss: 0.06408689992831033\n","Epoch [92/100], Training Loss: 0.06303088380681242\n","Epoch [92/100], Validation Loss: 0.0644855547203299\n","Epoch [93/100], Training Loss: 0.06287148577508096\n","Epoch [93/100], Validation Loss: 0.06541326598209493\n","Epoch [94/100], Training Loss: 0.0638674688616804\n","Epoch [94/100], Validation Loss: 0.06426512247280163\n","Epoch [95/100], Training Loss: 0.06314291644330118\n","Epoch [95/100], Validation Loss: 0.06397161925868954\n","Epoch [96/100], Training Loss: 0.06331787857354856\n","Epoch [96/100], Validation Loss: 0.0649877151419573\n","Epoch [97/100], Training Loss: 0.0626951386038141\n","Epoch [97/100], Validation Loss: 0.06487435600994264\n","Epoch [98/100], Training Loss: 0.06348940946490449\n","Epoch [98/100], Validation Loss: 0.06477518752217293\n","Epoch [99/100], Training Loss: 0.06380297147723682\n","Epoch [99/100], Validation Loss: 0.06503918273922275\n","Epoch [100/100], Training Loss: 0.06332623501143911\n","Epoch [100/100], Validation Loss: 0.06374195278348292\n","Model saved at epoch 100 with validation loss: 0.06374195278348292\n"]}],"source":["# Number of epochs\n","epochs = 100\n","\n","# Track the best validation loss\n","best_val_loss = float('inf')\n","\n","for epoch in range(epochs):\n","    # Training phase\n","    autoencoder.train()  # Set the model to training mode\n","    total_loss = 0.0\n","    for batch_idx, (inputs, labels) in enumerate(trainloader):\n","        inputs_reduced = torch.mean(inputs, dim=-1)\n","        inputs = inputs_reduced\n","\n","        inputs = inputs.to(device)  # Send to GPU if available\n","\n","        # Forward pass\n","        outputs = autoencoder(inputs)\n","        loss = criterion(outputs, inputs)  # Compare reconstruction with original input\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    # Calculate average training loss\n","    avg_train_loss = total_loss / len(trainloader)\n","    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {avg_train_loss}\")\n","\n","    # Validation phase\n","    autoencoder.eval()  # Set the model to evaluation mode\n","    total_val_loss = 0.0\n","    with torch.no_grad():  # Disable gradient calculation\n","        for val_inputs, val_labels in valloader:\n","            val_inputs_reduced = torch.mean(val_inputs, dim=-1)\n","            val_inputs = val_inputs_reduced.to(device)  # Send validation inputs to GPU if available\n","\n","            # Forward pass\n","            val_outputs = autoencoder(val_inputs)\n","            val_loss = criterion(val_outputs, val_inputs)  # Compare reconstruction with original input\n","            total_val_loss += val_loss.item()\n","\n","    # Calculate average validation loss\n","    avg_val_loss = total_val_loss / len(valloader)\n","    print(f\"Epoch [{epoch+1}/{epochs}], Validation Loss: {avg_val_loss}\")\n","\n","    # Save the model if the validation loss has decreased\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        torch.save(autoencoder.state_dict(), save_path)\n","        print(f\"Model saved at epoch {epoch+1} with validation loss: {avg_val_loss}\")\n","\n","# Final save after training\n","torch.save(autoencoder.state_dict(), save_path)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMaDGZjUjH0q9uGkEIfs8cd","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
