{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10713,"status":"ok","timestamp":1727205201330,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"JVxRWRFoXmzp"},"outputs":[],"source":["# Torch-related imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset, Subset\n","\n","# Scikit-learn-related imports\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","# Nibabel and Scipy imports (for handling fMRI and image processing)\n","import nibabel as nib\n","import scipy.ndimage as ndimage  # For smoothing\n","\n","# NumPy, Matplotlib, and Seaborn (for data manipulation and visualization)\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# OS for file system operations\n","import os"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1727205204171,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"gbM8hGXtXr20","outputId":"86fdd20c-ff4d-4855-dcfa-081c4a820ec0"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"Y6g2yk5jYDOY"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1350,"status":"ok","timestamp":1727205206943,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"nOOgfWGtXsiJ","outputId":"cc09d016-f527-47d8-df41-9d20ce946ae8"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# root_dir = os.path.join('/content/drive', 'My Drive', 'UCR', '2-2024', 'InvCC', 'ADHD200', 'Datasets', 'preprocessed')\n","\n","root_dir = os.path.join('preprocessed')\n","\n","# Carpetas para TDC y ADHD\n","tdc_dir = os.path.join(root_dir, 'TDC')\n","adhd_dir = os.path.join(root_dir, 'ADHD')\n","\n","# Para guardar el estado del autoencoder\n","save_path = os.path.join(root_dir, 'autoencoder.pt')\n","\n","# Listas para almacenar las rutas de archivos\n","tdc_file_paths = [os.path.join(tdc_dir, file) for file in os.listdir(tdc_dir) if file.endswith('.nii.gz')]\n","adhd_file_paths = [os.path.join(adhd_dir, file) for file in os.listdir(adhd_dir) if file.endswith('.nii.gz')]\n","\n","# Etiquetas correspondientes\n","tdc_labels = [0] * len(tdc_file_paths)\n","adhd_labels = [1] * len(adhd_file_paths)\n","\n","# Combinar rutas de archivos y etiquetas\n","file_paths = tdc_file_paths + adhd_file_paths\n","labels = tdc_labels + adhd_labels"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1727205212587,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"l6rQM69NXyLm"},"outputs":[],"source":["class FMRI_Dataset(Dataset):\n","    def __init__(self, file_paths, labels, max_shape, smoothing_sigma=1):\n","        self.file_paths = file_paths  # List of paths to the fMRI data files\n","        self.labels = labels  # Corresponding labels\n","        self.max_shape = max_shape  # Shape to pad all inputs to (e.g., [1, 53, 64, 46, 512])\n","        self.smoothing_sigma = smoothing_sigma  # Standard deviation for Gaussian smoothing\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, idx):\n","        # Load fMRI data using NiBabel\n","        fmri_img = nib.load(self.file_paths[idx])\n","        data = fmri_img.get_fdata()  # Extract the fMRI data as a NumPy array\n","\n","        # Apply smoothing\n","        data = self.smooth_data(data)\n","\n","        # Normalize the data\n","        data = self.normalize_data(data)\n","\n","        # Convert NumPy array to a PyTorch tensor and add missing dimensions as needed\n","        data = torch.tensor(data, dtype=torch.float32).unsqueeze(0)\n","\n","        # Pad the tensor to the specified max_shape\n","        data_padded = F.pad(data, pad=self.calculate_padding(data.shape), mode='constant', value=0)\n","\n","        # Ensure that the final shape matches max_shape exactly\n","        data_padded = data_padded.view(*self.max_shape)\n","\n","        # Get the label\n","        label = torch.tensor(self.labels[idx], dtype=torch.long)\n","\n","        return data_padded, label\n","\n","    def calculate_padding(self, current_shape):\n","        padding = []\n","        # Reverse the dimensions to calculate padding from last dimension to the first\n","        for current_dim, max_dim in zip(reversed(current_shape), reversed(self.max_shape)):\n","            pad_total = max_dim - current_dim\n","            padding.append(pad_total // 2)  # pad_left or pad_top, etc.\n","            padding.append(pad_total - (pad_total // 2))  # pad_right or pad_bottom, etc.\n","        return padding\n","\n","    def normalize_data(self, data):\n","        \"\"\"Normalize the data to zero mean and unit variance.\"\"\"\n","        mean = data.mean()\n","        std = data.std()\n","        if std > 0:  # Avoid division by zero\n","            data = (data - mean) / std\n","        return data\n","\n","    def smooth_data(self, data):\n","        \"\"\"Apply Gaussian smoothing to the data.\"\"\"\n","        return ndimage.gaussian_filter(data, sigma=self.smoothing_sigma)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1690,"status":"ok","timestamp":1727205217105,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"oNSAi-5rX3Pt","outputId":"6aa5e157-c2da-4190-a96d-15b000d70ec4"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 53, 64, 46, 512]) tensor(0)\n"]}],"source":["# Determine the maximum shape across all tensors\n","max_shape = [1, 53, 64, 46, 512]\n","\n","# Create the dataset with padded tensors\n","dataset = FMRI_Dataset(file_paths, labels, max_shape)\n","\n","sample_data, sample_label = dataset[0]\n","print(sample_data.shape, sample_label)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":10228,"status":"ok","timestamp":1727205249449,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"VuxrLbWOX5uj"},"outputs":[],"source":["from torch.utils.data import DataLoader, Dataset, Subset\n","from sklearn.model_selection import StratifiedShuffleSplit\n","import torch\n","\n","# Create StratifiedShuffleSplit object to split into training and test sets\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n","\n","# Ensure labels are on CPU for compatibility with sklearn\n","labels_cpu = dataset.labels.cpu().numpy() if isinstance(dataset.labels, torch.Tensor) else dataset.labels\n","\n","# Split into training and test sets\n","for train_val_idx, test_idx in sss.split(range(len(dataset)), labels_cpu):\n","    train_val_set = Subset(dataset, train_val_idx)\n","    testset = Subset(dataset, test_idx)\n","\n","# Create another StratifiedShuffleSplit for training and validation sets\n","sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)  # 0.25 of 0.8 gives 0.2 total for validation\n","\n","# Access labels for train_val_set\n","train_val_labels = [labels_cpu[i] for i in train_val_idx]  # Use list comprehension to retrieve labels\n","\n","# Split train_val_set into train and validation sets\n","for train_idx, val_idx in sss_val.split(range(len(train_val_set)), train_val_labels):\n","    trainset = Subset(train_val_set, train_idx)\n","    valset = Subset(train_val_set, val_idx)\n","\n","# Create dataloaders\n","batch_size = 1\n","trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n","valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=0)\n","testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n","\n","class_names = [\"TDC\", \"ADHD\"]\n","\n","# Verify the dataloaders\n","for batch in trainloader:\n","    if batch[0] is not None:\n","        images, labels = batch\n","        break\n","        # print(f\"Shape of inputs: {images.shape}, Shape of labels: {labels}\")\n","\n","for batch in testloader:\n","    if batch[0] is not None:\n","        images, labels = batch\n","        break\n","        # print(f\"Shape of inputs: {images.shape}, Shape of labels: {labels}\")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1727205253990,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"ElUPKRG4X7m9","outputId":"1e7cfc3d-4985-4eec-b14d-f66a5025d64e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of samples in valloader: 561\n","Number of samples in trainloader: 1680\n","Number of samples in testloader: 561\n"]}],"source":["print(f\"Number of samples in valloader: {len(valloader.dataset)}\")\n","print(f\"Number of samples in trainloader: {len(trainloader.dataset)}\")\n","print(f\"Number of samples in testloader: {len(testloader.dataset)}\")"]},{"cell_type":"markdown","metadata":{"id":"O8foNAGnYHdv"},"source":["# CNN-AE"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2468,"status":"ok","timestamp":1727205276496,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"3mG-7GH_YKAO","outputId":"19a7bdcb-b596-48f5-ebe2-14332a68922d"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 53, 64, 46])\n"]}],"source":["class CNN_Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(CNN_Autoencoder, self).__init__()\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv3d(1, 16, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv3d(16, 64, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose3d(256, 128, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(0, 1, 0)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(1, 0, 1)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(64, 16, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 0, 1)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 1, 1)),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","\n","# Example usage\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","autoencoder = CNN_Autoencoder().to(device)\n","\n","# Generate random input matching new shape [1, 1, 53, 64] (Batch size 1)\n","inputs = torch.rand((1, 53, 64, 46)).to(device)  # Example input\n","output = autoencoder(inputs)\n","print(output.shape)  # should match the input shape [1, 53, 64, 46]\n","\n","# Loss and optimizer\n","criterion = nn.MSELoss()  # Since it's an autoencoder, Mean Squared Error is commonly used\n","optimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHZ6Bjm4YMCa","outputId":"f0d69c64-f5a9-44fa-88bc-75d50fdf19cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Training Loss: 0.022387138504113648\n","Epoch [1/100], Validation Loss: 0.015976974350498215\n","Model saved at epoch 1 with validation loss: 0.015976974350498215\n","Epoch [2/100], Training Loss: 0.010911609241780492\n","Epoch [2/100], Validation Loss: 0.009090638543734802\n","Model saved at epoch 2 with validation loss: 0.009090638543734802\n","Epoch [3/100], Training Loss: 0.007110771070507499\n","Epoch [3/100], Validation Loss: 0.011868832764359367\n","Epoch [4/100], Training Loss: 0.006184336319849882\n","Epoch [4/100], Validation Loss: 0.006798737244132687\n","Model saved at epoch 4 with validation loss: 0.006798737244132687\n","Epoch [5/100], Training Loss: 0.0054549514425335\n","Epoch [5/100], Validation Loss: 0.007431440960701784\n","Epoch [6/100], Training Loss: 0.0048228091685727816\n","Epoch [6/100], Validation Loss: 0.006723169088224613\n","Model saved at epoch 6 with validation loss: 0.006723169088224613\n","Epoch [7/100], Training Loss: 0.0048604436141388195\n","Epoch [7/100], Validation Loss: 0.005937016141158279\n","Model saved at epoch 7 with validation loss: 0.005937016141158279\n","Epoch [8/100], Training Loss: 0.004428445980123624\n","Epoch [8/100], Validation Loss: 0.005341091381681423\n","Model saved at epoch 8 with validation loss: 0.005341091381681423\n","Epoch [9/100], Training Loss: 0.004515380619635662\n","Epoch [9/100], Validation Loss: 0.005159255272865299\n","Model saved at epoch 9 with validation loss: 0.005159255272865299\n","Epoch [10/100], Training Loss: 0.004738508083236021\n","Epoch [10/100], Validation Loss: 0.010770061411089703\n","Epoch [11/100], Training Loss: 0.004516967284429744\n","Epoch [11/100], Validation Loss: 0.0054612008808263696\n","Epoch [12/100], Training Loss: 0.005383235320663343\n","Epoch [12/100], Validation Loss: 0.00538008313547922\n","Epoch [13/100], Training Loss: 0.004321411469174477\n","Epoch [13/100], Validation Loss: 0.006636288690080064\n","Epoch [14/100], Training Loss: 0.004322816496235083\n","Epoch [14/100], Validation Loss: 0.005032016253818919\n","Model saved at epoch 14 with validation loss: 0.005032016253818919\n","Epoch [15/100], Training Loss: 0.004152914528791977\n","Epoch [15/100], Validation Loss: 0.005577116494864697\n","Epoch [16/100], Training Loss: 0.004490910937740756\n","Epoch [16/100], Validation Loss: 0.005022609994410365\n","Model saved at epoch 16 with validation loss: 0.005022609994410365\n","Epoch [17/100], Training Loss: 0.004107555946150873\n","Epoch [17/100], Validation Loss: 0.0051025865709002595\n","Epoch [18/100], Training Loss: 0.004154553887864105\n","Epoch [18/100], Validation Loss: 0.004948728856664448\n","Model saved at epoch 18 with validation loss: 0.004948728856664448\n","Epoch [19/100], Training Loss: 0.004507677765316961\n","Epoch [19/100], Validation Loss: 0.005773928394916641\n","Epoch [20/100], Training Loss: 0.004057459127107861\n","Epoch [20/100], Validation Loss: 0.005051021960568315\n","Epoch [21/100], Training Loss: 0.004028602441364152\n","Epoch [21/100], Validation Loss: 0.005941249516414609\n","Epoch [22/100], Training Loss: 0.004226722590785704\n","Epoch [22/100], Validation Loss: 0.005230867323712483\n","Epoch [23/100], Training Loss: 0.003935826323461134\n","Epoch [23/100], Validation Loss: 0.005028815818082088\n","Epoch [24/100], Training Loss: 0.004320511730609377\n","Epoch [24/100], Validation Loss: 0.0049665060090994684\n","Epoch [25/100], Training Loss: 0.004101892390272475\n","Epoch [25/100], Validation Loss: 0.005313186829329369\n","Epoch [26/100], Training Loss: 0.00420452153472243\n","Epoch [26/100], Validation Loss: 0.004928454253294961\n","Model saved at epoch 26 with validation loss: 0.004928454253294961\n","Epoch [27/100], Training Loss: 0.0038683281061258597\n","Epoch [27/100], Validation Loss: 0.004910262601720165\n","Model saved at epoch 27 with validation loss: 0.004910262601720165\n","Epoch [28/100], Training Loss: 0.003942189638961022\n","Epoch [28/100], Validation Loss: 0.0050797929872906334\n","Epoch [29/100], Training Loss: 0.004049189056463763\n","Epoch [29/100], Validation Loss: 0.006542733571788725\n","Epoch [30/100], Training Loss: 0.004071389127624397\n","Epoch [30/100], Validation Loss: 0.004850061452267326\n","Model saved at epoch 30 with validation loss: 0.004850061452267326\n","Epoch [31/100], Training Loss: 0.003942802744179409\n","Epoch [31/100], Validation Loss: 0.0048661938831538526\n","Epoch [32/100], Training Loss: 0.003961169840009202\n","Epoch [32/100], Validation Loss: 0.004831490318188221\n","Model saved at epoch 32 with validation loss: 0.004831490318188221\n","Epoch [33/100], Training Loss: 0.004134402177795068\n","Epoch [33/100], Validation Loss: 0.004928249315015366\n","Epoch [34/100], Training Loss: 0.003819563938454199\n","Epoch [34/100], Validation Loss: 0.004842771333065155\n","Epoch [35/100], Training Loss: 0.003895096369132305\n","Epoch [35/100], Validation Loss: 0.0049124425757184455\n","Epoch [36/100], Training Loss: 0.003936171778247756\n","Epoch [36/100], Validation Loss: 0.004894234600960739\n","Epoch [37/100], Training Loss: 0.0039373079041762965\n","Epoch [37/100], Validation Loss: 0.007109309478986941\n","Epoch [38/100], Training Loss: 0.00388566870175661\n","Epoch [38/100], Validation Loss: 0.004814435047812753\n","Model saved at epoch 38 with validation loss: 0.004814435047812753\n","Epoch [39/100], Training Loss: 0.003827775241329402\n","Epoch [39/100], Validation Loss: 0.0048562401069167154\n","Epoch [40/100], Training Loss: 0.003810359276279823\n","Epoch [40/100], Validation Loss: 0.004841154364541593\n","Epoch [41/100], Training Loss: 0.00402805490731182\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m total_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient calculation\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val_inputs, val_labels \u001b[38;5;129;01min\u001b[39;00m valloader:\n\u001b[1;32m     37\u001b[0m         val_inputs_reduced \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(val_inputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m         val_inputs \u001b[38;5;241m=\u001b[39m val_inputs_reduced\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Send validation inputs to GPU if available\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py:418\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices: List[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[T_co]:\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m# add batched sampling support when parent dataset supports it.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m--> 418\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36mFMRI_Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m fmri_img\u001b[38;5;241m.\u001b[39mget_fdata()  \u001b[38;5;66;03m# Extract the fMRI data as a NumPy array\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Apply smoothing\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Normalize the data\u001b[39;00m\n\u001b[1;32m     20\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_data(data)\n","Cell \u001b[0;32mIn[13], line 55\u001b[0m, in \u001b[0;36mFMRI_Dataset.smooth_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msmooth_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply Gaussian smoothing to the data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mndimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmoothing_sigma\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/ndimage/_filters.py:368\u001b[0m, in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate, radius)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, sigma, order, mode, radius \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[0;32m--> 368\u001b[0m         \u001b[43mgaussian_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/ndimage/_filters.py:276\u001b[0m, in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[1;32m    275\u001b[0m weights \u001b[38;5;241m=\u001b[39m _gaussian_kernel1d(sigma, order, lw)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/ndimage/_filters.py:134\u001b[0m, in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid origin; origin must satisfy \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    131\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    132\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(len(weights)-1) // 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    133\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[0;32m--> 134\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                      \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Number of epochs\n","epochs = 100\n","\n","# Track the best validation loss\n","best_val_loss = float('inf')\n","\n","for epoch in range(epochs):\n","    # Training phase\n","    autoencoder.train()  # Set the model to training mode\n","    total_loss = 0.0\n","    for batch_idx, (inputs, labels) in enumerate(trainloader):\n","        inputs_reduced = torch.mean(inputs, dim=-1)\n","        inputs = inputs_reduced\n","\n","        inputs = inputs.to(device)  # Send to GPU if available\n","\n","        # Forward pass\n","        outputs = autoencoder(inputs)\n","        loss = criterion(outputs, inputs)  # Compare reconstruction with original input\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    # Calculate average training loss\n","    avg_train_loss = total_loss / len(trainloader)\n","    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {avg_train_loss}\")\n","\n","    # Validation phase\n","    autoencoder.eval()  # Set the model to evaluation mode\n","    total_val_loss = 0.0\n","    with torch.no_grad():  # Disable gradient calculation\n","        for val_inputs, val_labels in valloader:\n","            val_inputs_reduced = torch.mean(val_inputs, dim=-1)\n","            val_inputs = val_inputs_reduced.to(device)  # Send validation inputs to GPU if available\n","\n","            # Forward pass\n","            val_outputs = autoencoder(val_inputs)\n","            val_loss = criterion(val_outputs, val_inputs)  # Compare reconstruction with original input\n","            total_val_loss += val_loss.item()\n","\n","    # Calculate average validation loss\n","    avg_val_loss = total_val_loss / len(valloader)\n","    print(f\"Epoch [{epoch+1}/{epochs}], Validation Loss: {avg_val_loss}\")\n","\n","    # Save the model if the validation loss has decreased\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        torch.save(autoencoder.state_dict(), save_path)\n","        print(f\"Model saved at epoch {epoch+1} with validation loss: {avg_val_loss}\")\n","\n","# Final save after training\n","torch.save(autoencoder.state_dict(), save_path)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMaDGZjUjH0q9uGkEIfs8cd","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
