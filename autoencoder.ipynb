{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10713,"status":"ok","timestamp":1727205201330,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"JVxRWRFoXmzp"},"outputs":[],"source":["# Torch-related imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset, Subset\n","\n","# Scikit-learn-related imports\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","# Nibabel and Scipy imports (for handling fMRI and image processing)\n","import nibabel as nib\n","import scipy.ndimage as ndimage  # For smoothing\n","\n","# NumPy, Matplotlib, and Seaborn (for data manipulation and visualization)\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# OS for file system operations\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1727205204171,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"gbM8hGXtXr20","outputId":"86fdd20c-ff4d-4855-dcfa-081c4a820ec0"},"outputs":[],"source":["os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"Y6g2yk5jYDOY"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1350,"status":"ok","timestamp":1727205206943,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"nOOgfWGtXsiJ","outputId":"cc09d016-f527-47d8-df41-9d20ce946ae8"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# root_dir = os.path.join('/content/drive', 'My Drive', 'UCR', '2-2024', 'InvCC', 'ADHD200', 'Datasets', 'preprocessed')\n","\n","root_dir = os.path.join('preprocessed')\n","\n","# Carpetas para TDC y ADHD\n","tdc_dir = os.path.join(root_dir, 'TDC')\n","adhd_dir = os.path.join(root_dir, 'ADHD')\n","\n","# Para guardar el estado del autoencoder\n","save_path = os.path.join(root_dir, 'autoencoder_261024.pt')\n","\n","# Listas para almacenar las rutas de archivos\n","tdc_file_paths = [os.path.join(tdc_dir, file) for file in os.listdir(tdc_dir) if file.endswith('.nii.gz')]\n","adhd_file_paths = [os.path.join(adhd_dir, file) for file in os.listdir(adhd_dir) if file.endswith('.nii.gz')]\n","\n","# Etiquetas correspondientes\n","tdc_labels = [0] * len(tdc_file_paths)\n","adhd_labels = [1] * len(adhd_file_paths)\n","\n","# Combinar rutas de archivos y etiquetas\n","file_paths = tdc_file_paths + adhd_file_paths\n","labels = tdc_labels + adhd_labels"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1727205212587,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"l6rQM69NXyLm"},"outputs":[],"source":["class FMRI_Dataset(Dataset):\n","    def __init__(self, file_paths, labels, max_shape, smoothing_sigma=1):\n","        self.file_paths = file_paths  # List of paths to the fMRI data files\n","        self.labels = labels  # Corresponding labels\n","        self.max_shape = max_shape  # Shape to pad all inputs to\n","        self.smoothing_sigma = smoothing_sigma  # Standard deviation for Gaussian smoothing\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, idx):\n","        # Load fMRI data using NiBabel\n","        fmri_img = nib.load(self.file_paths[idx])\n","        data = fmri_img.get_fdata()  # Extract the fMRI data as a NumPy array\n","\n","        # Apply smoothing\n","        # data = self.smooth_data(data)\n","\n","        # Normalize the data\n","        data = self.normalize_data(data)\n","\n","        # Convert NumPy array to a PyTorch tensor\n","        data = torch.tensor(data, dtype=torch.float32)\n","\n","        # Get the label\n","        label = torch.tensor(self.labels[idx])\n","\n","        # Pad the tensor to the max_shape\n","        data_padded = F.pad(data, pad=self.calculate_padding(data.shape), mode='constant', value=0)\n","\n","        return data_padded, label\n","\n","    def calculate_padding(self, current_shape):\n","        padding = []\n","        for current_dim, max_dim in zip(reversed(current_shape), reversed(self.max_shape)):\n","            pad_total = max_dim - current_dim\n","            padding.append(pad_total // 2)  # pad_left or pad_top, etc.\n","            padding.append(pad_total - (pad_total // 2))  # pad_right or pad_bottom, etc.\n","\n","        return padding\n","\n","    def normalize_data(self, data):\n","        \"\"\"Normalize the data to zero mean and unit variance.\"\"\"\n","        mean = data.mean()\n","        std = data.std()\n","        if std > 0:  # Avoid division by zero\n","            data = (data - mean) / std\n","        return data\n","\n","    def smooth_data(self, data):\n","        \"\"\"Apply Gaussian smoothing to the data.\"\"\"\n","        return ndimage.gaussian_filter(data, sigma=self.smoothing_sigma)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1690,"status":"ok","timestamp":1727205217105,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"oNSAi-5rX3Pt","outputId":"6aa5e157-c2da-4190-a96d-15b000d70ec4"},"outputs":[],"source":["# Determine the maximum shape across all tensors\n","max_shape = [1, 53, 64, 46, 512]\n","\n","# Create the dataset with padded tensors\n","dataset = FMRI_Dataset(file_paths, labels, max_shape)\n","\n","sample_data, sample_label = dataset[0]\n","print(sample_data.shape, sample_label)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10228,"status":"ok","timestamp":1727205249449,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"VuxrLbWOX5uj"},"outputs":[],"source":["# Crear el objeto StratifiedShuffleSplit para dividir en conjuntos de entrenamiento y prueba\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n","\n","# Dividir en entrenamiento y prueba\n","for train_val_idx, test_idx in sss.split(range(len(dataset)), dataset.labels):\n","    train_val_set = torch.utils.data.Subset(dataset, train_val_idx)\n","    testset = torch.utils.data.Subset(dataset, test_idx)\n","\n","# Ahora crear un segundo StratifiedShuffleSplit para los conjuntos de entrenamiento y validación\n","sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)  # 0.25 de 0.8 es 0.2 total para validación\n","\n","# Acceder a las etiquetas del conjunto de entrenamiento y validación\n","train_val_labels = [dataset.labels[i] for i in train_val_idx]  # Obtener las etiquetas usando una lista de comprensión\n","\n","for train_idx, val_idx in sss_val.split(range(len(train_val_set)), train_val_labels):\n","    trainset = torch.utils.data.Subset(train_val_set, train_idx)\n","    valset = torch.utils.data.Subset(train_val_set, val_idx)\n","\n","# Crear los dataloaders\n","batch_size = 1\n","trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n","valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=0)\n","testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n","\n","class_names = [\"TDC\", \"ADHD\"]\n","\n","# Iterate over the dataloaders to verify they are being processed correctly\n","for batch in trainloader:\n","    if batch[0] is not None:\n","        images, _ = batch\n","        break\n","        # print(f\"Shape of inputs: {images.shape}, Shape of labels: {_}\")\n","\n","\n","for batch in testloader:\n","    if batch[0] is not None:\n","        images, _ = batch\n","        break\n","        # print(f\"Shape of inputs: {images.shape}, Shape of labels: {_}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1727205253990,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"ElUPKRG4X7m9","outputId":"1e7cfc3d-4985-4eec-b14d-f66a5025d64e"},"outputs":[],"source":["print(f\"Number of samples in valloader: {len(valloader.dataset)}\")\n","print(f\"Number of samples in trainloader: {len(trainloader.dataset)}\")\n","print(f\"Number of samples in testloader: {len(testloader.dataset)}\")"]},{"cell_type":"markdown","metadata":{"id":"O8foNAGnYHdv"},"source":["# CNN-AE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2468,"status":"ok","timestamp":1727205276496,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"3mG-7GH_YKAO","outputId":"19a7bdcb-b596-48f5-ebe2-14332a68922d"},"outputs":[],"source":["class CNN_Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(CNN_Autoencoder, self).__init__()\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv3d(1, 16, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Dropout3d(0.2),\n","            nn.Conv3d(16, 64, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Dropout3d(0.2),\n","            nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Dropout3d(0.2),\n","            nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose3d(256, 128, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(0, 1, 0)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(1, 0, 1)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(64, 16, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 0, 1)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 1, 1)),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","\n","# Example usage\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","autoencoder = CNN_Autoencoder().to(device)\n","\n","# Generate random input matching new shape [1, 1, 53, 64] (Batch size 1)\n","inputs = torch.rand((1, 53, 64, 46)).to(device)  # Example input\n","output = autoencoder(inputs)\n","print(output.shape)  # should match the input shape [1, 53, 64, 46]\n","\n","# Loss and optimizer\n","criterion = nn.MSELoss()  # Since it's an autoencoder, Mean Squared Error is commonly used\n","optimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHZ6Bjm4YMCa","outputId":"f0d69c64-f5a9-44fa-88bc-75d50fdf19cc"},"outputs":[],"source":["# Number of epochs\n","epochs = 100\n","\n","# Track the best validation loss\n","best_val_loss = float('inf')\n","\n","for epoch in range(epochs):\n","    # Training phase\n","    autoencoder.train()  # Set the model to training mode\n","    total_loss = 0.0\n","    for batch_idx, (inputs, labels) in enumerate(trainloader):\n","        inputs_reduced = torch.mean(inputs, dim=-1)\n","        inputs = inputs_reduced\n","\n","        inputs = inputs.to(device)  # Send to GPU if available\n","\n","        # Forward pass\n","        outputs = autoencoder(inputs)\n","        loss = criterion(outputs, inputs)  # Compare reconstruction with original input\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    # Calculate average training loss\n","    avg_train_loss = total_loss / len(trainloader)\n","    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {avg_train_loss}\")\n","\n","    # Validation phase\n","    autoencoder.eval()  # Set the model to evaluation mode\n","    total_val_loss = 0.0\n","    with torch.no_grad():  # Disable gradient calculation\n","        for val_inputs, val_labels in valloader:\n","            val_inputs_reduced = torch.mean(val_inputs, dim=-1)\n","            val_inputs = val_inputs_reduced.to(device)  # Send validation inputs to GPU if available\n","\n","            # Forward pass\n","            val_outputs = autoencoder(val_inputs)\n","            val_loss = criterion(val_outputs, val_inputs)  # Compare reconstruction with original input\n","            total_val_loss += val_loss.item()\n","\n","    # Calculate average validation loss\n","    avg_val_loss = total_val_loss / len(valloader)\n","    print(f\"Epoch [{epoch+1}/{epochs}], Validation Loss: {avg_val_loss}\")\n","\n","    # Save the model if the validation loss has decreased\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        torch.save(autoencoder.state_dict(), save_path)\n","        print(f\"Model saved at epoch {epoch+1} with validation loss: {avg_val_loss}\")\n","\n","# Final save after training\n","torch.save(autoencoder.state_dict(), save_path)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMaDGZjUjH0q9uGkEIfs8cd","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
