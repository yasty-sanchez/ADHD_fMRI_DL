{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10713,"status":"ok","timestamp":1727205201330,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"JVxRWRFoXmzp"},"outputs":[],"source":["# Torch-related imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset, Subset\n","\n","# Scikit-learn-related imports\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","# Nibabel and Scipy imports (for handling fMRI and image processing)\n","import nibabel as nib\n","import scipy.ndimage as ndimage  # For smoothing\n","\n","# NumPy, Matplotlib, and Seaborn (for data manipulation and visualization)\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# OS for file system operations\n","import os"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1727205204171,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"gbM8hGXtXr20","outputId":"86fdd20c-ff4d-4855-dcfa-081c4a820ec0"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"Y6g2yk5jYDOY"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1350,"status":"ok","timestamp":1727205206943,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"nOOgfWGtXsiJ","outputId":"cc09d016-f527-47d8-df41-9d20ce946ae8"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# root_dir = os.path.join('/content/drive', 'My Drive', 'UCR', '2-2024', 'InvCC', 'ADHD200', 'Datasets', 'preprocessed')\n","\n","root_dir = os.path.join('preprocessed')\n","\n","# Carpetas para TDC y ADHD\n","tdc_dir = os.path.join(root_dir, 'TDC')\n","adhd_dir = os.path.join(root_dir, 'ADHD')\n","\n","# Para guardar el estado del autoencoder\n","save_path = os.path.join(root_dir, 'autoencoder.pt')\n","\n","# Listas para almacenar las rutas de archivos\n","tdc_file_paths = [os.path.join(tdc_dir, file) for file in os.listdir(tdc_dir) if file.endswith('.nii.gz')]\n","adhd_file_paths = [os.path.join(adhd_dir, file) for file in os.listdir(adhd_dir) if file.endswith('.nii.gz')]\n","\n","# Etiquetas correspondientes\n","tdc_labels = [0] * len(tdc_file_paths)\n","adhd_labels = [1] * len(adhd_file_paths)\n","\n","# Combinar rutas de archivos y etiquetas\n","file_paths = tdc_file_paths + adhd_file_paths\n","labels = tdc_labels + adhd_labels"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1727205212587,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"l6rQM69NXyLm"},"outputs":[],"source":["class FMRI_Dataset(Dataset):\n","    def __init__(self, file_paths, labels, max_shape, smoothing_sigma=1):\n","        self.file_paths = file_paths  # List of paths to the fMRI data files\n","        self.labels = labels  # Corresponding labels\n","        self.max_shape = max_shape  # Shape to pad all inputs to\n","        self.smoothing_sigma = smoothing_sigma  # Standard deviation for Gaussian smoothing\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, idx):\n","        # Load fMRI data using NiBabel\n","        fmri_img = nib.load(self.file_paths[idx])\n","        data = fmri_img.get_fdata()  # Extract the fMRI data as a NumPy array\n","\n","        # Apply smoothing\n","        # data = self.smooth_data(data)\n","\n","        # Normalize the data\n","        data = self.normalize_data(data)\n","\n","        # Convert NumPy array to a PyTorch tensor\n","        data = torch.tensor(data, dtype=torch.float32)\n","\n","        # Get the label\n","        label = torch.tensor(self.labels[idx])\n","\n","        # Pad the tensor to the max_shape\n","        data_padded = F.pad(data, pad=self.calculate_padding(data.shape), mode='constant', value=0)\n","\n","        return data_padded, label\n","\n","    def calculate_padding(self, current_shape):\n","        padding = []\n","        for current_dim, max_dim in zip(reversed(current_shape), reversed(self.max_shape)):\n","            pad_total = max_dim - current_dim\n","            padding.append(pad_total // 2)  # pad_left or pad_top, etc.\n","            padding.append(pad_total - (pad_total // 2))  # pad_right or pad_bottom, etc.\n","\n","        return padding\n","\n","    def normalize_data(self, data):\n","        \"\"\"Normalize the data to zero mean and unit variance.\"\"\"\n","        mean = data.mean()\n","        std = data.std()\n","        if std > 0:  # Avoid division by zero\n","            data = (data - mean) / std\n","        return data\n","\n","    def smooth_data(self, data):\n","        \"\"\"Apply Gaussian smoothing to the data.\"\"\"\n","        return ndimage.gaussian_filter(data, sigma=self.smoothing_sigma)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1690,"status":"ok","timestamp":1727205217105,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"oNSAi-5rX3Pt","outputId":"6aa5e157-c2da-4190-a96d-15b000d70ec4"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([53, 64, 46, 512]) tensor(0)\n"]}],"source":["# Determine the maximum shape across all tensors\n","max_shape = [1, 53, 64, 46, 512]\n","\n","# Create the dataset with padded tensors\n","dataset = FMRI_Dataset(file_paths, labels, max_shape)\n","\n","sample_data, sample_label = dataset[0]\n","print(sample_data.shape, sample_label)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10228,"status":"ok","timestamp":1727205249449,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"VuxrLbWOX5uj"},"outputs":[],"source":["# Crear el objeto StratifiedShuffleSplit para dividir en conjuntos de entrenamiento y prueba\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n","\n","# Dividir en entrenamiento y prueba\n","for train_val_idx, test_idx in sss.split(range(len(dataset)), dataset.labels):\n","    train_val_set = torch.utils.data.Subset(dataset, train_val_idx)\n","    testset = torch.utils.data.Subset(dataset, test_idx)\n","\n","# Ahora crear un segundo StratifiedShuffleSplit para los conjuntos de entrenamiento y validación\n","sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)  # 0.25 de 0.8 es 0.2 total para validación\n","\n","# Acceder a las etiquetas del conjunto de entrenamiento y validación\n","train_val_labels = [dataset.labels[i] for i in train_val_idx]  # Obtener las etiquetas usando una lista de comprensión\n","\n","for train_idx, val_idx in sss_val.split(range(len(train_val_set)), train_val_labels):\n","    trainset = torch.utils.data.Subset(train_val_set, train_idx)\n","    valset = torch.utils.data.Subset(train_val_set, val_idx)\n","\n","# Crear los dataloaders\n","batch_size = 1\n","trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n","valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=0)\n","testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n","\n","class_names = [\"TDC\", \"ADHD\"]\n","\n","# Iterate over the dataloaders to verify they are being processed correctly\n","for batch in trainloader:\n","    if batch[0] is not None:\n","        images, _ = batch\n","        break\n","        # print(f\"Shape of inputs: {images.shape}, Shape of labels: {_}\")\n","\n","\n","for batch in testloader:\n","    if batch[0] is not None:\n","        images, _ = batch\n","        break\n","        # print(f\"Shape of inputs: {images.shape}, Shape of labels: {_}\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1727205253990,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"ElUPKRG4X7m9","outputId":"1e7cfc3d-4985-4eec-b14d-f66a5025d64e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of samples in valloader: 34\n","Number of samples in trainloader: 102\n","Number of samples in testloader: 34\n"]}],"source":["print(f\"Number of samples in valloader: {len(valloader.dataset)}\")\n","print(f\"Number of samples in trainloader: {len(trainloader.dataset)}\")\n","print(f\"Number of samples in testloader: {len(testloader.dataset)}\")"]},{"cell_type":"markdown","metadata":{"id":"O8foNAGnYHdv"},"source":["# CNN-AE"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2468,"status":"ok","timestamp":1727205276496,"user":{"displayName":"Yasty Sánchez","userId":"01336246420740504937"},"user_tz":360},"id":"3mG-7GH_YKAO","outputId":"19a7bdcb-b596-48f5-ebe2-14332a68922d"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 53, 64, 46])\n"]}],"source":["class CNN_Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(CNN_Autoencoder, self).__init__()\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv3d(1, 16, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv3d(16, 64, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(),\n","        )\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose3d(256, 128, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(0, 1, 0)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(1, 0, 1)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(64, 16, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 0, 1)),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 1, 1)),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","\n","# Example usage\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","autoencoder = CNN_Autoencoder().to(device)\n","\n","# Generate random input matching new shape [1, 1, 53, 64] (Batch size 1)\n","inputs = torch.rand((1, 53, 64, 46)).to(device)  # Example input\n","output = autoencoder(inputs)\n","print(output.shape)  # should match the input shape [1, 53, 64, 46]\n","\n","# Loss and optimizer\n","criterion = nn.MSELoss()  # Since it's an autoencoder, Mean Squared Error is commonly used\n","optimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHZ6Bjm4YMCa","outputId":"f0d69c64-f5a9-44fa-88bc-75d50fdf19cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Training Loss: 0.21296265403575756\n","Epoch [1/100], Validation Loss: 0.1888777820722145\n","Model saved at epoch 1 with validation loss: 0.1888777820722145\n","Epoch [2/100], Training Loss: 0.18055056039170891\n","Epoch [2/100], Validation Loss: 0.18452430724659385\n","Model saved at epoch 2 with validation loss: 0.18452430724659385\n","Epoch [3/100], Training Loss: 0.1748296212697146\n","Epoch [3/100], Validation Loss: 0.1775870112811818\n","Model saved at epoch 3 with validation loss: 0.1775870112811818\n","Epoch [4/100], Training Loss: 0.16804118377759175\n","Epoch [4/100], Validation Loss: 0.1712330775883268\n","Model saved at epoch 4 with validation loss: 0.1712330775883268\n","Epoch [5/100], Training Loss: 0.16233770326510363\n","Epoch [5/100], Validation Loss: 0.15772201175637104\n","Model saved at epoch 5 with validation loss: 0.15772201175637104\n","Epoch [6/100], Training Loss: 0.10574673444909208\n","Epoch [6/100], Validation Loss: 0.09358729822013308\n","Model saved at epoch 6 with validation loss: 0.09358729822013308\n","Epoch [7/100], Training Loss: 0.0884257063415705\n","Epoch [7/100], Validation Loss: 0.08783767295672613\n","Model saved at epoch 7 with validation loss: 0.08783767295672613\n","Epoch [8/100], Training Loss: 0.08438700705985813\n","Epoch [8/100], Validation Loss: 0.08519248297328458\n","Model saved at epoch 8 with validation loss: 0.08519248297328458\n","Epoch [9/100], Training Loss: 0.08218467922187318\n","Epoch [9/100], Validation Loss: 0.08613372205153984\n","Epoch [10/100], Training Loss: 0.08076068043124442\n","Epoch [10/100], Validation Loss: 0.08174181033802383\n","Model saved at epoch 10 with validation loss: 0.08174181033802383\n","Epoch [11/100], Training Loss: 0.07883318785724103\n","Epoch [11/100], Validation Loss: 0.08019915672347826\n","Model saved at epoch 11 with validation loss: 0.08019915672347826\n","Epoch [12/100], Training Loss: 0.07765519272024725\n","Epoch [12/100], Validation Loss: 0.0794262486126493\n","Model saved at epoch 12 with validation loss: 0.0794262486126493\n","Epoch [13/100], Training Loss: 0.07671141578797616\n","Epoch [13/100], Validation Loss: 0.07831177290748148\n","Model saved at epoch 13 with validation loss: 0.07831177290748148\n","Epoch [14/100], Training Loss: 0.07581277803390049\n","Epoch [14/100], Validation Loss: 0.0771996443543364\n","Model saved at epoch 14 with validation loss: 0.0771996443543364\n","Epoch [15/100], Training Loss: 0.07479631699913857\n","Epoch [15/100], Validation Loss: 0.07623098883777857\n","Model saved at epoch 15 with validation loss: 0.07623098883777857\n","Epoch [16/100], Training Loss: 0.07423742544636422\n","Epoch [16/100], Validation Loss: 0.07545621753396357\n","Model saved at epoch 16 with validation loss: 0.07545621753396357\n","Epoch [17/100], Training Loss: 0.07324758361951977\n","Epoch [17/100], Validation Loss: 0.07487370271016569\n","Model saved at epoch 17 with validation loss: 0.07487370271016569\n","Epoch [18/100], Training Loss: 0.0724619490587536\n","Epoch [18/100], Validation Loss: 0.07394989503218848\n","Model saved at epoch 18 with validation loss: 0.07394989503218848\n","Epoch [19/100], Training Loss: 0.07221769707679164\n","Epoch [19/100], Validation Loss: 0.07344282177441261\n","Model saved at epoch 19 with validation loss: 0.07344282177441261\n","Epoch [20/100], Training Loss: 0.07126490003885884\n","Epoch [20/100], Validation Loss: 0.07301067599259756\n","Model saved at epoch 20 with validation loss: 0.07301067599259756\n","Epoch [21/100], Training Loss: 0.07057259927558548\n","Epoch [21/100], Validation Loss: 0.0729827529969899\n","Model saved at epoch 21 with validation loss: 0.0729827529969899\n","Epoch [22/100], Training Loss: 0.07010248642159152\n","Epoch [22/100], Validation Loss: 0.07184574347646798\n","Model saved at epoch 22 with validation loss: 0.07184574347646798\n","Epoch [23/100], Training Loss: 0.06941150283148768\n","Epoch [23/100], Validation Loss: 0.0710899592103327\n","Model saved at epoch 23 with validation loss: 0.0710899592103327\n","Epoch [24/100], Training Loss: 0.06937157141738663\n","Epoch [24/100], Validation Loss: 0.07121733844499378\n","Epoch [25/100], Training Loss: 0.06852080454757693\n","Epoch [25/100], Validation Loss: 0.07031195482019992\n","Model saved at epoch 25 with validation loss: 0.07031195482019992\n","Epoch [26/100], Training Loss: 0.06810680457263016\n","Epoch [26/100], Validation Loss: 0.06963978261303376\n","Model saved at epoch 26 with validation loss: 0.06963978261303376\n","Epoch [27/100], Training Loss: 0.06767025309633098\n","Epoch [27/100], Validation Loss: 0.06948750178493998\n","Model saved at epoch 27 with validation loss: 0.06948750178493998\n","Epoch [28/100], Training Loss: 0.06710627191133943\n","Epoch [28/100], Validation Loss: 0.0688719815465019\n","Model saved at epoch 28 with validation loss: 0.0688719815465019\n","Epoch [29/100], Training Loss: 0.0667109171695569\n","Epoch [29/100], Validation Loss: 0.0684653865173459\n","Model saved at epoch 29 with validation loss: 0.0684653865173459\n","Epoch [30/100], Training Loss: 0.06644416023411003\n","Epoch [30/100], Validation Loss: 0.06794753917219008\n","Model saved at epoch 30 with validation loss: 0.06794753917219008\n","Epoch [31/100], Training Loss: 0.0660189232953331\n","Epoch [31/100], Validation Loss: 0.06754153410849326\n","Model saved at epoch 31 with validation loss: 0.06754153410849326\n","Epoch [32/100], Training Loss: 0.06571912415800434\n","Epoch [32/100], Validation Loss: 0.06753627742257189\n","Model saved at epoch 32 with validation loss: 0.06753627742257189\n","Epoch [33/100], Training Loss: 0.0655132829503832\n","Epoch [33/100], Validation Loss: 0.06703038680750657\n","Model saved at epoch 33 with validation loss: 0.06703038680750657\n","Epoch [34/100], Training Loss: 0.06509175203631029\n","Epoch [34/100], Validation Loss: 0.06665211707791861\n","Model saved at epoch 34 with validation loss: 0.06665211707791861\n","Epoch [35/100], Training Loss: 0.06467552605432038\n","Epoch [35/100], Validation Loss: 0.0664314528762856\n","Model saved at epoch 35 with validation loss: 0.0664314528762856\n","Epoch [36/100], Training Loss: 0.06454221014042988\n","Epoch [36/100], Validation Loss: 0.0681953541112735\n","Epoch [37/100], Training Loss: 0.06436929816161008\n","Epoch [37/100], Validation Loss: 0.06596077192465172\n","Model saved at epoch 37 with validation loss: 0.06596077192465172\n","Epoch [38/100], Training Loss: 0.06405103792819906\n","Epoch [38/100], Validation Loss: 0.0658451678669628\n","Model saved at epoch 38 with validation loss: 0.0658451678669628\n","Epoch [39/100], Training Loss: 0.06376536822348249\n","Epoch [39/100], Validation Loss: 0.06563022943651851\n","Model saved at epoch 39 with validation loss: 0.06563022943651851\n","Epoch [40/100], Training Loss: 0.06356103658931804\n","Epoch [40/100], Validation Loss: 0.06537776878651451\n","Model saved at epoch 40 with validation loss: 0.06537776878651451\n","Epoch [41/100], Training Loss: 0.06326039137282208\n","Epoch [41/100], Validation Loss: 0.06533646463033031\n","Model saved at epoch 41 with validation loss: 0.06533646463033031\n","Epoch [42/100], Training Loss: 0.06319763976167522\n","Epoch [42/100], Validation Loss: 0.06488458080874647\n","Model saved at epoch 42 with validation loss: 0.06488458080874647\n","Epoch [43/100], Training Loss: 0.06281199979175832\n","Epoch [43/100], Validation Loss: 0.0645533459918464\n","Model saved at epoch 43 with validation loss: 0.0645533459918464\n","Epoch [44/100], Training Loss: 0.06271892903810915\n","Epoch [44/100], Validation Loss: 0.06432309404344243\n","Model saved at epoch 44 with validation loss: 0.06432309404344243\n","Epoch [45/100], Training Loss: 0.06262694981277865\n","Epoch [45/100], Validation Loss: 0.06435017178163809\n","Epoch [46/100], Training Loss: 0.06229448727532929\n","Epoch [46/100], Validation Loss: 0.06399307717733524\n","Model saved at epoch 46 with validation loss: 0.06399307717733524\n","Epoch [47/100], Training Loss: 0.062205803279271894\n","Epoch [47/100], Validation Loss: 0.0641490078312071\n","Epoch [48/100], Training Loss: 0.06215349108199863\n","Epoch [48/100], Validation Loss: 0.0637770811753238\n","Model saved at epoch 48 with validation loss: 0.0637770811753238\n","Epoch [49/100], Training Loss: 0.06191934951051485\n","Epoch [49/100], Validation Loss: 0.06368190680137452\n","Model saved at epoch 49 with validation loss: 0.06368190680137452\n","Epoch [50/100], Training Loss: 0.061665049681038246\n","Epoch [50/100], Validation Loss: 0.06427807254059349\n","Epoch [51/100], Training Loss: 0.06182009156099429\n","Epoch [51/100], Validation Loss: 0.06422436859129983\n","Epoch [52/100], Training Loss: 0.06230487158595055\n","Epoch [52/100], Validation Loss: 0.0637730271281565\n","Epoch [53/100], Training Loss: 0.06147359054097358\n","Epoch [53/100], Validation Loss: 0.06310704273774344\n","Model saved at epoch 53 with validation loss: 0.06310704273774344\n","Epoch [54/100], Training Loss: 0.061237492151193174\n","Epoch [54/100], Validation Loss: 0.0630656213444822\n","Model saved at epoch 54 with validation loss: 0.0630656213444822\n","Epoch [55/100], Training Loss: 0.06144880047798449\n","Epoch [55/100], Validation Loss: 0.06308482064153342\n","Epoch [56/100], Training Loss: 0.061176515120428564\n","Epoch [56/100], Validation Loss: 0.06386119475149933\n","Epoch [57/100], Training Loss: 0.06106256682644872\n","Epoch [57/100], Validation Loss: 0.06273897008641678\n","Model saved at epoch 57 with validation loss: 0.06273897008641678\n","Epoch [58/100], Training Loss: 0.06099734227081724\n","Epoch [58/100], Validation Loss: 0.06267971824854612\n","Model saved at epoch 58 with validation loss: 0.06267971824854612\n","Epoch [59/100], Training Loss: 0.06193158668739831\n","Epoch [59/100], Validation Loss: 0.0639299362185685\n","Epoch [60/100], Training Loss: 0.06098870747704424\n","Epoch [60/100], Validation Loss: 0.06254081677316743\n","Model saved at epoch 60 with validation loss: 0.06254081677316743\n","Epoch [61/100], Training Loss: 0.06080662223565228\n","Epoch [61/100], Validation Loss: 0.06254211613251005\n","Epoch [62/100], Training Loss: 0.06066765417984011\n","Epoch [62/100], Validation Loss: 0.06245557777583599\n","Model saved at epoch 62 with validation loss: 0.06245557777583599\n","Epoch [63/100], Training Loss: 0.06055599310453616\n","Epoch [63/100], Validation Loss: 0.06246489023461061\n","Epoch [64/100], Training Loss: 0.06057676468409744\n","Epoch [64/100], Validation Loss: 0.06229141625740072\n","Model saved at epoch 64 with validation loss: 0.06229141625740072\n","Epoch [65/100], Training Loss: 0.0605218066724346\n","Epoch [65/100], Validation Loss: 0.06224488395759288\n","Model saved at epoch 65 with validation loss: 0.06224488395759288\n","Epoch [66/100], Training Loss: 0.06050962066350907\n","Epoch [66/100], Validation Loss: 0.06215067980263163\n","Model saved at epoch 66 with validation loss: 0.06215067980263163\n","Epoch [67/100], Training Loss: 0.06057777664825028\n","Epoch [67/100], Validation Loss: 0.06220926582703695\n","Epoch [68/100], Training Loss: 0.060298816784851106\n","Epoch [68/100], Validation Loss: 0.06218803915030816\n","Epoch [69/100], Training Loss: 0.060433537215359656\n","Epoch [69/100], Validation Loss: 0.06282674288377166\n","Epoch [70/100], Training Loss: 0.06045263176601307\n","Epoch [70/100], Validation Loss: 0.062219576006207394\n","Epoch [71/100], Training Loss: 0.06037730082650395\n","Epoch [71/100], Validation Loss: 0.06259555076522862\n","Epoch [72/100], Training Loss: 0.060582536154006626\n","Epoch [72/100], Validation Loss: 0.06192026854328373\n","Model saved at epoch 72 with validation loss: 0.06192026854328373\n","Epoch [73/100], Training Loss: 0.06015827604478188\n","Epoch [73/100], Validation Loss: 0.06190134842387017\n","Model saved at epoch 73 with validation loss: 0.06190134842387017\n","Epoch [74/100], Training Loss: 0.05999728781627674\n","Epoch [74/100], Validation Loss: 0.06183924150707967\n","Model saved at epoch 74 with validation loss: 0.06183924150707967\n","Epoch [75/100], Training Loss: 0.060730875834968744\n","Epoch [75/100], Validation Loss: 0.06202733346863704\n","Epoch [76/100], Training Loss: 0.06017025538227137\n","Epoch [76/100], Validation Loss: 0.06205225259284763\n","Epoch [77/100], Training Loss: 0.06013833372579778\n","Epoch [77/100], Validation Loss: 0.0620417926898774\n","Epoch [78/100], Training Loss: 0.06007636676305065\n","Epoch [78/100], Validation Loss: 0.06185517879202962\n","Epoch [79/100], Training Loss: 0.05988316186795048\n","Epoch [79/100], Validation Loss: 0.06164443413453067\n","Model saved at epoch 79 with validation loss: 0.06164443413453067\n","Epoch [80/100], Training Loss: 0.0599557735372846\n","Epoch [80/100], Validation Loss: 0.06173354954294422\n","Epoch [81/100], Training Loss: 0.060027767703229304\n","Epoch [81/100], Validation Loss: 0.06173910841564922\n","Epoch [82/100], Training Loss: 0.05986626522944254\n","Epoch [82/100], Validation Loss: 0.06159843452384367\n","Model saved at epoch 82 with validation loss: 0.06159843452384367\n","Epoch [83/100], Training Loss: 0.05970484510465872\n","Epoch [83/100], Validation Loss: 0.06157954658984261\n","Model saved at epoch 83 with validation loss: 0.06157954658984261\n","Epoch [84/100], Training Loss: 0.059770711533286995\n","Epoch [84/100], Validation Loss: 0.06175433354013983\n","Epoch [85/100], Training Loss: 0.059947218910297924\n","Epoch [85/100], Validation Loss: 0.06155749728136203\n","Model saved at epoch 85 with validation loss: 0.06155749728136203\n","Epoch [86/100], Training Loss: 0.05975741568916276\n","Epoch [86/100], Validation Loss: 0.06177829696303781\n","Epoch [87/100], Training Loss: 0.059620264104987476\n","Epoch [87/100], Validation Loss: 0.061601800104493606\n","Epoch [88/100], Training Loss: 0.05975261725960117\n","Epoch [88/100], Validation Loss: 0.061457086765371705\n","Model saved at epoch 88 with validation loss: 0.061457086765371705\n","Epoch [89/100], Training Loss: 0.059656791525947696\n","Epoch [89/100], Validation Loss: 0.061421127085957455\n","Model saved at epoch 89 with validation loss: 0.061421127085957455\n","Epoch [90/100], Training Loss: 0.059647882192888683\n","Epoch [90/100], Validation Loss: 0.06143058242057176\n","Epoch [91/100], Training Loss: 0.05972755242906073\n","Epoch [91/100], Validation Loss: 0.061438846785356015\n","Epoch [92/100], Training Loss: 0.05961664705811178\n","Epoch [92/100], Validation Loss: 0.061719903421095186\n","Epoch [93/100], Training Loss: 0.05959375689317491\n","Epoch [93/100], Validation Loss: 0.06128967320546508\n","Model saved at epoch 93 with validation loss: 0.06128967320546508\n","Epoch [94/100], Training Loss: 0.05947550293058157\n","Epoch [94/100], Validation Loss: 0.061288195881335175\n","Model saved at epoch 94 with validation loss: 0.061288195881335175\n","Epoch [95/100], Training Loss: 0.059501004213576805\n","Epoch [95/100], Validation Loss: 0.06130053020794602\n","Epoch [96/100], Training Loss: 0.05970424644685551\n","Epoch [96/100], Validation Loss: 0.06130417422665393\n","Epoch [97/100], Training Loss: 0.0596232638858697\n","Epoch [97/100], Validation Loss: 0.06122866081183448\n","Model saved at epoch 97 with validation loss: 0.06122866081183448\n","Epoch [98/100], Training Loss: 0.05943849509326266\n","Epoch [98/100], Validation Loss: 0.06130059290786877\n","Epoch [99/100], Training Loss: 0.059474602843835656\n","Epoch [99/100], Validation Loss: 0.061184991397621\n","Model saved at epoch 99 with validation loss: 0.061184991397621\n","Epoch [100/100], Training Loss: 0.060252837033248414\n","Epoch [100/100], Validation Loss: 0.06191226311356706\n"]}],"source":["# Number of epochs\n","epochs = 100\n","\n","# Track the best validation loss\n","best_val_loss = float('inf')\n","\n","for epoch in range(epochs):\n","    # Training phase\n","    autoencoder.train()  # Set the model to training mode\n","    total_loss = 0.0\n","    for batch_idx, (inputs, labels) in enumerate(trainloader):\n","        inputs_reduced = torch.mean(inputs, dim=-1)\n","        inputs = inputs_reduced\n","\n","        inputs = inputs.to(device)  # Send to GPU if available\n","\n","        # Forward pass\n","        outputs = autoencoder(inputs)\n","        loss = criterion(outputs, inputs)  # Compare reconstruction with original input\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    # Calculate average training loss\n","    avg_train_loss = total_loss / len(trainloader)\n","    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {avg_train_loss}\")\n","\n","    # Validation phase\n","    autoencoder.eval()  # Set the model to evaluation mode\n","    total_val_loss = 0.0\n","    with torch.no_grad():  # Disable gradient calculation\n","        for val_inputs, val_labels in valloader:\n","            val_inputs_reduced = torch.mean(val_inputs, dim=-1)\n","            val_inputs = val_inputs_reduced.to(device)  # Send validation inputs to GPU if available\n","\n","            # Forward pass\n","            val_outputs = autoencoder(val_inputs)\n","            val_loss = criterion(val_outputs, val_inputs)  # Compare reconstruction with original input\n","            total_val_loss += val_loss.item()\n","\n","    # Calculate average validation loss\n","    avg_val_loss = total_val_loss / len(valloader)\n","    print(f\"Epoch [{epoch+1}/{epochs}], Validation Loss: {avg_val_loss}\")\n","\n","    # Save the model if the validation loss has decreased\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        torch.save(autoencoder.state_dict(), save_path)\n","        print(f\"Model saved at epoch {epoch+1} with validation loss: {avg_val_loss}\")\n","\n","# Final save after training\n","torch.save(autoencoder.state_dict(), save_path)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMaDGZjUjH0q9uGkEIfs8cd","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
