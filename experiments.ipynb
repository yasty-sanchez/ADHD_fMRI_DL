{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GWvNv3IrQtwK"
   },
   "outputs": [],
   "source": [
    "# Torch-related imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "# Scikit-learn-related imports\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Nibabel and Scipy imports (for handling fMRI and image processing)\n",
    "import nibabel as nib\n",
    "import scipy.ndimage as ndimage  # For smoothing\n",
    "\n",
    "# NumPy, Matplotlib, and Seaborn (for data manipulation and visualization)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# OS for file system operations\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1729905899637,
     "user": {
      "displayName": "Yasty Sánchez",
      "userId": "01336246420740504937"
     },
     "user_tz": 360
    },
    "id": "PBnx2TrBRAvy",
    "outputId": "7abe6154-a5d7-4cdc-b770-78d6db615511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3693,
     "status": "ok",
     "timestamp": 1729906065409,
     "user": {
      "displayName": "Yasty Sánchez",
      "userId": "01336246420740504937"
     },
     "user_tz": 360
    },
    "id": "ELtPOdZYQ9ny",
    "outputId": "2975f1d9-50c4-42d0-ca16-e5c337366126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total file paths: 5100\n",
      "Total labels: 5100\n",
      "Class weights:  tensor([0.8004, 1.3323], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# root_dir = os.path.join('/content/drive', 'My Drive', 'UCR', '2-2024', 'InvCC', 'ADHD200', 'Datasets', 'preprocessed')\n",
    "\n",
    "import os\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "root_dir = os.path.join('data', 'preprocessed')\n",
    "\n",
    "tdc_dir = os.path.join(root_dir, 'TDC')\n",
    "adhd_dir = os.path.join(root_dir, 'ADHD')\n",
    "\n",
    "# To save autoencoder state dict\n",
    "save_path = os.path.join(root_dir, 'autoencoder.pt')\n",
    "\n",
    "# Recursively find all .nii.gz files in TDC and ADHD folders\n",
    "tdc_file_paths = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(tdc_dir)\n",
    "    for file in files if file.endswith('.nii.gz')\n",
    "]\n",
    "\n",
    "adhd_file_paths = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(adhd_dir)\n",
    "    for file in files if file.endswith('.nii.gz')\n",
    "]\n",
    "\n",
    "# Assuming tdc_file_paths and adhd_file_paths were correctly populated\n",
    "tdc_labels = [0] * len(tdc_file_paths)  # Create labels for TDC\n",
    "adhd_labels = [1] * len(adhd_file_paths)  # Create labels for ADHD\n",
    "\n",
    "# Combine file paths and labels\n",
    "file_paths = tdc_file_paths + adhd_file_paths\n",
    "labels = tdc_labels + adhd_labels\n",
    "\n",
    "# Verify lengths\n",
    "print(f\"Total file paths: {len(file_paths)}\")  # Should be 5100\n",
    "print(f\"Total labels: {len(labels)}\")  # Should also be 5100\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f'Class weights: ', class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzMlmaGzUNdd"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_6Oj7oNrUHLO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "class FMRI_Dataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, max_shape, smoothing_sigma=1, augment=False):\n",
    "        self.file_paths = file_paths  # List of paths to the fMRI data files\n",
    "        self.labels = labels  # Corresponding labels\n",
    "        self.max_shape = max_shape  # Shape to pad all inputs to (e.g., [1, 61, 73, 61])\n",
    "        self.smoothing_sigma = smoothing_sigma  # Standard deviation for Gaussian smoothing\n",
    "        self.augment = augment  # Apply augmentations if True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load fMRI data\n",
    "        fmri_img = nib.load(self.file_paths[idx])\n",
    "        data = fmri_img.get_fdata()\n",
    "\n",
    "        # Apply Gaussian smoothing\n",
    "        data = self.smooth_data(data)\n",
    "\n",
    "        # Apply augmentations if enabled\n",
    "        if self.augment:\n",
    "            data = self.apply_augmentations(data)\n",
    "\n",
    "        # Normalize the data\n",
    "        data = self.normalize_data(data)\n",
    "\n",
    "        # Convert to tensor and add missing dimensions\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Pad the tensor to the specified max_shape\n",
    "        data_padded = F.pad(data_tensor, pad=self.calculate_padding(data_tensor.shape), mode='constant', value=0)\n",
    "\n",
    "        # Ensure the final shape matches max_shape\n",
    "        data_padded = data_padded.view(*self.max_shape)\n",
    "\n",
    "        # Get the label\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return data_padded, label\n",
    "\n",
    "    def apply_augmentations(self, data):\n",
    "        data = self.add_noise(data)\n",
    "        data = self.random_rotate(data)\n",
    "        data = self.random_intensity_shift(data)\n",
    "        return data\n",
    "\n",
    "    def add_noise(self, data, mean=0, std=0.01):\n",
    "        noise = np.random.normal(mean, std, data.shape)\n",
    "        return data + noise\n",
    "\n",
    "    def random_rotate(self, data):\n",
    "        angles = np.random.uniform(-5, 5, size=3)\n",
    "        return ndimage.rotate(data, angle=angles[0], axes=(1, 2), reshape=False, mode='nearest')\n",
    "\n",
    "    def random_intensity_shift(self, data, shift_limit=0.05):\n",
    "        shift_value = np.random.uniform(-shift_limit, shift_limit)\n",
    "        return data + shift_value\n",
    "\n",
    "    def calculate_padding(self, current_shape):\n",
    "        padding = []\n",
    "        for current_dim, max_dim in zip(reversed(current_shape), reversed(self.max_shape)):\n",
    "            pad_total = max_dim - current_dim\n",
    "            padding.append(pad_total // 2)\n",
    "            padding.append(pad_total - (pad_total // 2))\n",
    "        return padding\n",
    "\n",
    "    def normalize_data(self, data):\n",
    "        mean = data.mean()\n",
    "        std = data.std()\n",
    "        return (data - mean) / std if std > 0 else data\n",
    "\n",
    "    def smooth_data(self, data):\n",
    "        return ndimage.gaussian_filter(data, sigma=self.smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "n8wMvOSlXa0N",
    "outputId": "17ebcb4d-69c9-4232-8cfc-980c8e921933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3570\n",
      "Validation set size: 765\n",
      "Test set size: 765\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Assuming you already have file_paths and labels defined as in your previous code\n",
    "\n",
    "# Parameters\n",
    "batch_size = 4\n",
    "num_classes = 2\n",
    "max_shape = [1, 61, 73, 61]\n",
    "\n",
    "# Stratified Shuffle Split\n",
    "labels = np.array(labels)\n",
    "dataset = FMRI_Dataset(file_paths, labels, max_shape, augment=True)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)  # 70% train, 30% test\n",
    "\n",
    "for train_index, test_index in sss.split(file_paths, labels):\n",
    "    train_file_paths, test_file_paths = np.array(file_paths)[train_index], np.array(file_paths)[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "\n",
    "# Further split the test set into validation and test sets\n",
    "sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)  # 50% of the test set for validation\n",
    "for val_index, test_index in sss_val.split(test_file_paths, test_labels):\n",
    "    val_file_paths, final_test_file_paths = np.array(test_file_paths)[val_index], np.array(test_file_paths)[test_index]\n",
    "    val_labels, final_test_labels = test_labels[val_index], test_labels[test_index]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training set size: {len(train_file_paths)}\")\n",
    "print(f\"Validation set size: {len(val_file_paths)}\")\n",
    "print(f\"Test set size: {len(final_test_file_paths)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FMRI_Dataset(train_file_paths.tolist(), train_labels.tolist(), max_shape)\n",
    "val_dataset = FMRI_Dataset(val_file_paths.tolist(), val_labels.tolist(), max_shape)\n",
    "test_dataset = FMRI_Dataset(final_test_file_paths.tolist(), final_test_labels.tolist(), max_shape)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Path: data/preprocessed/TDC/ADHD200_DPARSF_ADHD200_WashU_0015049_HC/DegreeCentrality_PositiveBinarizedSumBrainMap_ADHD200_WashU_0015049.nii.gz\n",
      "Label: 0\n",
      "Data Shape: (61, 73, 61)\n",
      "\n",
      "File Path: data/preprocessed/TDC/ADHD200_DPARSF_ADHD200_NYU_2735617_HC/ALFFMap_ADHD200_NYU_2735617.nii.gz\n",
      "Label: 0\n",
      "Data Shape: (61, 73, 61)\n",
      "\n",
      "File Path: data/preprocessed/TDC/ADHD200_DPARSF_ADHD200_NYU_0010046_HC/DegreeCentrality_PositiveWeightedSumBrainMap_ADHD200_NYU_0010046.nii.gz\n",
      "Label: 0\n",
      "Data Shape: (61, 73, 61)\n",
      "\n",
      "File Path: data/preprocessed/TDC/ADHD200_DPARSF_ADHD200_Pittsburgh_0016015_HC/zVMHCMap_ADHD200_Pittsburgh_0016015.nii.gz\n",
      "Label: 0\n",
      "Data Shape: (61, 73, 61)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Sample based on actual length\n",
    "sample_size = min(4, len(file_paths))  # Adjust sample size to available data\n",
    "sample_indices = random.sample(range(len(file_paths)), sample_size)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    print(f\"File Path: {file_paths[idx]}\")\n",
    "    print(f\"Label: {labels[idx]}\")\n",
    "    data = nib.load(file_paths[idx]).get_fdata()\n",
    "    print(f\"Data Shape: {data.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 61, 73, 61])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=(1, 0, 1)),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=(0, 0, 0)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(64, 1, kernel_size=3, stride=2, padding=1, output_padding=(0, 0, 0)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "autoencoder = CNN_Autoencoder().to(device)\n",
    "\n",
    "# Generate random input\n",
    "inputs = torch.rand((4, 1, 61, 73, 61)).to(device)  # Example input shape\n",
    "output = autoencoder(inputs)\n",
    "print(output.shape)  # Should match the input shape [4, 1, 61, 73, 61]\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for autoencoder\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.0001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYw0MT13SblI"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-BF1plyaGTM"
   },
   "source": [
    "### Using pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR232TTAWkLH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNOnEncoder(nn.Module):\n",
    "    def __init__(self, autoencoder, num_classes):\n",
    "        super(CNNOnEncoder, self).__init__()\n",
    "        self.encoder = autoencoder.encoder  # Use the encoder from the autoencoder\n",
    "        \n",
    "        # Convolutional layers with batch normalization\n",
    "        self.conv1 = nn.Conv3d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(512)  # Batch norm after conv1\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(256)  # Batch norm after conv2\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(128)  # Batch norm after conv3\n",
    "        \n",
    "        # Pooling and fully connected layers\n",
    "        self.pool = nn.AdaptiveMaxPool3d(output_size=(8, 8, 5))\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8 * 5, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)  # Encoder from autoencoder\n",
    "\n",
    "        # Convolutional layers with batch normalization and pooling\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output layer, without softmax\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rl5qWwF7aAIi"
   },
   "outputs": [],
   "source": [
    "# Load trained autoencoder\n",
    "trained_autoencoder = CNN_Autoencoder()\n",
    "trained_autoencoder.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "trained_autoencoder.to(device)\n",
    "trained_autoencoder.eval() # Set the model to evaluation mode\n",
    "\n",
    "# Create an instance of the new model\n",
    "cnn_with_ae_model = CNNOnEncoder(trained_autoencoder, num_classes=2).to(device)\n",
    "\n",
    "# Optionally, freeze the encoder layers, Frozen= false, Unfrozen= true\n",
    "for param in cnn_with_ae_model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.SGD(cnn_with_ae_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "error",
     "timestamp": 1725738817442,
     "user": {
      "displayName": "Yasty Sánchez",
      "userId": "01336246420740504937"
     },
     "user_tz": 360
    },
    "id": "JtGhl4d5WuQ8",
    "outputId": "8ce13504-e388-4ebe-f475-51f24117dc37"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    cnn_with_ae_model.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = cnn_with_ae_model(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and labels for accuracy calculation\n",
    "        _, preds = torch.max(output, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate training accuracy and average loss for the epoch\n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    cnn_with_ae_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels_batch in val_loader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels_batch = val_labels_batch.to(device)\n",
    "\n",
    "            # Forward pass for validation data\n",
    "            val_outputs = cnn_with_ae_model(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            _, val_preds_batch = torch.max(val_outputs, 1)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "            val_preds.extend(val_preds_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate validation accuracy and average loss\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(cnn_with_ae_model.state_dict(), 'best_cnn_with_ae.pt')\n",
    "        print(f'Model saved at epoch {epoch+1} with validation loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    torch.save(cnn_with_ae_model.state_dict(), f'cnn_with_ae_epoch{epoch+1}.pt')\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(cnn_with_ae_model.state_dict(), 'cnn_with_ae_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NC_sALTGWwog"
   },
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "\n",
    "# Load trained autoencoder\n",
    "trained_autoencoder = CNN_Autoencoder()\n",
    "trained_autoencoder.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "trained_autoencoder.to(device)\n",
    "trained_autoencoder.eval() # Set the model to evaluation mode\n",
    "\n",
    "# Load the model\n",
    "num_classes = 2\n",
    "\n",
    "classifier_model = CNNOnEncoder(trained_autoencoder, num_classes=2).to(device)  # Initialize your classifier model\n",
    "model_state_dict = torch.load('cnn_with_ae_final.pt', weights_only=False)\n",
    "classifier_model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "classifier_model.eval()\n",
    "\n",
    "# Define criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = classifier_model(inputs)\n",
    "        # print(outputs.shape)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels for confusion matrix\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and average loss\n",
    "accuracy = 100 * correct / total\n",
    "average_loss = total_loss / len(test_loader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "            xticklabels=[f'Class {i}' for i in range(num_classes)],\n",
    "            yticklabels=[f'Class {i}' for i in range(num_classes)])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Print accuracy and average loss\n",
    "print(f'Accuracy of the CNN with autoencoder on the test images: {accuracy:.2f}%')\n",
    "print(f'Average loss on the test images: {average_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhOKd9tEVyhT"
   },
   "source": [
    "### Not using pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BrAqWJi3ZhnE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(64)  # Added BatchNorm layer\n",
    "        self.conv2 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(128)  # Added BatchNorm layer\n",
    "        self.conv3 = nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(256)  # Added BatchNorm layer\n",
    "        self.pool = nn.AdaptiveMaxPool3d(output_size=(8, 8, 5))\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8 * 5, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "tW3TORHwZmS7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "simple_cnn_model = SimpleCNN(num_classes=2).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(simple_cnn_model.parameters(), lr=0.00001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Reduce LR by a factor of 0.1 every 10 epochs\n",
    "\n",
    "example_input = torch.randn(4, 1, 61, 73, 61)\n",
    "example_output = simple_cnn_model(example_input.to(device))\n",
    "print(\"Output shape:\", example_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Hbl8nB7YV2yZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.6683, Train Accuracy: 0.6409\n",
      "Epoch [1/100], Val Loss: 0.6350, Val Accuracy: 0.6614\n",
      "Model saved at epoch 1 with validation loss: 0.6350\n",
      "Epoch [2/100], Train Loss: 0.6428, Train Accuracy: 0.6529\n",
      "Epoch [2/100], Val Loss: 0.6523, Val Accuracy: 0.6627\n",
      "Epoch [3/100], Train Loss: 0.6180, Train Accuracy: 0.6742\n",
      "Epoch [3/100], Val Loss: 0.6909, Val Accuracy: 0.5033\n",
      "Epoch [4/100], Train Loss: 0.5975, Train Accuracy: 0.6832\n",
      "Epoch [4/100], Val Loss: 0.6089, Val Accuracy: 0.6549\n",
      "Model saved at epoch 4 with validation loss: 0.6089\n",
      "Epoch [5/100], Train Loss: 0.5749, Train Accuracy: 0.6966\n",
      "Epoch [5/100], Val Loss: 0.5842, Val Accuracy: 0.6941\n",
      "Model saved at epoch 5 with validation loss: 0.5842\n",
      "Epoch [6/100], Train Loss: 0.5476, Train Accuracy: 0.7162\n",
      "Epoch [6/100], Val Loss: 0.5691, Val Accuracy: 0.7072\n",
      "Model saved at epoch 6 with validation loss: 0.5691\n",
      "Epoch [7/100], Train Loss: 0.5114, Train Accuracy: 0.7471\n",
      "Epoch [7/100], Val Loss: 0.5786, Val Accuracy: 0.7124\n",
      "Epoch [8/100], Train Loss: 0.4814, Train Accuracy: 0.7552\n",
      "Epoch [8/100], Val Loss: 0.5416, Val Accuracy: 0.7085\n",
      "Model saved at epoch 8 with validation loss: 0.5416\n",
      "Epoch [9/100], Train Loss: 0.4601, Train Accuracy: 0.7728\n",
      "Epoch [9/100], Val Loss: 0.5675, Val Accuracy: 0.7111\n",
      "Epoch [10/100], Train Loss: 0.4312, Train Accuracy: 0.7821\n",
      "Epoch [10/100], Val Loss: 0.5432, Val Accuracy: 0.7033\n",
      "Epoch [11/100], Train Loss: 0.3776, Train Accuracy: 0.8297\n",
      "Epoch [11/100], Val Loss: 0.5263, Val Accuracy: 0.7190\n",
      "Model saved at epoch 11 with validation loss: 0.5263\n",
      "Epoch [12/100], Train Loss: 0.3700, Train Accuracy: 0.8311\n",
      "Epoch [12/100], Val Loss: 0.5229, Val Accuracy: 0.7281\n",
      "Model saved at epoch 12 with validation loss: 0.5229\n",
      "Epoch [13/100], Train Loss: 0.3655, Train Accuracy: 0.8345\n",
      "Epoch [13/100], Val Loss: 0.5230, Val Accuracy: 0.7281\n",
      "Epoch [14/100], Train Loss: 0.3626, Train Accuracy: 0.8350\n",
      "Epoch [14/100], Val Loss: 0.5266, Val Accuracy: 0.7294\n",
      "Epoch [15/100], Train Loss: 0.3557, Train Accuracy: 0.8392\n",
      "Epoch [15/100], Val Loss: 0.5200, Val Accuracy: 0.7242\n",
      "Model saved at epoch 15 with validation loss: 0.5200\n",
      "Epoch [16/100], Train Loss: 0.3525, Train Accuracy: 0.8387\n",
      "Epoch [16/100], Val Loss: 0.5206, Val Accuracy: 0.7281\n",
      "Epoch [17/100], Train Loss: 0.3488, Train Accuracy: 0.8395\n",
      "Epoch [17/100], Val Loss: 0.5412, Val Accuracy: 0.7307\n",
      "Epoch [18/100], Train Loss: 0.3451, Train Accuracy: 0.8370\n",
      "Epoch [18/100], Val Loss: 0.5188, Val Accuracy: 0.7294\n",
      "Model saved at epoch 18 with validation loss: 0.5188\n",
      "Epoch [19/100], Train Loss: 0.3436, Train Accuracy: 0.8392\n",
      "Epoch [19/100], Val Loss: 0.5246, Val Accuracy: 0.7242\n",
      "Epoch [20/100], Train Loss: 0.3395, Train Accuracy: 0.8448\n",
      "Epoch [20/100], Val Loss: 0.5291, Val Accuracy: 0.7294\n",
      "Epoch [21/100], Train Loss: 0.3338, Train Accuracy: 0.8415\n",
      "Epoch [21/100], Val Loss: 0.5206, Val Accuracy: 0.7320\n",
      "Epoch [22/100], Train Loss: 0.3335, Train Accuracy: 0.8451\n",
      "Epoch [22/100], Val Loss: 0.5205, Val Accuracy: 0.7333\n",
      "Epoch [23/100], Train Loss: 0.3319, Train Accuracy: 0.8459\n",
      "Epoch [23/100], Val Loss: 0.5215, Val Accuracy: 0.7359\n",
      "Epoch [24/100], Train Loss: 0.3313, Train Accuracy: 0.8485\n",
      "Epoch [24/100], Val Loss: 0.5228, Val Accuracy: 0.7294\n",
      "Epoch [25/100], Train Loss: 0.3323, Train Accuracy: 0.8459\n",
      "Epoch [25/100], Val Loss: 0.5186, Val Accuracy: 0.7412\n",
      "Model saved at epoch 25 with validation loss: 0.5186\n",
      "Epoch [26/100], Train Loss: 0.3322, Train Accuracy: 0.8454\n",
      "Epoch [26/100], Val Loss: 0.5204, Val Accuracy: 0.7346\n",
      "Epoch [27/100], Train Loss: 0.3315, Train Accuracy: 0.8482\n",
      "Epoch [27/100], Val Loss: 0.5197, Val Accuracy: 0.7346\n",
      "Epoch [28/100], Train Loss: 0.3301, Train Accuracy: 0.8459\n",
      "Epoch [28/100], Val Loss: 0.5221, Val Accuracy: 0.7346\n",
      "Epoch [29/100], Train Loss: 0.3312, Train Accuracy: 0.8465\n",
      "Epoch [29/100], Val Loss: 0.5198, Val Accuracy: 0.7346\n",
      "Epoch [30/100], Train Loss: 0.3310, Train Accuracy: 0.8476\n",
      "Epoch [30/100], Val Loss: 0.5197, Val Accuracy: 0.7346\n",
      "Epoch [31/100], Train Loss: 0.3301, Train Accuracy: 0.8459\n",
      "Epoch [31/100], Val Loss: 0.5226, Val Accuracy: 0.7307\n",
      "Epoch [32/100], Train Loss: 0.3300, Train Accuracy: 0.8482\n",
      "Epoch [32/100], Val Loss: 0.5204, Val Accuracy: 0.7346\n",
      "Epoch [33/100], Train Loss: 0.3297, Train Accuracy: 0.8468\n",
      "Epoch [33/100], Val Loss: 0.5217, Val Accuracy: 0.7281\n",
      "Epoch [34/100], Train Loss: 0.3304, Train Accuracy: 0.8468\n",
      "Epoch [34/100], Val Loss: 0.5211, Val Accuracy: 0.7373\n",
      "Epoch [35/100], Train Loss: 0.3305, Train Accuracy: 0.8468\n",
      "Epoch [35/100], Val Loss: 0.5196, Val Accuracy: 0.7294\n",
      "Epoch [36/100], Train Loss: 0.3294, Train Accuracy: 0.8465\n",
      "Epoch [36/100], Val Loss: 0.5204, Val Accuracy: 0.7333\n",
      "Epoch [37/100], Train Loss: 0.3306, Train Accuracy: 0.8471\n",
      "Epoch [37/100], Val Loss: 0.5192, Val Accuracy: 0.7359\n",
      "Epoch [38/100], Train Loss: 0.3288, Train Accuracy: 0.8465\n",
      "Epoch [38/100], Val Loss: 0.5195, Val Accuracy: 0.7346\n",
      "Epoch [39/100], Train Loss: 0.3290, Train Accuracy: 0.8473\n",
      "Epoch [39/100], Val Loss: 0.5207, Val Accuracy: 0.7346\n",
      "Epoch [40/100], Train Loss: 0.3296, Train Accuracy: 0.8465\n",
      "Epoch [40/100], Val Loss: 0.5222, Val Accuracy: 0.7294\n",
      "Epoch [41/100], Train Loss: 0.3310, Train Accuracy: 0.8479\n",
      "Epoch [41/100], Val Loss: 0.5220, Val Accuracy: 0.7333\n",
      "Epoch [42/100], Train Loss: 0.3299, Train Accuracy: 0.8476\n",
      "Epoch [42/100], Val Loss: 0.5209, Val Accuracy: 0.7373\n",
      "Epoch [43/100], Train Loss: 0.3289, Train Accuracy: 0.8465\n",
      "Epoch [43/100], Val Loss: 0.5192, Val Accuracy: 0.7333\n",
      "Epoch [44/100], Train Loss: 0.3292, Train Accuracy: 0.8468\n",
      "Epoch [44/100], Val Loss: 0.5194, Val Accuracy: 0.7346\n",
      "Epoch [45/100], Train Loss: 0.3286, Train Accuracy: 0.8499\n",
      "Epoch [45/100], Val Loss: 0.5274, Val Accuracy: 0.7294\n",
      "Epoch [46/100], Train Loss: 0.3293, Train Accuracy: 0.8485\n",
      "Epoch [46/100], Val Loss: 0.5208, Val Accuracy: 0.7359\n",
      "Epoch [47/100], Train Loss: 0.3291, Train Accuracy: 0.8473\n",
      "Epoch [47/100], Val Loss: 0.5199, Val Accuracy: 0.7333\n",
      "Epoch [48/100], Train Loss: 0.3295, Train Accuracy: 0.8473\n",
      "Epoch [48/100], Val Loss: 0.5193, Val Accuracy: 0.7346\n",
      "Epoch [49/100], Train Loss: 0.3292, Train Accuracy: 0.8485\n",
      "Epoch [49/100], Val Loss: 0.5238, Val Accuracy: 0.7333\n",
      "Epoch [50/100], Train Loss: 0.3289, Train Accuracy: 0.8479\n",
      "Epoch [50/100], Val Loss: 0.5189, Val Accuracy: 0.7359\n",
      "Epoch [51/100], Train Loss: 0.3300, Train Accuracy: 0.8454\n",
      "Epoch [51/100], Val Loss: 0.5207, Val Accuracy: 0.7359\n",
      "Epoch [52/100], Train Loss: 0.3301, Train Accuracy: 0.8473\n",
      "Epoch [52/100], Val Loss: 0.5230, Val Accuracy: 0.7307\n",
      "Epoch [53/100], Train Loss: 0.3304, Train Accuracy: 0.8459\n",
      "Epoch [53/100], Val Loss: 0.5210, Val Accuracy: 0.7359\n",
      "Epoch [54/100], Train Loss: 0.3291, Train Accuracy: 0.8482\n",
      "Epoch [54/100], Val Loss: 0.5187, Val Accuracy: 0.7359\n",
      "Epoch [55/100], Train Loss: 0.3292, Train Accuracy: 0.8487\n",
      "Epoch [55/100], Val Loss: 0.5238, Val Accuracy: 0.7294\n",
      "Epoch [56/100], Train Loss: 0.3288, Train Accuracy: 0.8459\n",
      "Epoch [56/100], Val Loss: 0.5200, Val Accuracy: 0.7320\n",
      "Epoch [57/100], Train Loss: 0.3294, Train Accuracy: 0.8471\n",
      "Epoch [57/100], Val Loss: 0.5273, Val Accuracy: 0.7294\n",
      "Epoch [58/100], Train Loss: 0.3297, Train Accuracy: 0.8473\n",
      "Epoch [58/100], Val Loss: 0.5212, Val Accuracy: 0.7294\n",
      "Epoch [59/100], Train Loss: 0.3303, Train Accuracy: 0.8473\n",
      "Epoch [59/100], Val Loss: 0.5199, Val Accuracy: 0.7307\n",
      "Epoch [60/100], Train Loss: 0.3306, Train Accuracy: 0.8473\n",
      "Epoch [60/100], Val Loss: 0.5195, Val Accuracy: 0.7359\n",
      "Epoch [61/100], Train Loss: 0.3288, Train Accuracy: 0.8471\n",
      "Epoch [61/100], Val Loss: 0.5204, Val Accuracy: 0.7320\n",
      "Epoch [62/100], Train Loss: 0.3302, Train Accuracy: 0.8448\n",
      "Epoch [62/100], Val Loss: 0.5317, Val Accuracy: 0.7307\n",
      "Epoch [63/100], Train Loss: 0.3287, Train Accuracy: 0.8482\n",
      "Epoch [63/100], Val Loss: 0.5219, Val Accuracy: 0.7320\n",
      "Epoch [64/100], Train Loss: 0.3292, Train Accuracy: 0.8476\n",
      "Epoch [64/100], Val Loss: 0.5206, Val Accuracy: 0.7386\n",
      "Epoch [65/100], Train Loss: 0.3303, Train Accuracy: 0.8476\n",
      "Epoch [65/100], Val Loss: 0.5210, Val Accuracy: 0.7294\n",
      "Epoch [66/100], Train Loss: 0.3288, Train Accuracy: 0.8487\n",
      "Epoch [66/100], Val Loss: 0.5240, Val Accuracy: 0.7307\n",
      "Epoch [67/100], Train Loss: 0.3306, Train Accuracy: 0.8468\n",
      "Epoch [67/100], Val Loss: 0.5212, Val Accuracy: 0.7255\n",
      "Epoch [68/100], Train Loss: 0.3296, Train Accuracy: 0.8476\n",
      "Epoch [68/100], Val Loss: 0.5230, Val Accuracy: 0.7294\n",
      "Epoch [69/100], Train Loss: 0.3296, Train Accuracy: 0.8468\n",
      "Epoch [69/100], Val Loss: 0.5203, Val Accuracy: 0.7373\n",
      "Epoch [70/100], Train Loss: 0.3289, Train Accuracy: 0.8465\n",
      "Epoch [70/100], Val Loss: 0.5201, Val Accuracy: 0.7373\n",
      "Epoch [71/100], Train Loss: 0.3278, Train Accuracy: 0.8479\n",
      "Epoch [71/100], Val Loss: 0.5213, Val Accuracy: 0.7281\n",
      "Epoch [72/100], Train Loss: 0.3290, Train Accuracy: 0.8471\n",
      "Epoch [72/100], Val Loss: 0.5206, Val Accuracy: 0.7346\n",
      "Epoch [73/100], Train Loss: 0.3292, Train Accuracy: 0.8485\n",
      "Epoch [73/100], Val Loss: 0.5212, Val Accuracy: 0.7333\n",
      "Epoch [74/100], Train Loss: 0.3278, Train Accuracy: 0.8462\n",
      "Epoch [74/100], Val Loss: 0.5193, Val Accuracy: 0.7359\n",
      "Epoch [75/100], Train Loss: 0.3278, Train Accuracy: 0.8476\n",
      "Epoch [75/100], Val Loss: 0.5215, Val Accuracy: 0.7320\n",
      "Epoch [76/100], Train Loss: 0.3297, Train Accuracy: 0.8468\n",
      "Epoch [76/100], Val Loss: 0.5243, Val Accuracy: 0.7294\n",
      "Epoch [77/100], Train Loss: 0.3301, Train Accuracy: 0.8479\n",
      "Epoch [77/100], Val Loss: 0.5236, Val Accuracy: 0.7307\n",
      "Epoch [78/100], Train Loss: 0.3297, Train Accuracy: 0.8473\n",
      "Epoch [78/100], Val Loss: 0.5302, Val Accuracy: 0.7294\n",
      "Epoch [79/100], Train Loss: 0.3288, Train Accuracy: 0.8454\n",
      "Epoch [79/100], Val Loss: 0.5195, Val Accuracy: 0.7373\n",
      "Epoch [80/100], Train Loss: 0.3313, Train Accuracy: 0.8471\n",
      "Epoch [80/100], Val Loss: 0.5191, Val Accuracy: 0.7320\n",
      "Epoch [81/100], Train Loss: 0.3276, Train Accuracy: 0.8462\n",
      "Epoch [81/100], Val Loss: 0.5203, Val Accuracy: 0.7359\n",
      "Epoch [82/100], Train Loss: 0.3285, Train Accuracy: 0.8459\n",
      "Epoch [82/100], Val Loss: 0.5189, Val Accuracy: 0.7346\n",
      "Epoch [83/100], Train Loss: 0.3288, Train Accuracy: 0.8485\n",
      "Epoch [83/100], Val Loss: 0.5194, Val Accuracy: 0.7346\n",
      "Epoch [84/100], Train Loss: 0.3289, Train Accuracy: 0.8471\n",
      "Epoch [84/100], Val Loss: 0.5191, Val Accuracy: 0.7359\n",
      "Epoch [85/100], Train Loss: 0.3284, Train Accuracy: 0.8473\n",
      "Epoch [85/100], Val Loss: 0.5210, Val Accuracy: 0.7333\n",
      "Epoch [86/100], Train Loss: 0.3303, Train Accuracy: 0.8459\n",
      "Epoch [86/100], Val Loss: 0.5380, Val Accuracy: 0.7294\n",
      "Epoch [87/100], Train Loss: 0.3286, Train Accuracy: 0.8462\n",
      "Epoch [87/100], Val Loss: 0.5192, Val Accuracy: 0.7373\n",
      "Epoch [88/100], Train Loss: 0.3297, Train Accuracy: 0.8454\n",
      "Epoch [88/100], Val Loss: 0.5215, Val Accuracy: 0.7359\n",
      "Epoch [89/100], Train Loss: 0.3301, Train Accuracy: 0.8479\n",
      "Epoch [89/100], Val Loss: 0.5196, Val Accuracy: 0.7373\n",
      "Epoch [90/100], Train Loss: 0.3277, Train Accuracy: 0.8465\n",
      "Epoch [90/100], Val Loss: 0.5226, Val Accuracy: 0.7307\n",
      "Epoch [91/100], Train Loss: 0.3294, Train Accuracy: 0.8448\n",
      "Epoch [91/100], Val Loss: 0.5209, Val Accuracy: 0.7346\n",
      "Epoch [92/100], Train Loss: 0.3282, Train Accuracy: 0.8479\n",
      "Epoch [92/100], Val Loss: 0.5228, Val Accuracy: 0.7307\n",
      "Epoch [93/100], Train Loss: 0.3297, Train Accuracy: 0.8457\n",
      "Epoch [93/100], Val Loss: 0.5195, Val Accuracy: 0.7359\n",
      "Epoch [94/100], Train Loss: 0.3295, Train Accuracy: 0.8490\n",
      "Epoch [94/100], Val Loss: 0.5201, Val Accuracy: 0.7359\n",
      "Epoch [95/100], Train Loss: 0.3282, Train Accuracy: 0.8471\n",
      "Epoch [95/100], Val Loss: 0.5237, Val Accuracy: 0.7320\n",
      "Epoch [96/100], Train Loss: 0.3297, Train Accuracy: 0.8476\n",
      "Epoch [96/100], Val Loss: 0.5197, Val Accuracy: 0.7320\n",
      "Epoch [97/100], Train Loss: 0.3288, Train Accuracy: 0.8459\n",
      "Epoch [97/100], Val Loss: 0.5194, Val Accuracy: 0.7333\n",
      "Epoch [98/100], Train Loss: 0.3279, Train Accuracy: 0.8490\n",
      "Epoch [98/100], Val Loss: 0.5218, Val Accuracy: 0.7359\n",
      "Epoch [99/100], Train Loss: 0.3294, Train Accuracy: 0.8468\n",
      "Epoch [99/100], Val Loss: 0.5195, Val Accuracy: 0.7307\n",
      "Epoch [100/100], Train Loss: 0.3293, Train Accuracy: 0.8487\n",
      "Epoch [100/100], Val Loss: 0.5215, Val Accuracy: 0.7333\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    simple_cnn_model.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_cnn_model(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and labels for accuracy calculation\n",
    "        _, preds = torch.max(output, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate training accuracy and average loss for the epoch\n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    simple_cnn_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels_batch in val_loader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels_batch = val_labels_batch.to(device)\n",
    "\n",
    "            # Forward pass for validation data\n",
    "            val_outputs = simple_cnn_model(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            _, val_preds_batch = torch.max(val_outputs, 1)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "            val_preds.extend(val_preds_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate validation accuracy and average loss\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(simple_cnn_model.state_dict(), 'best_simple_cnn.pt')\n",
    "        print(f'Model saved at epoch {epoch+1} with validation loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    torch.save(simple_cnn_model.state_dict(), f'simple_cnn_epoch{epoch+1}.pt')\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(simple_cnn_model.state_dict(), 'simple_cnn_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "6tjD7zs4ZtyY"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the simple CNN on the test images: 72.29%\n",
      "Average loss on the test images: 0.5427\n",
      "Sensitivity (Recall): 0.76\n",
      "Specificity: 0.70\n",
      "AUC: 0.79\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "classifier_model = SimpleCNN(num_classes=2).to(device)  # Initialize your classifier model\n",
    "model_state_dict = torch.load('simple_cnn_final.pt', weights_only=False)\n",
    "classifier_model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "classifier_model.eval()\n",
    "\n",
    "# Define criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = classifier_model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Get predictions and probabilities\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        probs = torch.softmax(output, dim=1)[:, 1]  # Probability for the positive class\n",
    "        \n",
    "        # Update counts\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Store predictions, labels, and probabilities for further metrics\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and average loss\n",
    "accuracy = 100 * correct / total\n",
    "average_loss = total_loss / len(test_loader)\n",
    "\n",
    "# Calculate confusion matrix and derived metrics\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensitivity / Recall\n",
    "specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # Specificity\n",
    "\n",
    "# Calculate AUC and plot ROC curve\n",
    "auc_score = roc_auc_score(all_labels, all_probs)\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Confusion matrix plot\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax[0],\n",
    "            xticklabels=[f'Class {i}' for i in range(num_classes)],\n",
    "            yticklabels=[f'Class {i}' for i in range(num_classes)])\n",
    "ax[0].set_xlabel('Predicted')\n",
    "ax[0].set_ylabel('True')\n",
    "ax[0].set_title('Confusion Matrix')\n",
    "\n",
    "# ROC curve plot\n",
    "ax[1].plot(fpr, tpr, color='blue', label=f'AUC = {auc_score:.2f}')\n",
    "ax[1].plot([0, 1], [0, 1], 'r--')\n",
    "ax[1].set_xlim([0.0, 1.0])\n",
    "ax[1].set_ylim([0.0, 1.05])\n",
    "ax[1].set_xlabel('False Positive Rate')\n",
    "ax[1].set_ylabel('True Positive Rate')\n",
    "ax[1].set_title('ROC Curve')\n",
    "ax[1].legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy of the simple CNN on the test images: {accuracy:.2f}%')\n",
    "print(f'Average loss on the test images: {average_loss:.4f}')\n",
    "print(f'Sensitivity (Recall): {sensitivity:.2f}')\n",
    "print(f'Specificity: {specificity:.2f}')\n",
    "print(f'AUC: {auc_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2w7Mw4rSe2U"
   },
   "source": [
    "# CNN-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv-DovH-a-AR"
   },
   "source": [
    "### Using pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKoBTxICbFxY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNLSTMOnAutoencoder(nn.Module):\n",
    "    def __init__(self, autoencoder, hidden_size=128, num_classes=2):\n",
    "        super(CNNLSTMOnAutoencoder, self).__init__()\n",
    "        \n",
    "        # Use the encoder from the pre-trained autoencoder\n",
    "        self.encoder = autoencoder.encoder\n",
    "        \n",
    "        # Convolutional layers with batch normalization\n",
    "        self.conv1 = nn.Conv3d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(512)\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(256)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        # Adaptive max pooling layer\n",
    "        self.pool = nn.AdaptiveMaxPool3d(output_size=(8, 8, 5))\n",
    "        \n",
    "        # LSTM and fully connected layer placeholders (initialized in forward pass)\n",
    "        self.lstm = None\n",
    "        self.fc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Pass through the encoder\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # Convolutional layers with batch normalization and pooling\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Get shape after convolutions\n",
    "        batch_size, channels, new_height, new_width, new_depth = x.shape\n",
    "        lstm_input_size = channels * new_height * new_width\n",
    "        \n",
    "        # Reshape for LSTM input (sequence length is new_depth)\n",
    "        x = x.view(batch_size, new_depth, lstm_input_size)\n",
    "\n",
    "        # Initialize LSTM and FC layers if not yet initialized\n",
    "        if self.lstm is None:\n",
    "            self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=128, batch_first=True).to(x.device)\n",
    "            self.fc = nn.Linear(in_features=128, out_features=2).to(x.device)\n",
    "\n",
    "        # Pass through LSTM and fully connected layer\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Take the output from the last LSTM step\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained autoencoder\n",
    "trained_autoencoder = CNN_Autoencoder().to(device)\n",
    "trained_autoencoder.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "trained_autoencoder.eval() # Set the model to evaluation mode\n",
    "\n",
    "# Model with pretrained weights\n",
    "cnn_lstm_with_ae = CNNLSTMOnAutoencoder(trained_autoencoder, hidden_size=128, num_classes=2).to(device)\n",
    "\n",
    "# Optionally, freeze the encoder layers, Frozen= false, Unfrozen= true\n",
    "for param in cnn_lstm_with_ae.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.SGD(cnn_lstm_with_ae.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfevQjv7erK1"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    cnn_lstm_with_ae.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = cnn_lstm_with_ae(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and labels for accuracy calculation\n",
    "        _, preds = torch.max(output, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate training accuracy and average loss for the epoch\n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    cnn_lstm_with_ae.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels_batch in val_loader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels_batch = val_labels_batch.to(device)\n",
    "\n",
    "            # Forward pass for validation data\n",
    "            val_outputs = cnn_lstm_with_ae(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            _, val_preds_batch = torch.max(val_outputs, 1)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "            val_preds.extend(val_preds_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate validation accuracy and average loss\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(cnn_lstm_with_ae.state_dict(), 'best_cnnlstm_with_ae.pt')\n",
    "        print(f'Model saved at epoch {epoch+1} with validation loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    torch.save(cnn_lstm_with_ae.state_dict(), f'cnnlstm_with_ae_epoch{epoch+1}.pt')\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(cnn_lstm_with_ae.state_dict(), 'cnnlstm_with_ae_final.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZppsrq1eun2"
   },
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "\n",
    "# Load trained autoencoder\n",
    "trained_autoencoder = CNN_Autoencoder().to(device)\n",
    "trained_autoencoder.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "trained_autoencoder.eval() # Set the model to evaluation mode\n",
    "\n",
    "# Load the model\n",
    "classifier_model = CNNLSTMOnAutoencoder(trained_autoencoder, hidden_size=128, num_classes=2).to(device)  # Initialize your classifier model\n",
    "model_state_dict = torch.load('cnnlstm_with_ae_final.pt', weights_only=False)\n",
    "classifier_model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "classifier_model.eval()\n",
    "\n",
    "# Define criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_cnn_model(inputs)\n",
    "        # print(outputs.shape)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels for confusion matrix\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and average loss\n",
    "accuracy = 100 * correct / total\n",
    "average_loss = total_loss / len(test_loader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "fig, ax = plt.subplots(figsize=(18, 16))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "            xticklabels=[f'Class {i}' for i in range(num_classes)],\n",
    "            yticklabels=[f'Class {i}' for i in range(num_classes)])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Print accuracy and average loss\n",
    "print(f'Accuracy of the CNN-LSTM with autoencoder on the test images: {accuracy:.2f}%')\n",
    "print(f'Average loss on the test images: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtCf0ayFa-f5"
   },
   "source": [
    "### Not using pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otTTcIpabGSF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_classes=2):\n",
    "        super(SimpleCNNLSTM, self).__init__()\n",
    "        \n",
    "        # Convolutional layers with batch normalization\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(256)\n",
    "        \n",
    "        # Adaptive max pooling layer\n",
    "        self.pool = nn.AdaptiveMaxPool3d(output_size=(8, 8, 5))\n",
    "        \n",
    "        # LSTM and fully connected layer placeholders\n",
    "        self.lstm = None\n",
    "        self.fc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Convolutional layers with batch normalization and pooling\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Get the output shape after convolutions\n",
    "        batch_size, channels, new_height, new_width, new_depth = x.shape\n",
    "        lstm_input_size = channels * new_height * new_width\n",
    "\n",
    "        # Reshape for LSTM input (sequence length is new_depth)\n",
    "        x = x.view(batch_size, new_depth, lstm_input_size)\n",
    "\n",
    "        # Initialize LSTM and FC layers if not yet initialized\n",
    "        if self.lstm is None:\n",
    "            self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=128, batch_first=True).to(x.device)\n",
    "            self.fc = nn.Linear(in_features=128, out_features=2).to(x.device)\n",
    "\n",
    "        # Pass through LSTM and fully connected layer\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Take the output from the last LSTM step\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model without pretrained weights\n",
    "simple_cnnlstm = SimpleCNNLSTM(hidden_size=128, num_classes=2).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.SGD(simple_cnnlstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gcu0LbVJc65y"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    simple_cnnlstm.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_cnnlstm(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and labels for accuracy calculation\n",
    "        _, preds = torch.max(output, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate training accuracy and average loss for the epoch\n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    simple_cnnlstm.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels_batch in val_loader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels_batch = val_labels_batch.to(device)\n",
    "\n",
    "            # Forward pass for validation data\n",
    "            val_outputs = simple_cnnlstm(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            _, val_preds_batch = torch.max(val_outputs, 1)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "            val_preds.extend(val_preds_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate validation accuracy and average loss\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(simple_cnnlstm.state_dict(), 'best_simple_cnnlstm.pt')\n",
    "        print(f'Model saved at epoch {epoch+1} with validation loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    torch.save(simple_cnnlstm.state_dict(), f'simple_cnnlstm_epoch{epoch+1}.pt')\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(simple_cnnlstm.state_dict(), 'simple_cnnlstm_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8O9R_idQdIef"
   },
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "\n",
    "# Load the model\n",
    "classifier_model = SimpleCNNLSTM(hidden_size=128, num_classes=2).to(device)  # Initialize your classifier model\n",
    "model_state_dict = torch.load('simple_cnnlstm_final.pt', weights_only=False)\n",
    "classifier_model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "classifier_model.eval()\n",
    "\n",
    "# Define criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_cnn_model(inputs)\n",
    "        # print(outputs.shape)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels for confusion matrix\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and average loss\n",
    "accuracy = 100 * correct / total\n",
    "average_loss = total_loss / len(test_loader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "fig, ax = plt.subplots(figsize=(18, 16))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "            xticklabels=[f'Class {i}' for i in range(num_classes)],\n",
    "            yticklabels=[f'Class {i}' for i in range(num_classes)])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Print accuracy and average loss\n",
    "print(f'Accuracy of the simple CNN-LSTM on the test images: {accuracy:.2f}%')\n",
    "print(f'Average loss on the test images: {average_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "S-BF1plyaGTM",
    "EhOKd9tEVyhT",
    "XtCf0ayFa-f5"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
