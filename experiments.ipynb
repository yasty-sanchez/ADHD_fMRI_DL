{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "GWvNv3IrQtwK"
   },
   "outputs": [],
   "source": [
    "# Torch-related imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "# Scikit-learn-related imports\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Nibabel and Scipy imports (for handling fMRI and image processing)\n",
    "import nibabel as nib\n",
    "import scipy.ndimage as ndimage  # For smoothing\n",
    "\n",
    "# NumPy, Matplotlib, and Seaborn (for data manipulation and visualization)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# OS for file system operations\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1729905899637,
     "user": {
      "displayName": "Yasty Sánchez",
      "userId": "01336246420740504937"
     },
     "user_tz": 360
    },
    "id": "PBnx2TrBRAvy",
    "outputId": "7abe6154-a5d7-4cdc-b770-78d6db615511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3693,
     "status": "ok",
     "timestamp": 1729906065409,
     "user": {
      "displayName": "Yasty Sánchez",
      "userId": "01336246420740504937"
     },
     "user_tz": 360
    },
    "id": "ELtPOdZYQ9ny",
    "outputId": "2975f1d9-50c4-42d0-ca16-e5c337366126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:  tensor([0.8004, 1.3323], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# root_dir = os.path.join('/content/drive', 'My Drive', 'UCR', '2-2024', 'InvCC', 'ADHD200', 'Datasets', 'preprocessed')\n",
    "\n",
    "import os\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "root_dir = os.path.join('data', 'preprocessed')\n",
    "\n",
    "tdc_dir = os.path.join(root_dir, 'TDC')\n",
    "adhd_dir = os.path.join(root_dir, 'ADHD')\n",
    "\n",
    "# To save autoencoder state dict\n",
    "save_path = os.path.join(root_dir, 'autoencoder.pt')\n",
    "\n",
    "# Recursively find all .nii.gz files in TDC and ADHD folders\n",
    "tdc_file_paths = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(tdc_dir)\n",
    "    for file in files if file.endswith('.nii.gz')\n",
    "]\n",
    "\n",
    "adhd_file_paths = [\n",
    "    os.path.join(root, file)\n",
    "    for root, _, files in os.walk(adhd_dir)\n",
    "    for file in files if file.endswith('.nii.gz')\n",
    "]\n",
    "\n",
    "# Adding labels\n",
    "tdc_labels = [0] * len(tdc_file_paths)\n",
    "adhd_labels = [1] * len(adhd_file_paths)\n",
    "\n",
    "file_paths = tdc_file_paths + adhd_file_paths\n",
    "labels = tdc_labels + adhd_labels\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f'Class weights: ', class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzMlmaGzUNdd"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "_6Oj7oNrUHLO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "class FMRI_Dataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, max_shape, smoothing_sigma=1, augment=False):\n",
    "        self.file_paths = file_paths  # List of paths to the fMRI data files\n",
    "        self.labels = labels  # Corresponding labels\n",
    "        self.max_shape = max_shape  # Shape to pad all inputs to (e.g., [1, 61, 73, 61])\n",
    "        self.smoothing_sigma = smoothing_sigma  # Standard deviation for Gaussian smoothing\n",
    "        self.augment = augment  # Apply augmentations if True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load fMRI data\n",
    "        fmri_img = nib.load(self.file_paths[idx])\n",
    "        data = fmri_img.get_fdata()\n",
    "\n",
    "        # Apply Gaussian smoothing\n",
    "        data = self.smooth_data(data)\n",
    "\n",
    "        # Apply augmentations if enabled\n",
    "        if self.augment:\n",
    "            data = self.apply_augmentations(data)\n",
    "\n",
    "        # Normalize the data\n",
    "        data = self.normalize_data(data)\n",
    "\n",
    "        # Convert to tensor and add missing dimensions\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Pad the tensor to the specified max_shape\n",
    "        data_padded = F.pad(data_tensor, pad=self.calculate_padding(data_tensor.shape), mode='constant', value=0)\n",
    "\n",
    "        # Ensure the final shape matches max_shape\n",
    "        data_padded = data_padded.view(*self.max_shape)\n",
    "\n",
    "        # Get the label\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return data_padded, label\n",
    "\n",
    "    def apply_augmentations(self, data):\n",
    "        data = self.add_noise(data)\n",
    "        data = self.random_rotate(data)\n",
    "        data = self.random_intensity_shift(data)\n",
    "        return data\n",
    "\n",
    "    def add_noise(self, data, mean=0, std=0.01):\n",
    "        noise = np.random.normal(mean, std, data.shape)\n",
    "        return data + noise\n",
    "\n",
    "    def random_rotate(self, data):\n",
    "        angles = np.random.uniform(-5, 5, size=3)\n",
    "        return ndimage.rotate(data, angle=angles[0], axes=(1, 2), reshape=False, mode='nearest')\n",
    "\n",
    "    def random_intensity_shift(self, data, shift_limit=0.05):\n",
    "        shift_value = np.random.uniform(-shift_limit, shift_limit)\n",
    "        return data + shift_value\n",
    "\n",
    "    def calculate_padding(self, current_shape):\n",
    "        padding = []\n",
    "        for current_dim, max_dim in zip(reversed(current_shape), reversed(self.max_shape)):\n",
    "            pad_total = max_dim - current_dim\n",
    "            padding.append(pad_total // 2)\n",
    "            padding.append(pad_total - (pad_total // 2))\n",
    "        return padding\n",
    "\n",
    "    def normalize_data(self, data):\n",
    "        mean = data.mean()\n",
    "        std = data.std()\n",
    "        return (data - mean) / std if std > 0 else data\n",
    "\n",
    "    def smooth_data(self, data):\n",
    "        return ndimage.gaussian_filter(data, sigma=self.smoothing_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "n8wMvOSlXa0N",
    "outputId": "17ebcb4d-69c9-4232-8cfc-980c8e921933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3570\n",
      "Validation set size: 765\n",
      "Test set size: 765\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Assuming you already have file_paths and labels defined as in your previous code\n",
    "\n",
    "# Parameters\n",
    "batch_size = 4\n",
    "max_shape = [1, 61, 73, 61]\n",
    "\n",
    "# Stratified Shuffle Split\n",
    "labels = np.array(labels)\n",
    "dataset = FMRI_Dataset(file_paths, labels, max_shape)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)  # 70% train, 30% test\n",
    "\n",
    "for train_index, test_index in sss.split(file_paths, labels):\n",
    "    train_file_paths, test_file_paths = np.array(file_paths)[train_index], np.array(file_paths)[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "\n",
    "# Further split the test set into validation and test sets\n",
    "sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)  # 50% of the test set for validation\n",
    "for val_index, test_index in sss_val.split(test_file_paths, test_labels):\n",
    "    val_file_paths, final_test_file_paths = np.array(test_file_paths)[val_index], np.array(test_file_paths)[test_index]\n",
    "    val_labels, final_test_labels = test_labels[val_index], test_labels[test_index]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training set size: {len(train_file_paths)}\")\n",
    "print(f\"Validation set size: {len(val_file_paths)}\")\n",
    "print(f\"Test set size: {len(final_test_file_paths)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FMRI_Dataset(train_file_paths.tolist(), train_labels.tolist(), max_shape)\n",
    "val_dataset = FMRI_Dataset(val_file_paths.tolist(), val_labels.tolist(), max_shape)\n",
    "test_dataset = FMRI_Dataset(final_test_file_paths.tolist(), final_test_labels.tolist(), max_shape)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 53, 64, 46])\n"
     ]
    }
   ],
   "source": [
    "class CNN_Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(16, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(256, 128, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(0, 1, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=(1, 1, 1), output_padding=(1, 0, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(64, 16, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 0, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2, padding=(1, 0, 0), output_padding=(0, 1, 1)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "autoencoder = CNN_Autoencoder().to(device)\n",
    "\n",
    "# Generate random input matching new shape [1, 1, 53, 64] (Batch size 1)\n",
    "inputs = torch.rand((1, 53, 64, 46)).to(device)  # Example input\n",
    "output = autoencoder(inputs)\n",
    "print(output.shape)  # should match the input shape [1, 53, 64, 46]\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()  # Since it's an autoencoder, Mean Squared Error is commonly used\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYw0MT13SblI"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-BF1plyaGTM"
   },
   "source": [
    "### Using pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HR232TTAWkLH"
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "\n",
    "class CNNOnEncoder(nn.Module):\n",
    "    def __init__(self, autoencoder, num_classes):\n",
    "        super(CNNOnEncoder, self).__init__()\n",
    "        self.encoder = autoencoder.encoder  # Use the encoder from the autoencoder\n",
    "        self.conv1 = nn.Conv3d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool3d(output_size=(8, 8, 5))\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8 * 5, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.encoder(x)\n",
    "        # print(f'Encoder {x.shape}')\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # First conv + pooling\n",
    "        # print(f'First conv + pooling {x.shape}')\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Second conv + pooling\n",
    "        # print(f'Second conv + pooling {x.shape}')\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # Second conv + pooling\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.view(x.size(1), -1)  # Flatten\n",
    "        # print(f'Flattened {x.shape}')\n",
    "        x = F.relu(self.fc1(x))  # First fully connected layer\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        x = F.softmax(x, dim=1)  # Apply softmax for probabilistic output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rl5qWwF7aAIi"
   },
   "outputs": [],
   "source": [
    "# Load trained autoencoder\n",
    "trained_autoencoder = CNN_Autoencoder()\n",
    "trained_autoencoder.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "trained_autoencoder.to(device)\n",
    "trained_autoencoder.eval() # Set the model to evaluation mode\n",
    "\n",
    "# Create an instance of the new model\n",
    "cnn_with_ae_model = CNNOnEncoder(trained_autoencoder, num_classes=2).to(device)\n",
    "\n",
    "# Optionally, freeze the encoder layers, Frozen= false, Unfrozen= true\n",
    "for param in cnn_with_ae_model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "class_weights = torch.tensor([1.0, 1.1])\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.SGD(cnn_with_ae_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "error",
     "timestamp": 1725738817442,
     "user": {
      "displayName": "Yasty Sánchez",
      "userId": "01336246420740504937"
     },
     "user_tz": 360
    },
    "id": "JtGhl4d5WuQ8",
    "outputId": "8ce13504-e388-4ebe-f475-51f24117dc37"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_with_ae_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[114], line 16\u001b[0m, in \u001b[0;36mCNNOnEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# print(f'Encoder {x.shape}')\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))  \u001b[38;5;66;03m# First conv + pooling\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:603\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    593\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    594\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    602\u001b[0m     )\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    cnn_with_ae_model.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs_reduced = torch.mean(inputs, dim=-1)\n",
    "        inputs = inputs_reduced\n",
    "\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = cnn_with_ae_model(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and labels for accuracy calculation\n",
    "        _, preds = torch.max(output, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate training accuracy and average loss for the epoch\n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_train_loss = total_loss / len(trainloader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    cnn_with_ae_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels_batch in valloader:\n",
    "            val_inputs_reduced = torch.mean(val_inputs, dim=-1)\n",
    "            val_inputs = val_inputs_reduced.to(device)\n",
    "            val_labels_batch = val_labels_batch.to(device)\n",
    "\n",
    "            # Forward pass for validation data\n",
    "            val_outputs = cnn_with_ae_model(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            _, val_preds_batch = torch.max(val_outputs, 1)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "            val_preds.extend(val_preds_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate validation accuracy and average loss\n",
    "    avg_val_loss = val_loss / len(valloader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(cnn_with_ae_model.state_dict(), 'best_cnn_with_ae.pt')\n",
    "        print(f'Model saved at epoch {epoch+1} with validation loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    torch.save(cnn_with_ae_model.state_dict(), f'cnn_with_ae_epoch{epoch}.pt')\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(cnn_with_ae_model.state_dict(), 'cnn_with_ae_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "NC_sALTGWwog"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the CNN with autoencoder on the test images: 52.23%\n",
      "Average loss on the test images: 0.6923\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAIjCAYAAACTaWgmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABE1UlEQVR4nO3dd3wUdf7H8fcmIUuAVEoKJfQSqhQxgpQjR0eaSgQhICB6iS00UbpoPOQEC8IVBQ7BgigqKtIURAJyFCkiEAhyHiT0REoSSOb3B7I/h4AkwGYS5vX0MY8HmZmd/ey6yifv7/c76zAMwxAAALA9D6sLAAAAhQNNAQAAkERTAAAAfkNTAAAAJNEUAACA39AUAAAASTQFAADgNzQFAABAEk0BAAD4DU0BkEf79u1T+/bt5e/vL4fDoSVLltzS6x88eFAOh0Nz5869pdctytq0aaM2bdpYXQZgGzQFKFL279+vYcOGqWrVqipevLj8/PzUokULvfrqqzp//rxbnzsmJkY7duzQCy+8oPnz56tp06Zufb6CNHDgQDkcDvn5+V31fdy3b58cDoccDoemTZuW7+sfPnxYEydO1LZt225BtQDcxcvqAoC8+vzzz3X//ffL6XRqwIABqlevnrKysrRu3TqNHDlSu3bt0j/+8Q+3PPf58+eVmJio5557TnFxcW55jvDwcJ0/f17FihVzy/Wvx8vLS+fOndNnn32mBx54wHRswYIFKl68uDIyMm7o2ocPH9akSZNUuXJlNWrUKM+PW758+Q09H4AbQ1OAIiE5OVnR0dEKDw/X6tWrFRoa6joWGxurpKQkff755257/mPHjkmSAgIC3PYcDodDxYsXd9v1r8fpdKpFixZ69913czUFCxcuVJcuXbR48eICqeXcuXMqUaKEvL29C+T5AFzC8AGKhKlTp+rMmTN66623TA3BZdWrV9eTTz7p+vnixYt6/vnnVa1aNTmdTlWuXFnPPvusMjMzTY+rXLmyunbtqnXr1unOO+9U8eLFVbVqVf373/92nTNx4kSFh4dLkkaOHCmHw6HKlStLuhS7X/7z702cOFEOh8O0b8WKFWrZsqUCAgJUqlQp1apVS88++6zr+LXmFKxevVr33HOPSpYsqYCAAHXv3l27d+++6vMlJSVp4MCBCggIkL+/vwYNGqRz585d+429Qt++ffXll1/q9OnTrn2bNm3Svn371Ldv31znnzx5UiNGjFD9+vVVqlQp+fn5qVOnTvrhhx9c53zzzTdq1qyZJGnQoEGuYYjLr7NNmzaqV6+eNm/erFatWqlEiRKu9+XKOQUxMTEqXrx4rtffoUMHBQYG6vDhw3l+rQByoylAkfDZZ5+patWquvvuu/N0/pAhQzR+/Hg1btxY06dPV+vWrZWQkKDo6Ohc5yYlJem+++7Tn//8Z/3tb39TYGCgBg4cqF27dkmSevXqpenTp0uSHnzwQc2fP18zZszIV/27du1S165dlZmZqcmTJ+tvf/ub7r33Xn333Xd/+LiVK1eqQ4cOOnr0qCZOnKj4+HitX79eLVq00MGDB3Od/8ADD+jXX39VQkKCHnjgAc2dO1eTJk3Kc529evWSw+HQRx995Nq3cOFC1a5dW40bN851/oEDB7RkyRJ17dpVr7zyikaOHKkdO3aodevWrr+g69Spo8mTJ0uSHnnkEc2fP1/z589Xq1atXNc5ceKEOnXqpEaNGmnGjBlq27btVet79dVXVbZsWcXExCg7O1uS9Pe//13Lly/X66+/rrCwsDy/VgBXYQCFXFpamiHJ6N69e57O37ZtmyHJGDJkiGn/iBEjDEnG6tWrXfvCw8MNScbatWtd+44ePWo4nU5j+PDhrn3JycmGJOPll182XTMmJsYIDw/PVcOECROM3//nNX36dEOScezYsWvWffk55syZ49rXqFEjo1y5csaJEydc+3744QfDw8PDGDBgQK7ne/jhh03X7Nmzp1G6dOlrPufvX0fJkiUNwzCM++67z2jXrp1hGIaRnZ1thISEGJMmTbrqe5CRkWFkZ2fneh1Op9OYPHmya9+mTZtyvbbLWrdubUgyZs+efdVjrVu3Nu376quvDEnGlClTjAMHDhilSpUyevTocd3XCOD6SApQ6KWnp0uSfH1983T+F198IUmKj4837R8+fLgk5Zp7EBERoXvuucf1c9myZVWrVi0dOHDghmu+0uW5CJ988olycnLy9JgjR45o27ZtGjhwoIKCglz7GzRooD//+c+u1/l7jz76qOnne+65RydOnHC9h3nRt29fffPNN0pJSdHq1auVkpJy1aED6dI8BA+PS/8byc7O1okTJ1xDI1u2bMnzczqdTg0aNChP57Zv317Dhg3T5MmT1atXLxUvXlx///vf8/xcAK6NpgCFnp+fnyTp119/zdP5P//8szw8PFS9enXT/pCQEAUEBOjnn3827a9UqVKuawQGBurUqVM3WHFuffr0UYsWLTRkyBAFBwcrOjpaH3zwwR82CJfrrFWrVq5jderU0fHjx3X27FnT/itfS2BgoCTl67V07txZvr6+ev/997VgwQI1a9Ys13t5WU5OjqZPn64aNWrI6XSqTJkyKlu2rLZv3660tLQ8P2f58uXzNalw2rRpCgoK0rZt2/Taa6+pXLlyeX4sgGujKUCh5+fnp7CwMO3cuTNfj7tyot+1eHp6XnW/YRg3/ByXx7sv8/Hx0dq1a7Vy5Ur1799f27dvV58+ffTnP/8517k342Zey2VOp1O9evXSvHnz9PHHH18zJZCkF198UfHx8WrVqpXeeecdffXVV1qxYoXq1q2b50REuvT+5MfWrVt19OhRSdKOHTvy9VgA10ZTgCKha9eu2r9/vxITE697bnh4uHJycrRv3z7T/tTUVJ0+fdq1kuBWCAwMNM3Uv+zKNEKSPDw81K5dO73yyiv68ccf9cILL2j16tX6+uuvr3rty3Xu2bMn17GffvpJZcqUUcmSJW/uBVxD3759tXXrVv36669XnZx52Ycffqi2bdvqrbfeUnR0tNq3b6+oqKhc70leG7S8OHv2rAYNGqSIiAg98sgjmjp1qjZt2nTLrg/YGU0BioRRo0apZMmSGjJkiFJTU3Md379/v1599VVJl+JvSblWCLzyyiuSpC5dutyyuqpVq6a0tDRt377dte/IkSP6+OOPTeedPHky12Mv38TnymWSl4WGhqpRo0aaN2+e6S/ZnTt3avny5a7X6Q5t27bV888/rzfeeEMhISHXPM/T0zNXCrFo0SL973//M+273LxcrYHKr9GjR+vQoUOaN2+eXnnlFVWuXFkxMTHXfB8B5B03L0KRUK1aNS1cuFB9+vRRnTp1THc0XL9+vRYtWqSBAwdKkho2bKiYmBj94x//0OnTp9W6dWt9//33mjdvnnr06HHN5W43Ijo6WqNHj1bPnj31xBNP6Ny5c5o1a5Zq1qxpmmg3efJkrV27Vl26dFF4eLiOHj2qN998UxUqVFDLli2vef2XX35ZnTp1UmRkpAYPHqzz58/r9ddfl7+/vyZOnHjLXseVPDw8NHbs2Oue17VrV02ePFmDBg3S3XffrR07dmjBggWqWrWq6bxq1aopICBAs2fPlq+vr0qWLKnmzZurSpUq+apr9erVevPNNzVhwgTXEsk5c+aoTZs2GjdunKZOnZqv6wG4gsWrH4B82bt3rzF06FCjcuXKhre3t+Hr62u0aNHCeP31142MjAzXeRcuXDAmTZpkVKlSxShWrJhRsWJFY8yYMaZzDOPSksQuXbrkep4rl8Jda0miYRjG8uXLjXr16hne3t5GrVq1jHfeeSfXksRVq1YZ3bt3N8LCwgxvb28jLCzMePDBB429e/fmeo4rl+2tXLnSaNGiheHj42P4+fkZ3bp1M3788UfTOZef78olj3PmzDEkGcnJydd8Tw3DvCTxWq61JHH48OFGaGio4ePjY7Ro0cJITEy86lLCTz75xIiIiDC8vLxMr7N169ZG3bp1r/qcv79Oenq6ER4ebjRu3Ni4cOGC6bynn37a8PDwMBITE//wNQD4Yw7DyMcMJAAAcNtiTgEAAJBEUwAAAH5DUwAAACTRFAAAgN/QFAAAAEk0BQAA4Dc0BQAAQNJtekfDjItWVwC4X2CXaVaXALjd+a9GuPX6PnfEue3a57e+4bZruwtJAQAAkHSbJgUAAOSJg9+Nf4+mAABgX7fwa71vB7RIAABAEkkBAMDOGD4w4d0AAACSSAoAAHbGnAITkgIAACCJpAAAYGfMKTDh3QAAAJJICgAAdsacAhOaAgCAfTF8YMK7AQAAJJEUAADsjOEDE5ICAAAgiaQAAGBnzCkw4d0AAACSSAoAAHbGnAITkgIAACCJpAAAYGfMKTChKQAA2BfDBya0SAAAQBJJAQDAzhg+MOHdAAAAkkgKAAB2RlJgwrsBAAAkkRQAAOzMg9UHv0dSAAAAJJEUAADsjDkFJjQFAAD74uZFJrRIAABAEkkBAMDOGD4w4d0AAACSSAoAAHbGnAITkgIAACCJpAAAYGfMKTDh3QAAAJJICgAAdsacAhOaAgCAfTF8YMK7AQAAJJEUAADsjOEDE5ICAAAgiaQAAGBnzCkw4d0AAACSSAoAAHbGnAITkgIAACCJpAAAYGfMKTChKQAA2BdNgQnvBgAAkERSAACwMyYampAUAAAASSQFAAA7Y06BCe8GAACQRFIAALAz5hSYkBQAAABJJAUAADtjToEJTQEAwL4YPjChRQIAAJJICgAANuYgKTAhKQAAAJJICgAANkZSYEZSAAAAJJEUAADsjKDAhKQAAAALJSQkqFmzZvL19VW5cuXUo0cP7dmzx3ROmzZt5HA4TNujjz5qOufQoUPq0qWLSpQooXLlymnkyJG6ePFivmohKQAA2FZhmFOwZs0axcbGqlmzZrp48aKeffZZtW/fXj/++KNKlizpOm/o0KGaPHmy6+cSJUq4/pydna0uXbooJCRE69ev15EjRzRgwAAVK1ZML774Yp5roSkAANhWYWgKli1bZvp57ty5KleunDZv3qxWrVq59pcoUUIhISFXvcby5cv1448/auXKlQoODlajRo30/PPPa/To0Zo4caK8vb3zVAvDBwAAuEFmZqbS09NNW2Zm5nUfl5aWJkkKCgoy7V+wYIHKlCmjevXqacyYMTp37pzrWGJiourXr6/g4GDXvg4dOig9PV27du3Kc800BQAA27pynP5WbgkJCfL39zdtCQkJf1hPTk6OnnrqKbVo0UL16tVz7e/bt6/eeecdff311xozZozmz5+vhx56yHU8JSXF1BBIcv2ckpKS5/eD4QMAANxgzJgxio+PN+1zOp1/+JjY2Fjt3LlT69atM+1/5JFHXH+uX7++QkND1a5dO+3fv1/VqlW7ZTXTFAAAbMudcwqcTud1m4Dfi4uL09KlS7V27VpVqFDhD89t3ry5JCkpKUnVqlVTSEiIvv/+e9M5qampknTNeQhXw/ABAAAWMgxDcXFx+vjjj7V69WpVqVLluo/Ztm2bJCk0NFSSFBkZqR07dujo0aOuc1asWCE/Pz9FRETkuRaSAgCAfVm/+ECxsbFauHChPvnkE/n6+rrmAPj7+8vHx0f79+/XwoUL1blzZ5UuXVrbt2/X008/rVatWqlBgwaSpPbt2ysiIkL9+/fX1KlTlZKSorFjxyo2NjZfaQVJAQAAFpo1a5bS0tLUpk0bhYaGurb3339fkuTt7a2VK1eqffv2ql27toYPH67evXvrs88+c13D09NTS5culaenpyIjI/XQQw9pwIABpvsa5AVJAQDAtgrDfQoMw/jD4xUrVtSaNWuue53w8HB98cUXN1ULSQEAAJBEUgAAsLHCkBQUJjQFAADboikwY/gAAABIIikAANgYSYEZSQEAAJBEUgAAsDOCAhOSAgAAIImkAABgY8wpMCMpAAAAkkgKAAA2RlJgRlMAALAtmgIzhg8AAIAkkgIAgJ0RFJiQFAAAAEkkBQAAG2NOgRlJAQAAkERSAACwMZICM0ubgqysLC1ZskSJiYlKSUmRJIWEhOjuu+9W9+7d5e3tbWV5AADYimXDB0lJSapTp45iYmK0detW5eTkKCcnR1u3btWAAQNUt25dJSUlWVUeAMAGHA6H27aiyLKk4LHHHlP9+vW1detW+fn5mY6lp6drwIABio2N1VdffWVRhQCA211R/cvbXSxrCr777jt9//33uRoCSfLz89Pzzz+v5s2bW1AZAAD2ZNnwQUBAgA4ePHjN4wcPHlRAQECB1QMAsCGHG7ciyLKkYMiQIRowYIDGjRundu3aKTg4WJKUmpqqVatWacqUKXr88cetKg8AANuxrCmYPHmySpYsqZdfflnDhw93jesYhqGQkBCNHj1ao0aNsqo8AIANMKfAzNIliaNHj9bo0aOVnJxsWpJYpUoVK8sCAMCWCsXNi6pUqUIjAAAocCQFZtzmGAAASCokSQEAAFYgKTCjKQAA2Bc9gQnDBwAAQFIhaAqWLVumdevWuX6eOXOmGjVqpL59++rUqVMWVgYAuN3x3QdmljcFI0eOVHp6uiRpx44dGj58uDp37qzk5GTFx8dbXB0AAPZh+ZyC5ORkRURESJIWL16srl276sUXX9SWLVvUuXNni6sDANzOiupv9O5ieVLg7e2tc+fOSZJWrlyp9u3bS5KCgoJcCQIAAHA/y5OCli1bKj4+Xi1atND333+v999/X5K0d+9eVahQweLqkBfvLVygeXPe0vHjx1SzVm098+w41W/QwOqygOsa0edO9WhRUzUrBul81kVt/PF/eu6ttdr3i3k+U/M6oZo48B41qx2q7OwcbT9wVN2eXayMrIuSpOrlA/Xi0NaKjAiTt5endiYf06R/f6e1P/zXipeFfCApMLM8KXjjjTfk5eWlDz/8ULNmzVL58uUlSV9++aU6duxocXW4nmVffqFpUxM07C+xem/Rx6pVq7YeGzZYJ06csLo04LruaVBRsz/bqtZPLVDXMYvk5emppS/erxLOYq5zmtcJ1Scv3KdVmw/qnifeUcsn3tHsT7cpxzBc53w0uae8PDzUafQHujtuvrYfOKaPJvdScGAJK14WcMMchvG7T/ZtIuOi1RXYR7/o+1W3Xn09O3a8JCknJ0ft27XWg337a/DQRyyu7vYW2GWa1SXcdsr4++i/H8Qqavh7+m7nL5KkNTP6atWWnzX5399d9TGl/Xz0y6JYRQ1/V9/t/J8kqZRPMR1b8qQ6P/OBvt56qMDqvx2d/2qEW69f5anP3Xbt5Bld3HZtd7E8KdiyZYt27Njh+vmTTz5Rjx499OyzzyorK8vCynA9F7KytPvHXbor8m7XPg8PD911193a/sNWCysDboxfSack6dSvGZKksv4ldGedMB07fU5fT39QB997TMtf7qO765Z3PeZE+nnt+e8J9Y2qqxLOYvL0cGhIl4ZKPXVWW/elWvI6kA8ON25FkOVNwbBhw7R3715J0oEDBxQdHa0SJUpo0aJFefrq5MzMTKWnp5u2zMxMd5cNSadOn1J2drZKly5t2l+6dGkdP37coqqAG+NwSC8/2lbrd/6iH3++9PmtEuovSXqu/916+8sd6v7cYm1LStUXL92vamEBrsd2eWaRGlYrp2NLntDppU/riV5N1f25xTp9hv8XoWixvCnYu3evGjVqJElatGiRWrVqpYULF2ru3LlavHjxdR+fkJAgf39/0/byXxPcXDWA282MuCjVDS+jAQlLXfs8PC79uvfWFz9o/vKd+mH/UY36+zfa+8spxXSo7zpvelyUjp0+p6jh7+qeJ97Rp+uTtHhST4UElSzw14H84eZFZpavPjAMQzk5OZIuLUns2rWrJKlixYp5+m1zzJgxuW5yZHg6b32hyCUwIFCenp65JhWeOHFCZcqUsagqIP+mx7ZT5+ZVFTX8ff3v+BnX/iMnzkqSdv9s/ozv+e8JVSznK0lq06iSOt9ZVaH3vaFfz10a8nzqjZVq1zhcD0XV1bQPvi+gVwHcPMuTgqZNm2rKlCmaP3++1qxZoy5dLk3MSE5OVnBw8HUf73Q65efnZ9qcTpqCglDM21t1Iupq44ZE176cnBxt3JioBg3vsLAyIO+mx7bTvXdXV8dRH+jn1DTTsZ9T03T4+K+qWSHItL96+UAdOnrpPiolnJd+t8rJMc/Zzskx5PAomr8t2glJgZnlScGMGTPUr18/LVmyRM8995yqV68uSfrwww919913X+fRsFr/mEEa9+xo1a1bT/XqN9A78+fp/Pnz6tGzl9WlAdc1Iy5KfdrW1v0Tl+jM+SzXEsK0s1muexBM/3CTxvZvoR0HjumHA0f1UFRd1aoYpL5TPpUkbdx9RKfOZOhfIzvpxQWJOp95UQ93aqDKIf5a9v0By14bcCMK7ZLEjIwMeXp6qlixYtc/+crHsiSxQL274B3XzYtq1a6j0c+OVYMGDa0u67bHksSbd63lbkOnfal3Vuxy/TzigTs17N5GCvT10Y4DR/Xcv9Zq/a7/uY43rhGsiQNbqnHNEBXz9NDun0/oxQWJWv6fZLe/htudu5ckVh/xpduunTStk9uu7S6Ftim4GTQFsAOaAtgBTUHBsnz4IDs7W9OnT9cHH3ygQ4cO5bo3wcmTJy2qDABwuyuqY//uYvlEw0mTJumVV15Rnz59lJaWpvj4ePXq1UseHh6aOHGi1eUBAG5jDof7tqLI8qZgwYIF+uc//6nhw4fLy8tLDz74oP71r39p/Pjx2rBhg9XlAQBgG5Y3BSkpKapf/9JNQEqVKqW0tEtLgrp27arPP3ffPakBAGBJopnlTUGFChV05MgRSVK1atW0fPlySdKmTZu43wAAAAXI8qagZ8+eWrVqlSTp8ccf17hx41SjRg0NGDBADz/8sMXVAQBuZ8wpMLN89cFLL73k+nOfPn1UqVIlJSYmqkaNGurWrZuFlQEAYC+WNwVXioyMVGRkpNVlAABswINbUZtY0hR8+umneT733nvvdWMlAADgMkuagh49euTpPIfDoezsbPcWAwCwraI69u8uljQFl78qGQAAKxXVpYPuYvnqAwAAUDhY1hSsXr1aERERSk9Pz3UsLS1NdevW1dq1ay2oDABgFyxJNLOsKZgxY4aGDh0qPz+/XMf8/f01bNgwTZ8+3YLKAACwJ8uagh9++EEdO3a85vH27dtr8+bNBVgRAMBuuM2xmWVNQWpqqooVK3bN415eXjp27FgBVgQAgL1Z1hSUL19eO3fuvObx7du3KzQ0tAArAgDYDUmBmWVNQefOnTVu3DhlZGTkOnb+/HlNmDBBXbt2taAyAADsybLbHI8dO1YfffSRatasqbi4ONWqVUuS9NNPP2nmzJnKzs7Wc889Z1V5AAAbKKK/0LuNZU1BcHCw1q9fr8cee0xjxoyRYRiSLkU5HTp00MyZMxUcHGxVeQAAGyiqMb+7WPqFSOHh4friiy906tQpJSUlyTAM1ahRQ4GBgVaWBQCALRWKOxoGBgaqWbNmuvPOO2kIAAAFpjDcvCghIUHNmjWTr6+vypUrpx49emjPnj2mczIyMhQbG6vSpUurVKlS6t27t1JTU03nHDp0SF26dFGJEiVUrlw5jRw5UhcvXszX+1EomgIAAOxqzZo1io2N1YYNG7RixQpduHBB7du319mzZ13nPP300/rss8+0aNEirVmzRocPH1avXr1cx7Ozs9WlSxdlZWVp/fr1mjdvnubOnavx48fnqxaHcXkw/zaSkb/GCCiSArtMs7oEwO3OfzXCrddv8vzXbrv25nFtb+hxx44dU7ly5bRmzRq1atVKaWlpKlu2rBYuXKj77rtP0qVJ+XXq1FFiYqLuuusuffnll+ratasOHz7smo83e/ZsjR49WseOHZO3t3eenpukAAAAN8jMzFR6erppy8zMvO7j0tLSJElBQUGSpM2bN+vChQuKiopynVO7dm1VqlRJiYmJkqTExETVr1/fNEG/Q4cOSk9P165du/JcM00BAMC23DmnICEhQf7+/qYtISHhD+vJycnRU089pRYtWqhevXqSpJSUFHl7eysgIMB0bnBwsFJSUlznXLli7/LPl8/JC0tXHwAAcLsaM2aM4uPjTfucTucfPiY2NlY7d+7UunXr3FnaNdEUAABsy533KXA6nddtAn4vLi5OS5cu1dq1a1WhQgXX/pCQEGVlZen06dOmtCA1NVUhISGuc77//nvT9S6vTrh8Tl4wfAAAgIUMw1BcXJw+/vhjrV69WlWqVDEdb9KkiYoVK6ZVq1a59u3Zs0eHDh1SZGSkJCkyMlI7duzQ0aNHXeesWLFCfn5+ioiIyHMtJAUAANsqDDc0jI2N1cKFC/XJJ5/I19fXNQfA399fPj4+8vf31+DBgxUfH6+goCD5+fnp8ccfV2RkpO666y5JUvv27RUREaH+/ftr6tSpSklJ0dixYxUbG5uvtIKmAABgW4XhNsezZs2SJLVp08a0f86cORo4cKAkafr06fLw8FDv3r2VmZmpDh066M0333Sd6+npqaVLl+qxxx5TZGSkSpYsqZiYGE2ePDlftXCfAqCI4j4FsAN336egecIat11745jWbru2u5AUAABsqxAEBYUKEw0BAIAkkgIAgI0VhjkFhQlJAQAAkERSAACwMYICM5ICAAAgiaQAAGBjzCkwoykAANgWPYEZwwcAAEASSQEAwMYYPjAjKQAAAJJICgAANkZSYEZSAAAAJJEUAABsjKDAjKQAAABIIikAANgYcwrMaAoAALZFT2DG8AEAAJBEUgAAsDGGD8xICgAAgCSSAgCAjREUmJEUAAAASSQFAAAb8yAqMCEpAAAAkkgKAAA2RlBgRlMAALAtliSaMXwAAAAkkRQAAGzMg6DAhKQAAABIIikAANgYcwrMSAoAAIAkkgIAgI0RFJiRFAAAAEkkBQAAG3OIqOD3aAoAALbFkkQzhg8AAIAkkgIAgI2xJNGMpAAAAEgiKQAA2BhBgRlJAQAAkERSAACwMQ+iAhOSAgAAIImkAABgYwQFZjQFAADbYkmiGcMHAABAEkkBAMDGCArMSAoAAIAkkgIAgI2xJNGMpAAAAEgiKQAA2Bg5gRlJAQAAkERSAACwMe5TYEZTAACwLQ96AhOGDwAAgCSSAgCAjTF8YEZSAAAAJJEUAABsjKDAjKQAAABIIikAANgYcwrMSAoAAIAkkgIAgI1xnwIzmgIAgG0xfGDG8AEAAJBEUgAAsDFyAjOSAgAAIOkGm4Jvv/1WDz30kCIjI/W///1PkjR//nytW7fulhYHAIA7eTgcbtuKonw3BYsXL1aHDh3k4+OjrVu3KjMzU5KUlpamF1988ZYXCAAACka+m4IpU6Zo9uzZ+uc//6lixYq59rdo0UJbtmy5pcUBAOBODof7tqIo303Bnj171KpVq1z7/f39dfr06VtREwAAtrJ27Vp169ZNYWFhcjgcWrJkien4wIED5XA4TFvHjh1N55w8eVL9+vWTn5+fAgICNHjwYJ05cyZfdeS7KQgJCVFSUlKu/evWrVPVqlXzezkAACxz5V+0t3LLj7Nnz6phw4aaOXPmNc/p2LGjjhw54treffdd0/F+/fpp165dWrFihZYuXaq1a9fqkUceyVcd+V6SOHToUD355JN6++235XA4dPjwYSUmJmrEiBEaN25cfi8HAIDtderUSZ06dfrDc5xOp0JCQq56bPfu3Vq2bJk2bdqkpk2bSpJef/11de7cWdOmTVNYWFie6sh3U/DMM88oJydH7dq107lz59SqVSs5nU6NGDFCjz/+eH4vBwCAZdw59p+ZmemajH+Z0+mU0+m8oet98803KleunAIDA/WnP/1JU6ZMUenSpSVJiYmJCggIcDUEkhQVFSUPDw9t3LhRPXv2zNNz5Hv4wOFw6LnnntPJkye1c+dObdiwQceOHdPzzz+f30sBAGApdy5JTEhIkL+/v2lLSEi4oTo7duyof//731q1apX++te/as2aNerUqZOys7MlSSkpKSpXrpzpMV5eXgoKClJKSkqen+eG72jo7e2tiIiIG304AAC3tTFjxig+Pt6070ZTgujoaNef69evrwYNGqhatWr65ptv1K5du5uq8/fy3RS0bdv2DydQrF69+qYKAgCgoLhz+OBmhgqup2rVqipTpoySkpLUrl07hYSE6OjRo6ZzLl68qJMnT15zHsLV5LspaNSokennCxcuaNu2bdq5c6diYmLyezkAAJBPv/zyi06cOKHQ0FBJUmRkpE6fPq3NmzerSZMmki79kp6Tk6PmzZvn+br5bgqmT59+1f0TJ07M93pIAACsVFi+OvnMmTOm5f7Jycnatm2bgoKCFBQUpEmTJql3794KCQnR/v37NWrUKFWvXl0dOnSQJNWpU0cdO3bU0KFDNXv2bF24cEFxcXGKjo7O88oD6RZ+IdJDDz2kt99++1ZdDgAA2/jPf/6jO+64Q3fccYckKT4+XnfccYfGjx8vT09Pbd++Xffee69q1qypwYMHq0mTJvr2229NwxMLFixQ7dq11a5dO3Xu3FktW7bUP/7xj3zVccu+OjkxMVHFixe/VZcDcD1HD1pdAVDkFZavCm7Tpo0Mw7jm8a+++uq61wgKCtLChQtvqo58NwW9evUy/WwYho4cOaL//Oc/3LwIAIAiLN9Ngb+/v+lnDw8P1apVS5MnT1b79u1vWWEAALhbYZlTUFjkqynIzs7WoEGDVL9+fQUGBrqrJgAACoQHPYFJvoZTPD091b59e74NEQCA21C+51jUq1dPBw4ccEctAAAUKA+H+7aiKN9NwZQpUzRixAgtXbpUR44cUXp6umkDAABFU57nFEyePFnDhw9X586dJUn33nuvaYKGYRhyOByuL2cAAKCwY6KhWZ6bgkmTJunRRx/V119/7c56AACARfLcFFy+qULr1q3dVgwAAAWpqI79u0u+5hQQswAAcPvK130Katased3G4OTJkzdVEAAABYXfdc3y1RRMmjQp1x0NAQAoqjzoCkzy1RRER0erXLly7qoFAABYKM9NAfMJAAC3m8LyLYmFRZ7fjz/6SkcAAFD05TkpyMnJcWcdAAAUOEJwM5ITAAAgKZ8TDQEAuJ2w+sCMpAAAAEgiKQAA2BhBgRlNAQDAtvjuAzOGDwAAgCSSAgCAjTHR0IykAAAASCIpAADYGEGBGUkBAACQRFIAALAxVh+YkRQAAABJJAUAABtziKjg92gKAAC2xfCBGcMHAABAEkkBAMDGSArMSAoAAIAkkgIAgI05uHuRCUkBAACQRFIAALAx5hSYkRQAAABJJAUAABtjSoEZTQEAwLY86ApMGD4AAACSSAoAADbGREMzkgIAACCJpAAAYGNMKTAjKQAAAJJICgAANuYhooLfIykAAACSSAoAADbGnAIzmgIAgG2xJNGM4QMAACCJpAAAYGPc5tiMpAAAAEgiKQAA2BhBgRlJAQAAkERSAACwMeYUmJEUAAAASSQFAAAbIygwoykAANgWcbkZ7wcAAJBEUgAAsDEH4wcmJAUAAEASSQEAwMbICcxICgAAgCSSAgCAjXHzIjOSAgAAIImkAABgY+QEZjQFAADbYvTAjOEDAAAgiaQAAGBj3LzIjKQAAACLrV27Vt26dVNYWJgcDoeWLFliOm4YhsaPH6/Q0FD5+PgoKipK+/btM51z8uRJ9evXT35+fgoICNDgwYN15syZfNVBUwAAsC0PN275cfbsWTVs2FAzZ8686vGpU6fqtdde0+zZs7Vx40aVLFlSHTp0UEZGhuucfv36adeuXVqxYoWWLl2qtWvX6pFHHslXHQ7DMIx81l7oZVy0ugLA/QKbxVldAuB257e+4dbrv7/1f267dp87yt/Q4xwOhz7++GP16NFD0qWUICwsTMOHD9eIESMkSWlpaQoODtbcuXMVHR2t3bt3KyIiQps2bVLTpk0lScuWLVPnzp31yy+/KCwsLE/PTVIAALAth8Phti0zM1Pp6emmLTMzM981JicnKyUlRVFRUa59/v7+at68uRITEyVJiYmJCggIcDUEkhQVFSUPDw9t3Lgxz89FUwAAgBskJCTI39/ftCUkJOT7OikpKZKk4OBg0/7g4GDXsZSUFJUrV8503MvLS0FBQa5z8oLVBwAA23Ln2oMxY8YoPj7etM/pdLrxGW8eTQEAAG7gdDpvSRMQEhIiSUpNTVVoaKhrf2pqqho1auQ65+jRo6bHXbx4USdPnnQ9Pi8YPgAA2JY75xTcKlWqVFFISIhWrVrl2peenq6NGzcqMjJSkhQZGanTp09r8+bNrnNWr16tnJwcNW/ePM/PRVIAALCtwvKb8ZkzZ5SUlOT6OTk5Wdu2bVNQUJAqVaqkp556SlOmTFGNGjVUpUoVjRs3TmFhYa4VCnXq1FHHjh01dOhQzZ49WxcuXFBcXJyio6PzvPJAoikAAMBy//nPf9S2bVvXz5fnIsTExGju3LkaNWqUzp49q0ceeUSnT59Wy5YttWzZMhUvXtz1mAULFiguLk7t2rWTh4eHevfurddeey1fdXCfAqCI4j4FsAN336fg4+15n5mfXz0b5H0sv7AoLMkJAACwGMMHAADb4uuQzEgKAACAJJICAICN8c3JZiQFAABAEkkBAMDGPJhVYEJTAACwLYYPzBg+AAAAkkgKAAA25mD4wISkAAAASCIpAADYGHMKzEgKAACAJJICAICNsSTRrNAmBampqZo8ebLVZQAAYBuFtilISUnRpEmTrC4DAHAbczjctxVFlg0fbN++/Q+P79mzp4AqAQDYVVH9y9tdLGsKGjVqJIfDIcMwch27vN/Bvy0AAAqMZU1BUFCQpk6dqnbt2l31+K5du9StW7cCrgoAYCfcvMjMsqagSZMmOnz4sMLDw696/PTp01dNEQAAgHtY1hQ8+uijOnv27DWPV6pUSXPmzCnAigAAduNBUGBiWVPQs2fPPzweGBiomJiYAqoGAABw8yIAgG0xp8Cs0N6nAAAAFCySAgCAbbHy3YymAABgWwwfmDF8AAAAJBWCpmDZsmVat26d6+eZM2eqUaNG6tu3r06dOmVhZQCA252Hw31bUWR5UzBy5Eilp6dLknbs2KHhw4erc+fOSk5OVnx8vMXVAQBgH5bPKUhOTlZERIQkafHixeratatefPFFbdmyRZ07d7a4OgDA7Yw5BWaWJwXe3t46d+6cJGnlypVq3769pEvfjXA5QQAAAO5neVLQsmVLxcfHq0WLFvr+++/1/vvvS5L27t2rChUqWFwd8uK9hQs0b85bOn78mGrWqq1nnh2n+g0aWF0WcF0jHm6vHn9qqJqVg3U+84I2/nBAz736ifb9fNR1TpUKZfTS0z0VeUdVOYt5acX63Yr/6yIdPfmr65xFM4apYc3yKhvkq1Pp5/T1xj0a+9onOnIszYqXhXxgSaKZ5UnBG2+8IS8vL3344YeaNWuWypcvL0n68ssv1bFjR4urw/Us+/ILTZuaoGF/idV7iz5WrVq19diwwTpx4oTVpQHXdU/j6pr9/lq1HjBNXR97Q15enlo6K04lintLkkoU99bSN2NlGIY6PfK6/jRouryLeWrxq8NMX+2+dtNePTT6bTXsOVl9R/5LVSuW0cKXB1v1soAb5jBuw68izLhodQX20S/6ftWtV1/Pjh0vScrJyVH7dq31YN/+Gjz0EYuru70FNouzuoTbTpnAUvrv6pcUNXi6vtuyX+3uqq1P3viLQluP0q9nMyRJfqWK68iaqer6l5n6euOeq16nS+v6+uCVofJv/pQuXswpyJdw2zm/9Q23Xv+7fe5b5daiRqDbru0ulicFW7Zs0Y4dO1w/f/LJJ+rRo4eeffZZZWVlWVgZrudCVpZ2/7hLd0Xe7drn4eGhu+66W9t/2GphZcCN8StVXJJ0Ku3SPCent5cMw1Bm1v//ppGReVE5OYbublTtqtcI9Cuh6E5NteGHZBqCIsDD4XDbVhRZ3hQMGzZMe/fulSQdOHBA0dHRKlGihBYtWqRRo0Zd9/GZmZlKT083bZmZme4uG5JOnT6l7OxslS5d2rS/dOnSOn78uEVVATfG4XDo5RH3af3W/fpx/xFJ0vc7Durs+Sy98GR3+RQvphLFvfVSfE95eXkqpIyf6fFTnuiu4+v/psNrpqpiaJDuf/ofVrwM4KZY3hTs3btXjRo1kiQtWrRIrVq10sKFCzV37lwtXrz4uo9PSEiQv7+/aXv5rwlurhrA7WbGmAdUt3qoBjwzx7Xv+Kkz6jfqLXVuVU/Hv/ubUr99Wf6lfLTlx0PKuWLkdfq/V+qu6L+qy6NvKDs7R/96vn9BvwTcAIcbt6LI8tUHhmEoJ+dSxLZy5Up17dpVklSxYsU8/bY5ZsyYXDc5Mjydt75Q5BIYEChPT89ckwpPnDihMmXKWFQVkH/TR9+vzvfUU9TgGfrf0dOmY6s2/KS6905S6YCSungxR2lnzit5xYs6+NVm03knTp/VidNnlXToqPYkpyjpqylq3qCKNm5PLsBXAtwcy5OCpk2basqUKZo/f77WrFmjLl26SLp0U6Pg4ODrPt7pdMrPz8+0OZ00BQWhmLe36kTU1cYNia59OTk52rgxUQ0a3mFhZUDeTR99v+79U0N1HPaafj587VUzJ06fVdqZ82rdrKbKBZXS0jU7rnmux2/3uPUuZvnvXbgeogITyz+xM2bMUL9+/bRkyRI999xzql69uiTpww8/1N13332dR8Nq/WMGadyzo1W3bj3Vq99A78yfp/Pnz6tHz15WlwZc14wxD6hPp6a6/+l/6MzZDAWX9pUkpZ3JUEbmBUlS/3vv0p7kFB07dUbNG1TRtJH36fUFX7vuZdCsXria1A3X+q37dfrXc6pSoawm/KWL9h86RkqAIqfQLknMyMiQp6enihUrlv/HsiSxQL274B3XzYtq1a6j0c+OVYMGDa0u67bHksSbd63lbkPHz9c7n22UJD3/xL16qNtdCvIvoZ8Pn9S/Plyn195Z7Tq3bvUwTRvZW/VrVlBJH2+lHE/T8vW79dd/LtNhbl5009y9JHHjfvf9O2pezd9t13aXQtsU3AyaAtgBTQHsgKagYFk+fJCdna3p06frgw8+0KFDh3Ldm+DkyZMWVQYAuN0V0dsJuI3lEw0nTZqkV155RX369FFaWpri4+PVq1cveXh4aOLEiVaXBwC4jTHP0MzypmDBggX65z//qeHDh8vLy0sPPvig/vWvf2n8+PHasGGD1eUBAGAbljcFKSkpql+/viSpVKlSSku7NL7TtWtXff7551aWBgC43REVmFjeFFSoUEFHjly6pWi1atW0fPlySdKmTZu43wAAAAXI8qagZ8+eWrVqlSTp8ccf17hx41SjRg0NGDBADz/8sMXVAQBuZw43/lMUWb764KWXXnL9uU+fPqpUqZISExNVo0YNdevWzcLKAACwF8ubgitFRkYqMjLS6jIAADbAkkQzS5qCTz/9NM/n3nvvvW6sBAAAXGZJU9CjR488nedwOJSdne3eYgAAtkVQYGZJU3D5q5IBALAUXYGJ5asPAABA4WBZU7B69WpFREQoPT0917G0tDTVrVtXa9eutaAyAIBdsCTRzLKmYMaMGRo6dKj8/PxyHfP399ewYcM0ffp0CyoDAMCeLGsKfvjhB3Xs2PGax9u3b6/NmzcXYEUAALtxONy3FUWWNQWpqakqVqzYNY97eXnp2LFjBVgRAAD2ZllTUL58ee3cufOax7dv367Q0NACrAgAYDd8H5KZZU1B586dNW7cOGVkZOQ6dv78eU2YMEFdu3a1oDIAAOzJYRiGYcUTp6amqnHjxvL09FRcXJxq1aolSfrpp580c+ZMZWdna8uWLQoODs73tTMu3upqgcInsFmc1SUAbnd+6xtuvf4P//3VbdduWNHXbdd2F8u++yA4OFjr16/XY489pjFjxuhyb+JwONShQwfNnDnzhhoCAADyqqguHXQXS78QKTw8XF988YVOnTqlpKQkGYahGjVqKDAw0MqyAACwpULxLYmBgYFq1qyZ1WUAAGymqC4ddBducwwAACQVkqQAAAArEBSYkRQAAABJJAUAADsjKjAhKQAAAJJoCgAANlYYvjp54sSJcjgcpq127dqu4xkZGYqNjVXp0qVVqlQp9e7dW6mpqe54O2gKAACwWt26dXXkyBHXtm7dOtexp59+Wp999pkWLVqkNWvW6PDhw+rVq5db6mBOAQDAtgrLfQq8vLwUEhKSa39aWpreeustLVy4UH/6058kSXPmzFGdOnW0YcMG3XXXXbe0DpICAIBtufNbEjMzM5Wenm7aMjMzr1rHvn37FBYWpqpVq6pfv346dOiQJGnz5s26cOGCoqKiXOfWrl1blSpVUmJi4q19M0RTAACAWyQkJMjf39+0JSQk5DqvefPmmjt3rpYtW6ZZs2YpOTlZ99xzj3799VelpKTI29tbAQEBpscEBwcrJSXlltfM8AEAwL7cOHwwZswYxcfHm/Y5nc5c53Xq1Mn15wYNGqh58+YKDw/XBx98IB8fH/cVeBUkBQAAuIHT6ZSfn59pu1pTcKWAgADVrFlTSUlJCgkJUVZWlk6fPm06JzU19apzEG4WTQEAwLYKw5LEK505c0b79+9XaGiomjRpomLFimnVqlWu43v27NGhQ4cUGRl5K94CE4YPAACw0IgRI9StWzeFh4fr8OHDmjBhgjw9PfXggw/K399fgwcPVnx8vIKCguTn56fHH39ckZGRt3zlgURTAACwscKwJPGXX37Rgw8+qBMnTqhs2bJq2bKlNmzYoLJly0qSpk+fLg8PD/Xu3VuZmZnq0KGD3nzzTbfU4jAMw3DLlS2UcdHqCgD3C2wWZ3UJgNud3/qGW6+/J+Wc265dK6SE267tLiQFAADbKgRBQaFCUwAAsC+6AhNWHwAAAEkkBQAAG7uZpYO3I5ICAAAgiaQAAGBjhWFJYmFCUgAAACSRFAAAbIygwIykAAAASCIpAADYGVGBCU0BAMC2WJJoxvABAACQRFIAALAxliSakRQAAABJJAUAABsjKDAjKQAAAJJICgAAdkZUYEJSAAAAJJEUAABsjPsUmNEUAABsiyWJZgwfAAAASSQFAAAbIygwIykAAACSSAoAADbGnAIzkgIAACCJpAAAYGtEBb9HUgAAACSRFAAAbIw5BWY0BQAA26InMGP4AAAASCIpAADYGMMHZiQFAABAEkkBAMDG+JZEM5ICAAAgiaQAAGBnBAUmJAUAAEASSQEAwMYICsxoCgAAtsWSRDOGDwAAgCSSAgCAjbEk0YykAAAASCIpAADYGUGBCUkBAACQRFIAALAxggIzkgIAACCJpAAAYGPcp8CMpgAAYFssSTRj+AAAAEgiKQAA2BjDB2YkBQAAQBJNAQAA+A1NAQAAkMScAgCAjTGnwIykAAAASCIpAADYGPcpMKMpAADYFsMHZgwfAAAASSQFAAAbIygwIykAAACSSAoAAHZGVGBCUgAAACSRFAAAbIwliWYkBQAAQBJJAQDAxrhPgRlJAQAAkERSAACwMYICM5oCAIB90RWYMHwAAAAk0RQAAGzM4cZ/8mvmzJmqXLmyihcvrubNm+v77793wyv+YzQFAABY7P3331d8fLwmTJigLVu2qGHDhurQoYOOHj1aoHXQFAAAbMvhcN+WH6+88oqGDh2qQYMGKSIiQrNnz1aJEiX09ttvu+eFXwNNAQAAbpCZman09HTTlpmZmeu8rKwsbd68WVFRUa59Hh4eioqKUmJiYkGWfHuuPih+W76qwiszM1MJCQkaM2aMnE6n1eXYxvmtb1hdgq3wOb89ufPvi4lTEjRp0iTTvgkTJmjixImmfcePH1d2draCg4NN+4ODg/XTTz+5r8CrcBiGYRToM+K2k56eLn9/f6WlpcnPz8/qcgC34HOO/MrMzMyVDDidzlxN5eHDh1W+fHmtX79ekZGRrv2jRo3SmjVrtHHjxgKpV7pNkwIAAKx2tQbgasqUKSNPT0+lpqaa9qempiokJMRd5V0VcwoAALCQt7e3mjRpolWrVrn25eTkaNWqVabkoCCQFAAAYLH4+HjFxMSoadOmuvPOOzVjxgydPXtWgwYNKtA6aApw05xOpyZMmMDkK9zW+JzDnfr06aNjx45p/PjxSklJUaNGjbRs2bJckw/djYmGAABAEnMKAADAb2gKAACAJJoCAADwG5oCmDgcDi1ZssTqMgC34nMOXB1NgY2kpKTo8ccfV9WqVeV0OlWxYkV169bNtDbWSoZhaPz48QoNDZWPj4+ioqK0b98+q8tCEVPYP+cfffSR2rdvr9KlS8vhcGjbtm1WlwS40BTYxMGDB9WkSROtXr1aL7/8snbs2KFly5apbdu2io2Ntbo8SdLUqVP12muvafbs2dq4caNKliypDh06KCMjw+rSUEQUhc/52bNn1bJlS/31r3+1uhQgNwO20KlTJ6N8+fLGmTNnch07deqU68+SjI8//tj186hRo4waNWoYPj4+RpUqVYyxY8caWVlZruPbtm0z2rRpY5QqVcrw9fU1GjdubGzatMkwDMM4ePCg0bVrVyMgIMAoUaKEERERYXz++edXrS8nJ8cICQkxXn75Zde+06dPG06n03j33Xdv8tXDLgr75/z3kpOTDUnG1q1bb/j1ArcaNy+ygZMnT2rZsmV64YUXVLJkyVzHAwICrvlYX19fzZ07V2FhYdqxY4eGDh0qX19fjRo1SpLUr18/3XHHHZo1a5Y8PT21bds2FStWTJIUGxurrKwsrV27ViVLltSPP/6oUqVKXfV5kpOTlZKSYvrqUH9/fzVv3lyJiYmKjo6+iXcAdlAUPudAYUdTYANJSUkyDEO1a9fO92PHjh3r+nPlypU1YsQIvffee67/WR46dEgjR450XbtGjRqu8w8dOqTevXurfv36kqSqVate83lSUlIk6apfHXr5GPBHisLnHCjsmFNgA8ZN3LTy/fffV4sWLRQSEqJSpUpp7NixOnTokOt4fHy8hgwZoqioKL300kvav3+/69gTTzyhKVOmqEWLFpowYYK2b99+U68D+CN8zoGbR1NgAzVq1JDD4dBPP/2Ur8clJiaqX79+6ty5s5YuXaqtW7fqueeeU1ZWluuciRMnateuXerSpYtWr16tiIgIffzxx5KkIUOG6MCBA+rfv7927Nihpk2b6vXXX7/qc13+etDC8NWhKJqKwuccKPSsndKAgtKxY8d8T8CaNm2aUbVqVdO5gwcPNvz9/a/5PNHR0Ua3bt2ueuyZZ54x6tevf9VjlycaTps2zbUvLS2NiYbIl8L+Of89JhqiMCIpsImZM2cqOztbd955pxYvXqx9+/Zp9+7deu211675fd01atTQoUOH9N5772n//v167bXXXL8dSdL58+cVFxenb775Rj///LO+++47bdq0SXXq1JEkPfXUU/rqq6+UnJysLVu26Ouvv3Ydu5LD4dBTTz2lKVOm6NNPP9WOHTs0YMAAhYWFqUePHrf8/cDtqbB/zqVLEyK3bdumH3/8UZK0Z88ebdu2jbkzKBys7kpQcA4fPmzExsYa4eHhhre3t1G+fHnj3nvvNb7++mvXObpiqdbIkSON0qVLG6VKlTL69OljTJ8+3fUbVGZmphEdHW1UrFjR8Pb2NsLCwoy4uDjj/PnzhmEYRlxcnFGtWjXD6XQaZcuWNfr3728cP378mvXl5OQY48aNM4KDgw2n02m0a9fO2LNnjzveCtzGCvvnfM6cOYakXNuECRPc8G4A+cNXJwMAAElMNAQAAL+hKQAAAJJoCgAAwG9oCgAAgCSaAgAA8BuaAgAAIImmAAAA/IamAAAASKIpAIqEgQMHmm733KZNGz311FMFXsc333wjh8Oh06dPF/hzA3A/mgLgJgwcOFAOh0MOh0Pe3t6qXr26Jk+erIsXL7r1eT/66CM9//zzeTqXv8gB5JWX1QUARV3Hjh01Z84cZWZm6osvvlBsbKyKFSumMWPGmM7LysqSt7f3LXnOoKCgW3IdAPg9kgLgJjmdToWEhCg8PFyPPfaYoqKi9Omnn7oi/xdeeEFhYWGqVauWJOm///2vHnjgAQUEBCgoKEjdu3fXwYMHXdfLzs5WfHy8AgICVLp0aY0aNUpXfkXJlcMHmZmZGj16tCpWrCin06nq1avrrbfe0sGDB9W2bVtJUmBgoBwOhwYOHChJysnJUUJCgqpUqSIfHx81bNhQH374oel5vvjiC9WsWVM+Pj5q27atqU4Atx+aAuAW8/HxUVZWliRp1apV2rNnj1asWKGlS5fqwoUL6tChg3x9ffXtt9/qu+++U6lSpdSxY0fXY/72t79p7ty5evvtt7Vu3TqdPHnS9FW+VzNgwAC9++67eu2117R79279/e9/V6lSpVSxYkUtXrxY0qWv6D1y5IheffVVSVJCQoL+/e9/a/bs2dq1a5eefvppPfTQQ1qzZo2kS81Lr1691K1bN23btk1DhgzRM8884663DUBhYPG3NAJFWkxMjNG9e3fDMC599fOKFSsMp9NpjBgxwoiJiTGCg4ONzMxM1/nz5883atWqZeTk5Lj2ZWZmGj4+PsZXX31lGIZhhIaGGlOnTnUdv3DhglGhQgXX8xiGYbRu3dp48sknDcMwjD179hiSjBUrVly1xq+//tqQZJw6dcq1LyMjwyhRooSxfv1607mDBw82HnzwQcMwDGPMmDFGRESE6fjo0aNzXQvA7YM5BcBNWrp0qUqVKqULFy4oJydHffv21cSJExUbG6v69eub5hH88MMPSkpKkq+vr+kaGRkZ2r9/v9LS0nTkyBE1b97cdczLy0tNmzbNNYRw2bZt2+Tp6anWrVvnueakpCSdO3dOf/7zn037s7KydMcdd0iSdu/ebapDkiIjI/P8HACKHpoC4Ca1bdtWs2bNkre3t8LCwuTl9f//WZUsWdJ07pkzZ9SkSRMtWLAg13XKli17Q8/v4+OT78ecOXNGkvT555+rfPnypmNOp/OG6gBQ9NEUADepZMmSql69ep7Obdy4sd5//32VK1dOfn5+Vz0nNDRUGzduVKtWrSRJFy9e1ObNm9W4ceOrnl+/fn3l5ORozZo1ioqKynX8clKRnZ3t2hcRESGn06lDhw5dM2GoU6eOPv30U9O+DRs2XP9FAiiymGgIFKB+/fqpTJky6t69u7799lslJyfrm2++0RNPPKFffvlFkvTkk0/qpZde0pIlS/TTTz/pL3/5yx/eY6By5cqKiYnRww8/rCVLlriu+cEHH0iSwsPD5XA4tHTpUh07dkxnzpyRr6+vRowYoaefflrz5s3T/v37tWXLFr3++uuaN2+eJOnRRx/Vvn37NHLkSO3Zs0cLFy7U3Llz3f0WAbAQTQFQgEqUKKG1a9eqUqVK6tWrl+rUqaPBgwcrIyPDlRwMHz5c/fv3V0xMjCIjI+Xr66uePXv+4XVnzZql++67T3/5y19Uu3ZtDR06VGfPnpUklS9fXpMmTdIzzzyj4OBgxcXFSZKef/55jRs3TgkJCapTp446duyozz//XFWqVJEkVapUSYsXL9aSJUvUsGFDzZ49Wy+++KIb3x0AVnMY15q9BAAAbIWkAAAASKIpAAAAv6EpAAAAkmgKAADAb2gKAACAJJoCAADwG5oCAAAgiaYAAAD8hqYAAABIoikAAAC/oSkAAACSpP8Dx6/uAmZblK8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing loop\n",
    "\n",
    "# Load trained autoencoder\n",
    "trained_autoencoder = CNN_Autoencoder()\n",
    "trained_autoencoder.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "trained_autoencoder.to(device)\n",
    "trained_autoencoder.eval() # Set the model to evaluation mode\n",
    "\n",
    "# Load the model\n",
    "num_classes = 2\n",
    "\n",
    "classifier_model = CNNOnEncoder(trained_autoencoder, num_classes=2).to(device)  # Initialize your classifier model\n",
    "model_state_dict = torch.load('cnn_with_ae_epoch7.pt', weights_only=False)\n",
    "classifier_model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "classifier_model.eval()\n",
    "\n",
    "# Define criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs_reduced = torch.mean(inputs, dim=-1)\n",
    "        inputs = inputs_reduced\n",
    "\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = classifier_model(inputs)\n",
    "        # print(outputs.shape)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels for confusion matrix\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and average loss\n",
    "accuracy = 100 * correct / total\n",
    "average_loss = total_loss / len(testloader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "            xticklabels=[f'Class {i}' for i in range(num_classes)],\n",
    "            yticklabels=[f'Class {i}' for i in range(num_classes)])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Print accuracy and average loss\n",
    "print(f'Accuracy of the CNN with autoencoder on the test images: {accuracy:.2f}%')\n",
    "print(f'Average loss on the test images: {average_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhOKd9tEVyhT"
   },
   "source": [
    "### Not using pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "BrAqWJi3ZhnE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.conv2 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(128)\n",
    "        self.conv3 = nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(256)\n",
    "        self.pool = nn.AdaptiveMaxPool3d(output_size=(8, 8, 5))\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8 * 5, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv3d, nn.Linear)):\n",
    "            nn.init.kaiming_uniform_(m.weight, a=nn.init.calculate_gain('relu'))  # Use He initialization\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)  # Initialize biases to zero\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "tW3TORHwZmS7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "simple_cnn_model = SimpleCNN(num_classes=2).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(simple_cnn_model.parameters(), lr=0.01)\n",
    "\n",
    "example_input = torch.randn(4, 1, 61, 73, 61)\n",
    "example_output = simple_cnn_model(example_input.to(device))\n",
    "print(\"Output shape:\", example_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Hbl8nB7YV2yZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 5.2868, Train Accuracy: 0.6487\n",
      "Epoch [1/100], Val Loss: 0.6721, Val Accuracy: 0.6601\n",
      "Model saved at epoch 1 with validation loss: 0.6721\n",
      "Epoch [2/100], Train Loss: 0.7491, Train Accuracy: 0.6555\n",
      "Epoch [2/100], Val Loss: 0.6604, Val Accuracy: 0.6627\n",
      "Model saved at epoch 2 with validation loss: 0.6604\n",
      "Epoch [3/100], Train Loss: 1.1049, Train Accuracy: 0.6468\n",
      "Epoch [3/100], Val Loss: 0.6661, Val Accuracy: 0.6601\n",
      "Epoch [4/100], Train Loss: 0.6797, Train Accuracy: 0.6496\n",
      "Epoch [4/100], Val Loss: 0.6677, Val Accuracy: 0.6601\n",
      "Epoch [5/100], Train Loss: 0.6849, Train Accuracy: 0.6521\n",
      "Epoch [5/100], Val Loss: 0.6779, Val Accuracy: 0.6627\n",
      "Epoch [6/100], Train Loss: 0.6880, Train Accuracy: 0.6347\n",
      "Epoch [6/100], Val Loss: 0.6912, Val Accuracy: 0.6248\n",
      "Epoch [7/100], Train Loss: 0.6929, Train Accuracy: 0.5866\n",
      "Epoch [7/100], Val Loss: 0.6919, Val Accuracy: 0.6248\n",
      "Epoch [8/100], Train Loss: 0.6925, Train Accuracy: 0.6246\n",
      "Epoch [8/100], Val Loss: 0.6912, Val Accuracy: 0.6248\n",
      "Epoch [9/100], Train Loss: 0.6919, Train Accuracy: 0.5961\n",
      "Epoch [9/100], Val Loss: 0.6917, Val Accuracy: 0.6248\n",
      "Epoch [10/100], Train Loss: 0.6924, Train Accuracy: 0.6112\n",
      "Epoch [10/100], Val Loss: 0.6932, Val Accuracy: 0.6248\n",
      "Epoch [11/100], Train Loss: 0.6919, Train Accuracy: 0.5978\n",
      "Epoch [11/100], Val Loss: 0.6954, Val Accuracy: 0.3752\n",
      "Epoch [12/100], Train Loss: 0.6913, Train Accuracy: 0.5697\n",
      "Epoch [12/100], Val Loss: 0.6918, Val Accuracy: 0.6248\n",
      "Epoch [13/100], Train Loss: 0.6928, Train Accuracy: 0.6179\n",
      "Epoch [13/100], Val Loss: 0.6931, Val Accuracy: 0.6248\n",
      "Epoch [14/100], Train Loss: 0.6929, Train Accuracy: 0.6151\n",
      "Epoch [14/100], Val Loss: 0.6916, Val Accuracy: 0.6248\n",
      "Epoch [15/100], Train Loss: 0.6921, Train Accuracy: 0.6084\n",
      "Epoch [15/100], Val Loss: 0.6933, Val Accuracy: 0.6248\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     21\u001b[0m output \u001b[38;5;241m=\u001b[39m simple_cnn_model(inputs)\n\u001b[0;32m---> 23\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    simple_cnn_model.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_cnn_model(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and labels for accuracy calculation\n",
    "        _, preds = torch.max(output, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate training accuracy and average loss for the epoch\n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    simple_cnn_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels_batch in val_loader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels_batch = val_labels_batch.to(device)\n",
    "\n",
    "            # Forward pass for validation data\n",
    "            val_outputs = simple_cnn_model(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            _, val_preds_batch = torch.max(val_outputs, 1)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "            val_preds.extend(val_preds_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate validation accuracy and average loss\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(simple_cnn_model.state_dict(), 'best_simple_cnn.pt')\n",
    "        print(f'Model saved at epoch {epoch+1} with validation loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    torch.save(simple_cnn_model.state_dict(), f'simple_cnn_epoch{epoch+1}.pt')\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(simple_cnn_model.state_dict(), 'simple_cnn_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['TDC', 'ADHD'], yticklabels=['TDC', 'ADHD'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "6tjD7zs4ZtyY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the simple CNN on the test images: 52.23%\n",
      "Average loss on the test images: 0.6925\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing loop\n",
    "\n",
    "# Load the model\n",
    "classifier_model = SimpleCNN(num_classes=2).to(device)  # Initialize your classifier model\n",
    "model_state_dict = torch.load('simple_cnn_epoch1.pt', weights_only=False)\n",
    "classifier_model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "classifier_model.eval()\n",
    "\n",
    "# Define criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs_reduced = torch.mean(inputs, dim=-1)\n",
    "        inputs = inputs_reduced\n",
    "\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_cnn_model(inputs)\n",
    "        # print(outputs.shape)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels for confusion matrix\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and average loss\n",
    "accuracy = 100 * correct / total\n",
    "average_loss = total_loss / len(testloader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "            xticklabels=[f'Class {i}' for i in range(num_classes)],\n",
    "            yticklabels=[f'Class {i}' for i in range(num_classes)])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Print accuracy and average loss\n",
    "print(f'Accuracy of the simple CNN on the test images: {accuracy:.2f}%')\n",
    "print(f'Average loss on the test images: {average_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2w7Mw4rSe2U"
   },
   "source": [
    "# CNN-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv-DovH-a-AR"
   },
   "source": [
    "### Using pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "WKoBTxICbFxY"
   },
   "outputs": [],
   "source": [
    "class CNNLSTMOnAutoencoder(nn.Module):\n",
    "    def __init__(self, autoencoder, hidden_size, num_classes):\n",
    "        super(CNNLSTMOnAutoencoder, self).__init__()\n",
    "        self.encoder = autoencoder.encoder\n",
    "        self.conv1 = nn.Conv3d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool3d(output_size=(8, 8, 5))\n",
    "        self.lstm = None\n",
    "        self.fc = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        # Apply convolutions, dropout, and pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # print(f'First conv + pooling {x.shape}')\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(f'Second conv + pooling {x.shape}')\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # print(f'Third conv + pooling {x.shape}')\n",
    "\n",
    "        # Get the final shape after convolutions\n",
    "        conv_output_shape = x.shape\n",
    "        # print(f\"Convolution output shape: {conv_output_shape}\")\n",
    "        \n",
    "        # Extract available dimensions for reshaping\n",
    "        channels, new_height, new_width, new_depth = conv_output_shape\n",
    "\n",
    "        # Calculate the LSTM input size\n",
    "        lstm_input_size = channels * new_height * new_width\n",
    "\n",
    "        # Reshape for LSTM input\n",
    "        x = x.view(batch_size, new_depth, lstm_input_size)\n",
    "\n",
    "        # Initialize LSTM and FC layers if not yet initialized\n",
    "        if self.lstm is None:\n",
    "            self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=128, batch_first=True).to(x.device)\n",
    "            self.fc = nn.Linear(in_features=128, out_features=2).to(x.device)\n",
    "\n",
    "        # Pass through LSTM and FC\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = F.relu(self.fc(lstm_out[:, -1, :]))\n",
    "        out = F.softmax(out, dim=1)  # Apply softmax for probabilistic output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained autoencoder\n",
    "trained_autoencoder = CNN_Autoencoder().to(device)\n",
    "trained_autoencoder.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "trained_autoencoder.eval() # Set the model to evaluation mode\n",
    "\n",
    "# Model with pretrained weights\n",
    "cnn_lstm_with_ae = CNNLSTMOnAutoencoder(trained_autoencoder, 128, 2).to(device)\n",
    "\n",
    "# Optionally, freeze the encoder layers, Frozen= false, Unfrozen= true\n",
    "for param in cnn_lstm_with_ae.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn_lstm_with_ae.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfevQjv7erK1"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    cnn_lstm_with_ae.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs_reduced = torch.mean(inputs, dim=-1)\n",
    "        inputs = inputs_reduced\n",
    "\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = cnn_lstm_with_ae(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and labels for accuracy calculation\n",
    "        _, preds = torch.max(output, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate training accuracy and average loss for the epoch\n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_train_loss = total_loss / len(trainloader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    cnn_lstm_with_ae.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels_batch in valloader:\n",
    "            val_inputs_reduced = torch.mean(val_inputs, dim=-1)\n",
    "            val_inputs = val_inputs_reduced.to(device)\n",
    "            val_labels_batch = val_labels_batch.to(device)\n",
    "\n",
    "            # Forward pass for validation data\n",
    "            val_outputs = cnn_lstm_with_ae(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            _, val_preds_batch = torch.max(val_outputs, 1)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "            val_preds.extend(val_preds_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate validation accuracy and average loss\n",
    "    avg_val_loss = val_loss / len(valloader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(cnn_lstm_with_ae.state_dict(), 'best_cnnlstm_with_ae.pt')\n",
    "        print(f'Model saved at epoch {epoch+1} with validation loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    torch.save(cnn_lstm_with_ae.state_dict(), f'cnnlstm_with_ae_epoch{epoch}.pt')\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(cnn_lstm_with_ae.state_dict(), 'cnnlstm_with_ae_final.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZppsrq1eun2"
   },
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "\n",
    "# Load trained autoencoder\n",
    "trained_autoencoder = CNN_Autoencoder().to(device)\n",
    "trained_autoencoder.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "trained_autoencoder.eval() # Set the model to evaluation mode\n",
    "\n",
    "# Load the model\n",
    "classifier_model = CNNLSTMOnAutoencoder(trained_autoencoder, hidden_size=128, num_classes=2).to(device)  # Initialize your classifier model\n",
    "model_state_dict = torch.load('cnnlstm_with_ae_final.pt', weights_only=False)\n",
    "classifier_model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "classifier_model.eval()\n",
    "\n",
    "# Define criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs_reduced = torch.mean(inputs, dim=-1)\n",
    "        inputs = inputs_reduced\n",
    "\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_cnn_model(inputs)\n",
    "        # print(outputs.shape)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels for confusion matrix\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and average loss\n",
    "accuracy = 100 * correct / total\n",
    "average_loss = total_loss / len(testloader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "fig, ax = plt.subplots(figsize=(18, 16))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "            xticklabels=[f'Class {i}' for i in range(num_classes)],\n",
    "            yticklabels=[f'Class {i}' for i in range(num_classes)])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Print accuracy and average loss\n",
    "print(f'Accuracy of the CNN-LSTM with autoencoder on the test images: {accuracy:.2f}%')\n",
    "print(f'Average loss on the test images: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtCf0ayFa-f5"
   },
   "source": [
    "### Not using pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "otTTcIpabGSF"
   },
   "outputs": [],
   "source": [
    "class SimpleCNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(SimpleCNNLSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool3d(output_size=(8, 8, 5))\n",
    "        self.lstm = None # To be defined later after determining input size\n",
    "        self.fc = None  # To be defined later after determining LSTM output size\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Apply convolutions, dropout, and pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # print(f'First conv + pooling {x.shape}')\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(f'Second conv + pooling {x.shape}')\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # print(f'Third conv + pooling {x.shape}')\n",
    "\n",
    "        # Get the final shape after convolutions\n",
    "        conv_output_shape = x.shape\n",
    "        # print(f\"Convolution output shape: {conv_output_shape}\")\n",
    "        \n",
    "        # Extract available dimensions for reshaping\n",
    "        channels, new_height, new_width, new_depth = conv_output_shape\n",
    "\n",
    "        # Calculate the LSTM input size\n",
    "        lstm_input_size = channels * new_height * new_width\n",
    "\n",
    "        # Reshape for LSTM input\n",
    "        x = x.view(batch_size, new_depth, lstm_input_size)\n",
    "\n",
    "        # Initialize LSTM and FC layers if not yet initialized\n",
    "        if self.lstm is None:\n",
    "            self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=128, batch_first=True).to(x.device)\n",
    "            self.fc = nn.Linear(in_features=128, out_features=2).to(x.device)\n",
    "\n",
    "        # Pass through LSTM and FC\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = F.relu(self.fc(lstm_out[:, -1, :]))\n",
    "        out = F.softmax(out, dim=1)  # Apply softmax for probabilistic output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model without pretrained weights\n",
    "simple_cnnlstm = SimpleCNNLSTM(hidden_size=128, num_classes=2).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(simple_cnnlstm.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gcu0LbVJc65y"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    simple_cnnlstm.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs_reduced = torch.mean(inputs, dim=-1)\n",
    "        inputs = inputs_reduced\n",
    "\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_cnnlstm(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and labels for accuracy calculation\n",
    "        _, preds = torch.max(output, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate training accuracy and average loss for the epoch\n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    avg_train_loss = total_loss / len(trainloader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    simple_cnnlstm.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels_batch in valloader:\n",
    "            val_inputs_reduced = torch.mean(val_inputs, dim=-1)\n",
    "            val_inputs = val_inputs_reduced.to(device)\n",
    "            val_labels_batch = val_labels_batch.to(device)\n",
    "\n",
    "            # Forward pass for validation data\n",
    "            val_outputs = simple_cnnlstm(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            _, val_preds_batch = torch.max(val_outputs, 1)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "            val_preds.extend(val_preds_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate validation accuracy and average loss\n",
    "    avg_val_loss = val_loss / len(valloader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Save the model if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(simple_cnnlstm.state_dict(), 'best_simple_cnnlstm.pt')\n",
    "        print(f'Model saved at epoch {epoch+1} with validation loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    torch.save(simple_cnnlstm.state_dict(), f'simple_cnnlstm_epoch{epoch}.pt')\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(simple_cnnlstm.state_dict(), 'simple_cnnlstm_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8O9R_idQdIef"
   },
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "\n",
    "# Load the model\n",
    "classifier_model = SimpleCNNLSTM(hidden_size=128, num_classes=2).to(device)  # Initialize your classifier model\n",
    "model_state_dict = torch.load('simple_cnnlstm_final.pt', weights_only=False)\n",
    "classifier_model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "classifier_model.eval()\n",
    "\n",
    "# Define criterion (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs_reduced = torch.mean(inputs, dim=-1)\n",
    "        inputs = inputs_reduced\n",
    "\n",
    "        # Send inputs and labels to the device (GPU if available)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_cnn_model(inputs)\n",
    "        # print(outputs.shape)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels for confusion matrix\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy and average loss\n",
    "accuracy = 100 * correct / total\n",
    "average_loss = total_loss / len(testloader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "fig, ax = plt.subplots(figsize=(18, 16))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "            xticklabels=[f'Class {i}' for i in range(num_classes)],\n",
    "            yticklabels=[f'Class {i}' for i in range(num_classes)])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Print accuracy and average loss\n",
    "print(f'Accuracy of the simple CNN-LSTM on the test images: {accuracy:.2f}%')\n",
    "print(f'Average loss on the test images: {average_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "S-BF1plyaGTM",
    "EhOKd9tEVyhT",
    "XtCf0ayFa-f5"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
